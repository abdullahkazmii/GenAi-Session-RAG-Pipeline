s ``None`` (default),
            a single value is returned if ``df`` and ``nonc`` are both scalars.
            Otherwise, ``np.broadcast(df, nonc).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized noncentral chi-square distribution.

        See Also
        --------
        random.Generator.noncentral_chisquare: which should be used for new code.

        Notes
        -----
        The probability density function for the noncentral Chi-square
        distribution is

        .. math:: P(x;df,nonc) = \sum^{\infty}_{i=0}
                               \frac{e^{-nonc/2}(nonc/2)^{i}}{i!}
                               P_{Y_{df+2i}}(x),

        where :math:`Y_{q}` is the Chi-square with q degrees of freedom.

        References
        ----------
        .. [1] Wikipedia, "Noncentral chi-squared distribution"
               https://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution

        Examples
        --------
        Draw values from the distribution and plot the histogram

        >>> import matplotlib.pyplot as plt
        >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),
        ...                   bins=200, density=True)
        >>> plt.show()

        Draw values from a noncentral chisquare with very small noncentrality,
        and compare to a chisquare.

        >>> plt.figure()
        >>> values = plt.hist(np.random.noncentral_chisquare(3, .0000001, 100000),
        ...                   bins=np.arange(0., 25, .1), density=True)
        >>> values2 = plt.hist(np.random.chisquare(3, 100000),
        ...                    bins=np.arange(0., 25, .1), density=True)
        >>> plt.plot(values[1][0:-1], values[0]-values2[0], 'ob')
        >>> plt.show()

        Demonstrate how large values of non-centrality lead to a more symmetric
        distribution.

        >>> plt.figure()
        >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),
        ...                   bins=200, density=True)
        >>> plt.show()

        
        noncentral_f(dfnum, dfden, nonc, size=None)

        Draw samples from the noncentral F distribution.

        Samples are drawn from an F distribution with specified parameters,
        `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of
        freedom in denominator), where both parameters > 1.
        `nonc` is the non-centrality parameter.

        .. note::
            New code should use the
            `~numpy.random.Generator.noncentral_f`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        dfnum : float or array_like of floats
            Numerator degrees of freedom, must be > 0.
        dfden : float or array_like of floats
            Denominator degrees of freedom, must be > 0.
        nonc : float or array_like of floats
            Non-centrality parameter, the sum of the squares of the numerator
            means, must be >= 0.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``dfnum``, ``dfden``, and ``nonc``
            are all scalars.  Otherwise, ``np.broadcast(dfnum, dfden, nonc).size``
            samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized noncentral Fisher distribution.

        See Also
        --------
        random.Generator.noncentral_f: which should be used for new code.

        Notes
        -----
        When calculating the power of an experiment (power = probability of
        rejecting the null hypothesis when a specific alternative is true) the
        non-central F statistic becomes important.  When the null hypothesis is
        true, the F statistic follows a central F distribution. When the null
        hypothesis is not true, then it follows a non-central F statistic.

        References
        ----------
        .. [1] Weisstein, Eric W. "Noncentral F-Distribution."
               From MathWorld--A Wolfram Web Resource.
               https://mathworld.wolfram.com/NoncentralF-Distribution.html
        .. [2] Wikipedia, "Noncentral F-distribution",
               https://en.wikipedia.org/wiki/Noncentral_F-distribution

        Examples
        --------
        In a study, testing for a specific alternative to the null hypothesis
        requires use of the Noncentral F distribution. We need to calculate the
        area in the tail of the distribution that exceeds the value of the F
        distribution for the null hypothesis.  We'll plot the two probability
        distributions for comparison.

        >>> dfnum = 3 # between group deg of freedom
        >>> dfden = 20 # within groups degrees of freedom
        >>> nonc = 3.0
        >>> nc_vals = np.random.noncentral_f(dfnum, dfden, nonc, 1000000)
        >>> NF = np.histogram(nc_vals, bins=50, density=True)
        >>> c_vals = np.random.f(dfnum, dfden, 1000000)
        >>> F = np.histogram(c_vals, bins=50, density=True)
        >>> import matplotlib.pyplot as plt
        >>> plt.plot(F[1][1:], F[0])
        >>> plt.plot(NF[1][1:], NF[0])
        >>> plt.show()

        
        normal(loc=0.0, scale=1.0, size=None)

        Draw random samples from a normal (Gaussian) distribution.

        The probability density function of the normal distribution, first
        derived by De Moivre and 200 years later by both Gauss and Laplace
        independently [2]_, is often called the bell curve because of
        its characteristic shape (see the example below).

        The normal distributions occurs often in nature.  For example, it
        describes the commonly occurring distribution of samples influenced
        by a large number of tiny, random disturbances, each with its own
        unique distribution [2]_.

        .. note::
            New code should use the `~numpy.random.Generator.normal`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        loc : float or array_like of floats
            Mean ("centre") of the distribution.
        scale : float or array_like of floats
            Standard deviation (spread or "width") of the distribution. Must be
            non-negative.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``loc`` and ``scale`` are both scalars.
            Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized normal distribution.

        See Also
        --------
        scipy.stats.norm : probability density function, distribution or
            cumulative density function, etc.
        random.Generator.normal: which should be used for new code.

        Notes
        -----
        The probability density for the Gaussian distribution is

        .. math:: p(x) = \frac{1}{\sqrt{ 2 \pi \sigma^2 }}
                         e^{ - \frac{ (x - \mu)^2 } {2 \sigma^2} },

        where :math:`\mu` is the mean and :math:`\sigma` the standard
        deviation. The square of the standard deviation, :math:`\sigma^2`,
        is called the variance.

        The function has its peak at the mean, and its "spread" increases with
        the standard deviation (the function reaches 0.607 times its maximum at
        :math:`x + \sigma` and :math:`x - \sigma` [2]_).  This implies that
        normal is more likely to return samples lying close to the mean, rather
        than those far away.

        References
        ----------
        .. [1] Wikipedia, "Normal distribution",
               https://en.wikipedia.org/wiki/Normal_distribution
        .. [2] P. R. Peebles Jr., "Central Limit Theorem" in "Probability,
               Random Variables and Random Signal Principles", 4th ed., 2001,
               pp. 51, 51, 125.

        Examples
        --------
        Draw samples from the distribution:

        >>> mu, sigma = 0, 0.1 # mean and standard deviation
        >>> s = np.random.normal(mu, sigma, 1000)

        Verify the mean and the standard deviation:

        >>> abs(mu - np.mean(s))
        0.0  # may vary

        >>> abs(sigma - np.std(s, ddof=1))
        0.0  # may vary

        Display the histogram of the samples, along with
        the probability density function:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, ignored = plt.hist(s, 30, density=True)
        >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *
        ...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),
        ...          linewidth=2, color='r')
        >>> plt.show()

        Two-by-four array of samples from the normal distribution with
        mean 3 and standard deviation 2.5:

        >>> np.random.normal(3, 2.5, size=(2, 4))
        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random
               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random

        numpy._core.multiarray failed to importnumpy._core.umath failed to importnumpy.randomnumpy.random._mt19937numpy.random._picklenumpy/random/mtrand.pyx' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.'p' must be 1-dimensional
        pareto(a, size=None)

        Draw samples from a Pareto II or Lomax distribution with
        specified shape.

        The Lomax or Pareto II distribution is a shifted Pareto
        distribution. The classical Pareto distribution can be
        obtained from the Lomax distribution by adding 1 and
        multiplying by the scale parameter ``m`` (see Notes).  The
        smallest value of the Lomax distribution is zero while for the
        classical Pareto distribution it is ``mu``, where the standard
        Pareto distribution has location ``mu = 1``.  Lomax can also
        be considered as a simplified version of the Generalized
        Pareto distribution (available in SciPy), with the scale set
        to one and the location set to zero.

        The Pareto distribution must be greater than zero, and is
        unbounded above.  It is also known as the "80-20 rule".  In
        this distribution, 80 percent of the weights are in the lowest
        20 percent of the range, while the other 20 percent fill the
        remaining 80 percent of the range.

        .. note::
            New code should use the `~numpy.random.Generator.pareto`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        a : float or array_like of floats
            Shape of the distribution. Must be positive.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``a`` is a scalar.  Otherwise,
            ``np.array(a).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Pareto distribution.

        See Also
        --------
        scipy.stats.lomax : probability density function, distribution or
            cumulative density function, etc.
        scipy.stats.genpareto : probability density function, distribution or
            cumulative density function, etc.
        random.Generator.pareto: which should be used for new code.

        Notes
        -----
        The probability density for the Pareto distribution is

        .. math:: p(x) = \frac{am^a}{x^{a+1}}

        where :math:`a` is the shape and :math:`m` the scale.

        The Pareto distribution, named after the Italian economist
        Vilfredo Pareto, is a power law probability distribution
        useful in many real world problems.  Outside the field of
        economics it is generally referred to as the Bradford
        distribution. Pareto developed the distribution to describe
        the distribution of wealth in an economy.  It has also found
        use in insurance, web page access statistics, oil field sizes,
        and many other problems, including the download frequency for
        projects in Sourceforge [1]_.  It is one of the so-called
        "fat-tailed" distributions.

        References
        ----------
        .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of
               Sourceforge projects.
        .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.
        .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme
               Values, Birkhauser Verlag, Basel, pp 23-30.
        .. [4] Wikipedia, "Pareto distribution",
               https://en.wikipedia.org/wiki/Pareto_distribution

        Examples
        --------
        Draw samples from the distribution:

        >>> a, m = 3., 2.  # shape and mode
        >>> s = (np.random.pareto(a, 1000) + 1) * m

        Display the histogram of the samples, along with the probability
        density function:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, _ = plt.hist(s, 100, density=True)
        >>> fit = a*m**a / bins**(a+1)
        >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')
        >>> plt.show()

        
        permutation(x)

        Randomly permute a sequence, or return a permuted range.

        If `x` is a multi-dimensional array, it is only shuffled along its
        first index.

        .. note::
            New code should use the
            `~numpy.random.Generator.permutation`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        x : int or array_like
            If `x` is an integer, randomly permute ``np.arange(x)``.
            If `x` is an array, make a copy and shuffle the elements
            randomly.

        Returns
        -------
        out : ndarray
            Permuted sequence or array range.

        See Also
        --------
        random.Generator.permutation: which should be used for new code.

        Examples
        --------
        >>> np.random.permutation(10)
        array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random

        >>> np.random.permutation([1, 4, 9, 12, 15])
        array([15,  1,  9,  4, 12]) # random

        >>> arr = np.arange(9).reshape((3, 3))
        >>> np.random.permutation(arr)
        array([[6, 7, 8], # random
               [0, 1, 2],
               [3, 4, 5]])

        
        poisson(lam=1.0, size=None)

        Draw samples from a Poisson distribution.

        The Poisson distribution is the limit of the binomial distribution
        for large N.

        .. note::
            New code should use the `~numpy.random.Generator.poisson`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        lam : float or array_like of floats
            Expected number of events occurring in a fixed-time interval,
            must be >= 0. A sequence must be broadcastable over the requested
            size.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``lam`` is a scalar. Otherwise,
            ``np.array(lam).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Poisson distribution.

        See Also
        --------
        random.Generator.poisson: which should be used for new code.

        Notes
        -----
        The probability mass function (PMF) of Poisson distribution is

        .. math:: f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!}

        For events with an expected separation :math:`\lambda` the Poisson
        distribution :math:`f(k; \lambda)` describes the probability of
        :math:`k` events occurring within the observed
        interval :math:`\lambda`.

        Because the output is limited to the range of the C int64 type, a
        ValueError is raised when `lam` is within 10 sigma of the maximum
        representable value.

        References
        ----------
        .. [1] Weisstein, Eric W. "Poisson Distribution."
               From MathWorld--A Wolfram Web Resource.
               https://mathworld.wolfram.com/PoissonDistribution.html
        .. [2] Wikipedia, "Poisson distribution",
               https://en.wikipedia.org/wiki/Poisson_distribution

        Examples
        --------
        Draw samples from the distribution:

        >>> import numpy as np
        >>> s = np.random.poisson(5, 10000)

        Display histogram of the sample:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, ignored = plt.hist(s, 14, density=True)
        >>> plt.show()

        Draw each 100 values for lambda 100 and 500:

        >>> s = np.random.poisson(lam=(100., 500.), size=(100, 2))

        
        power(a, size=None)

        Draws samples in [0, 1] from a power distribution with positive
        exponent a - 1.

        Also known as the power function distribution.

        .. note::
            New code should use the `~numpy.random.Generator.power`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        a : float or array_like of floats
            Parameter of the distribution. Must be non-negative.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``a`` is a scalar.  Otherwise,
            ``np.array(a).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized power distribution.

        Raises
        ------
        ValueError
            If a <= 0.

        See Also
        --------
        random.Generator.power: which should be used for new code.

        Notes
        -----
        The probability density function is

        .. math:: P(x; a) = ax^{a-1}, 0 \le x \le 1, a>0.

        The power function distribution is just the inverse of the Pareto
        distribution. It may also be seen as a special case of the Beta
        distribution.

        It is used, for example, in modeling the over-reporting of insurance
        claims.

        References
        ----------
        .. [1] Christian Kleiber, Samuel Kotz, "Statistical size distributions
               in economics and actuarial sciences", Wiley, 2003.
        .. [2] Heckert, N. A. and Filliben, James J. "NIST Handbook 148:
               Dataplot Reference Manual, Volume 2: Let Subcommands and Library
               Functions", National Institute of Standards and Technology
               Handbook Series, June 2003.
               https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf

        Examples
        --------
        Draw samples from the distribution:

        >>> a = 5. # shape
        >>> samples = 1000
        >>> s = np.random.power(a, samples)

        Display the histogram of the samples, along with
        the probability density function:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, ignored = plt.hist(s, bins=30)
        >>> x = np.linspace(0, 1, 100)
        >>> y = a*x**(a-1.)
        >>> normed_y = samples*np.diff(bins)[0]*y
        >>> plt.plot(x, normed_y)
        >>> plt.show()

        Compare the power function distribution to the inverse of the Pareto.

        >>> from scipy import stats # doctest: +SKIP
        >>> rvs = np.random.power(5, 1000000)
        >>> rvsp = np.random.pareto(5, 1000000)
        >>> xx = np.linspace(0,1,100)
        >>> powpdf = stats.powerlaw.pdf(xx,5)  # doctest: +SKIP

        >>> plt.figure()
        >>> plt.hist(rvs, bins=50, density=True)
        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP
        >>> plt.title('np.random.power(5)')

        >>> plt.figure()
        >>> plt.hist(1./(1.+rvsp), bins=50, density=True)
        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP
        >>> plt.title('inverse of 1 + np.random.pareto(5)')

        >>> plt.figure()
        >>> plt.hist(1./(1.+rvsp), bins=50, density=True)
        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP
        >>> plt.title('inverse of stats.pareto(5)')

        probabilities are not non-negativeprobabilities contain NaNprobabilities do not sum to 1pvals must be a 1-d sequence
        rand(d0, d1, ..., dn)

        Random values in a given shape.

        .. note::
            This is a convenience function for users porting code from Matlab,
            and wraps `random_sample`. That function takes a
            tuple to specify the size of the output, which is consistent with
            other NumPy functions like `numpy.zeros` and `numpy.ones`.

        Create an array of the given shape and populate it with
        random samples from a uniform distribution
        over ``[0, 1)``.

        Parameters
        ----------
        d0, d1, ..., dn : int, optional
            The dimensions of the returned array, must be non-negative.
            If no argument is given a single Python float is returned.

        Returns
        -------
        out : ndarray, shape ``(d0, d1, ..., dn)``
            Random values.

        See Also
        --------
        random

        Examples
        --------
        >>> np.random.rand(3,2)
        array([[ 0.14022471,  0.96360618],  #random
               [ 0.37601032,  0.25528411],  #random
               [ 0.49313049,  0.94909878]]) #random

        
        randint(low, high=None, size=None, dtype=int)

        Return random integers from `low` (inclusive) to `high` (exclusive).

        Return random integers from the "discrete uniform" distribution of
        the specified dtype in the "half-open" interval [`low`, `high`). If
        `high` is None (the default), then results are from [0, `low`).

        .. note::
            New code should use the `~numpy.random.Generator.integers`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        low : int or array-like of ints
            Lowest (signed) integers to be drawn from the distribution (unless
            ``high=None``, in which case this parameter is one above the
            *highest* such integer).
        high : int or array-like of ints, optional
            If provided, one above the largest (signed) integer to be drawn
            from the distribution (see above for behavior if ``high=None``).
            If array-like, must contain integer values
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.
        dtype : dtype, optional
            Desired dtype of the result. Byteorder must be native.
            The default value is long.

            .. warning::
              This function defaults to the C-long dtype, which is 32bit on windows
              and otherwise 64bit on 64bit platforms (and 32bit on 32bit ones).
              Since NumPy 2.0, NumPy's default integer is 32bit on 32bit platforms
              and 64bit on 64bit platforms.  Which corresponds to `np.intp`.
              (`dtype=int` is not the same as in most NumPy functions.)

        Returns
        -------
        out : int or ndarray of ints
            `size`-shaped array of random integers from the appropriate
            distribution, or a single such random int if `size` not provided.

        See Also
        --------
        random_integers : similar to `randint`, only for the closed
            interval [`low`, `high`], and 1 is the lowest value if `high` is
            omitted.
        random.Generator.integers: which should be used for new code.

        Examples
        --------
        >>> np.random.randint(2, size=10)
        array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random
        >>> np.random.randint(1, size=10)
        array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

        Generate a 2 x 4 array of ints between 0 and 4, inclusive:

        >>> np.random.randint(5, size=(2, 4))
        array([[4, 0, 2, 1], # random
               [3, 2, 2, 0]])

        Generate a 1 x 3 array with 3 different upper bounds

        >>> np.random.randint(1, [3, 5, 10])
        array([2, 2, 9]) # random

        Generate a 1 by 3 array with 3 different lower bounds

        >>> np.random.randint([1, 5, 7], 10)
        array([9, 8, 7]) # random

        Generate a 2 by 4 array using broadcasting with dtype of uint8

        >>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)
        array([[ 8,  6,  9,  7], # random
               [ 1, 16,  9, 12]], dtype=uint8)
        
        randn(d0, d1, ..., dn)

        Return a sample (or samples) from the "standard normal" distribution.

        .. note::
            This is a convenience function for users porting code from Matlab,
            and wraps `standard_normal`. That function takes a
            tuple to specify the size of the output, which is consistent with
            other NumPy functions like `numpy.zeros` and `numpy.ones`.

        .. note::
            New code should use the
            `~numpy.random.Generator.standard_normal`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        If positive int_like arguments are provided, `randn` generates an array
        of shape ``(d0, d1, ..., dn)``, filled
        with random floats sampled from a univariate "normal" (Gaussian)
        distribution of mean 0 and variance 1. A single float randomly sampled
        from the distribution is returned if no argument is provided.

        Parameters
        ----------
        d0, d1, ..., dn : int, optional
            The dimensions of the returned array, must be non-negative.
            If no argument is given a single Python float is returned.

        Returns
        -------
        Z : ndarray or float
            A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from
            the standard normal distribution, or a single such float if
            no parameters were supplied.

        See Also
        --------
        standard_normal : Similar, but takes a tuple as its argument.
        normal : Also accepts mu and sigma arguments.
        random.Generator.standard_normal: which should be used for new code.

        Notes
        -----
        For random samples from the normal distribution with mean ``mu`` and
        standard deviation ``sigma``, use::

            sigma * np.random.randn(...) + mu

        Examples
        --------
        >>> np.random.randn()
        2.1923875335537315  # random

        Two-by-four array of samples from the normal distribution with
        mean 3 and standard deviation 2.5:

        >>> 3 + 2.5 * np.random.randn(2, 4)
        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random
               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random

        
        random_integers(low, high=None, size=None)

        Random integers of type `numpy.int_` between `low` and `high`, inclusive.

        Return random integers of type `numpy.int_` from the "discrete uniform"
        distribution in the closed interval [`low`, `high`].  If `high` is
        None (the default), then results are from [1, `low`]. The `numpy.int_`
        type translates to the C long integer type and its precision
        is platform dependent.

        This function has been deprecated. Use randint instead.

        .. deprecated:: 1.11.0

        Parameters
        ----------
        low : int
            Lowest (signed) integer to be drawn from the distribution (unless
            ``high=None``, in which case this parameter is the *highest* such
            integer).
        high : int, optional
            If provided, the largest (signed) integer to be drawn from the
            distribution (see above for behavior if ``high=None``).
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        out : int or ndarray of ints
            `size`-shaped array of random integers from the appropriate
            distribution, or a single such random int if `size` not provided.

        See Also
        --------
        randint : Similar to `random_integers`, only for the half-open
            interval [`low`, `high`), and 0 is the lowest value if `high` is
            omitted.

        Notes
        -----
        To sample from N evenly spaced floating-point numbers between a and b,
        use::

          a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)

        Examples
        --------
        >>> np.random.random_integers(5)
        4 # random
        >>> type(np.random.random_integers(5))
        <class 'numpy.int64'>
        >>> np.random.random_integers(5, size=(3,2))
        array([[5, 4], # random
               [3, 3],
               [4, 5]])

        Choose five random numbers from the set of five evenly-spaced
        numbers between 0 and 2.5, inclusive (*i.e.*, from the set
        :math:`{0, 5/8, 10/8, 15/8, 20/8}`):

        >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.
        array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ]) # random

        Roll two six sided dice 1000 times and sum the results:

        >>> d1 = np.random.random_integers(1, 6, 1000)
        >>> d2 = np.random.random_integers(1, 6, 1000)
        >>> dsums = d1 + d2

        Display results as a histogram:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, ignored = plt.hist(dsums, 11, density=True)
        >>> plt.show()

        
        random_sample(size=None)

        Return random floats in the half-open interval [0.0, 1.0).

        Results are from the "continuous uniform" distribution over the
        stated interval.  To sample :math:`Unif[a, b), b > a` multiply
        the output of `random_sample` by `(b-a)` and add `a`::

          (b - a) * random_sample() + a

        .. note::
            New code should use the `~numpy.random.Generator.random`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        out : float or ndarray of floats
            Array of random floats of shape `size` (unless ``size=None``, in which
            case a single float is returned).

        See Also
        --------
        random.Generator.random: which should be used for new code.

        Examples
        --------
        >>> np.random.random_sample()
        0.47108547995356098 # random
        >>> type(np.random.random_sample())
        <class 'float'>
        >>> np.random.random_sample((5,))
        array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428]) # random

        Three-by-two array of random numbers from [-5, 0):

        >>> 5 * np.random.random_sample((3, 2)) - 5
        array([[-3.99149989, -0.52338984], # random
               [-2.99091858, -0.79479508],
               [-1.23204345, -1.75224494]])

        
        rayleigh(scale=1.0, size=None)

        Draw samples from a Rayleigh distribution.

        The :math:`\chi` and Weibull distributions are generalizations of the
        Rayleigh.

        .. note::
            New code should use the `~numpy.random.Generator.rayleigh`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        scale : float or array_like of floats, optional
            Scale, also equals the mode. Must be non-negative. Default is 1.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``scale`` is a scalar.  Otherwise,
            ``np.array(scale).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Rayleigh distribution.

        See Also
        --------
        random.Generator.rayleigh: which should be used for new code.

        Notes
        -----
        The probability density function for the Rayleigh distribution is

        .. math:: P(x;scale) = \frac{x}{scale^2}e^{\frac{-x^2}{2 \cdotp scale^2}}

        The Rayleigh distribution would arise, for example, if the East
        and North components of the wind velocity had identical zero-mean
        Gaussian distributions.  Then the wind speed would have a Rayleigh
        distribution.

        References
        ----------
        .. [1] Brighton Webs Ltd., "Rayleigh Distribution,"
               https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp
        .. [2] Wikipedia, "Rayleigh distribution"
               https://en.wikipedia.org/wiki/Rayleigh_distribution

        Examples
        --------
        Draw values from the distribution and plot the histogram

        >>> from matplotlib.pyplot import hist
        >>> values = hist(np.random.rayleigh(3, 100000), bins=200, density=True)

        Wave heights tend to follow a Rayleigh distribution. If the mean wave
        height is 1 meter, what fraction of waves are likely to be larger than 3
        meters?

        >>> meanvalue = 1
        >>> modevalue = np.sqrt(2 / np.pi) * meanvalue
        >>> s = np.random.rayleigh(modevalue, 1000000)

        The percentage of waves larger than 3 meters is:

        >>> 100.*sum(s>3)/1000000.
        0.087300000000000003 # random

        
        seed(seed=None)

        Reseed a legacy MT19937 BitGenerator

        Notes
        -----
        This is a convenience, legacy function.

        The best practice is to **not** reseed a BitGenerator, rather to
        recreate a new one. This method is here for legacy reasons.
        This example demonstrates best practice.

        >>> from numpy.random import MT19937
        >>> from numpy.random import RandomState, SeedSequence
        >>> rs = RandomState(MT19937(SeedSequence(123456789)))
        # Later, you want to restart the stream
        >>> rs = RandomState(MT19937(SeedSequence(987654321)))
        set_state can only be used with legacy MT19937 state instances.
        shuffle(x)

        Modify a sequence in-place by shuffling its contents.

        This function only shuffles the array along the first axis of a
        multi-dimensional array. The order of sub-arrays is changed but
        their contents remains the same.

        .. note::
            New code should use the `~numpy.random.Generator.shuffle`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        x : ndarray or MutableSequence
            The array, list or mutable sequence to be shuffled.

        Returns
        -------
        None

        See Also
        --------
        random.Generator.shuffle: which should be used for new code.

        Examples
        --------
        >>> arr = np.arange(10)
        >>> np.random.shuffle(arr)
        >>> arr
        [1 7 5 2 9 4 3 6 0 8] # random

        Multi-dimensional arrays are only shuffled along the first axis:

        >>> arr = np.arange(9).reshape((3, 3))
        >>> np.random.shuffle(arr)
        >>> arr
        array([[3, 4, 5], # random
               [6, 7, 8],
               [0, 1, 2]])

        
        standard_cauchy(size=None)

        Draw samples from a standard Cauchy distribution with mode = 0.

        Also known as the Lorentz distribution.

        .. note::
            New code should use the
            `~numpy.random.Generator.standard_cauchy`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        samples : ndarray or scalar
            The drawn samples.

        See Also
        --------
        random.Generator.standard_cauchy: which should be used for new code.

        Notes
        -----
        The probability density function for the full Cauchy distribution is

        .. math:: P(x; x_0, \gamma) = \frac{1}{\pi \gamma \bigl[ 1+
                  (\frac{x-x_0}{\gamma})^2 \bigr] }

        and the Standard Cauchy distribution just sets :math:`x_0=0` and
        :math:`\gamma=1`

        The Cauchy distribution arises in the solution to the driven harmonic
        oscillator problem, and also describes spectral line broadening. It
        also describes the distribution of values at which a line tilted at
        a random angle will cut the x axis.

        When studying hypothesis tests that assume normality, seeing how the
        tests perform on data from a Cauchy distribution is a good indicator of
        their sensitivity to a heavy-tailed distribution, since the Cauchy looks
        very much like a Gaussian distribution, but with heavier tails.

        References
        ----------
        .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, "Cauchy
              Distribution",
              https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm
        .. [2] Weisstein, Eric W. "Cauchy Distribution." From MathWorld--A
              Wolfram Web Resource.
              https://mathworld.wolfram.com/CauchyDistribution.html
        .. [3] Wikipedia, "Cauchy distribution"
              https://en.wikipedia.org/wiki/Cauchy_distribution

        Examples
        --------
        Draw samples and plot the distribution:

        >>> import matplotlib.pyplot as plt
        >>> s = np.random.standard_cauchy(1000000)
        >>> s = s[(s>-25) & (s<25)]  # truncate distribution so it plots well
        >>> plt.hist(s, bins=100)
        >>> plt.show()

        
        standard_exponential(size=None)

        Draw samples from the standard exponential distribution.

        `standard_exponential` is identical to the exponential distribution
        with a scale parameter of 1.

        .. note::
            New code should use the
            `~numpy.random.Generator.standard_exponential`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        out : float or ndarray
            Drawn samples.

        See Also
        --------
        random.Generator.standard_exponential: which should be used for new code.

        Examples
        --------
        Output a 3x8000 array:

        >>> n = np.random.standard_exponential((3, 8000))

        
        standard_gamma(shape, size=None)

        Draw samples from a standard Gamma distribution.

        Samples are drawn from a Gamma distribution with specified parameters,
        shape (sometimes designated "k") and scale=1.

        .. note::
            New code should use the
            `~numpy.random.Generator.standard_gamma`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        shape : float or array_like of floats
            Parameter, must be non-negative.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``shape`` is a scalar.  Otherwise,
            ``np.array(shape).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized standard gamma distribution.

        See Also
        --------
        scipy.stats.gamma : probability density function, distribution or
            cumulative density function, etc.
        random.Generator.standard_gamma: which should be used for new code.

        Notes
        -----
        The probability density for the Gamma distribution is

        .. math:: p(x) = x^{k-1}\frac{e^{-x/\theta}}{\theta^k\Gamma(k)},

        where :math:`k` is the shape and :math:`\theta` the scale,
        and :math:`\Gamma` is the Gamma function.

        The Gamma distribution is often used to model the times to failure of
        electronic components, and arises naturally in processes for which the
        waiting times between Poisson distributed events are relevant.

        References
        ----------
        .. [1] Weisstein, Eric W. "Gamma Distribution." From MathWorld--A
               Wolfram Web Resource.
               https://mathworld.wolfram.com/GammaDistribution.html
        .. [2] Wikipedia, "Gamma distribution",
               https://en.wikipedia.org/wiki/Gamma_distribution

        Examples
        --------
        Draw samples from the distribution:

        >>> shape, scale = 2., 1. # mean and width
        >>> s = np.random.standard_gamma(shape, 1000000)

        Display the histogram of the samples, along with
        the probability density function:

        >>> import matplotlib.pyplot as plt
        >>> import scipy.special as sps  # doctest: +SKIP
        >>> count, bins, ignored = plt.hist(s, 50, density=True)
        >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/  # doctest: +SKIP
        ...                       (sps.gamma(shape) * scale**shape))
        >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP
        >>> plt.show()

        
        standard_normal(size=None)

        Draw samples from a standard Normal distribution (mean=0, stdev=1).

        .. note::
            New code should use the
            `~numpy.random.Generator.standard_normal`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        out : float or ndarray
            A floating-point array of shape ``size`` of drawn samples, or a
            single sample if ``size`` was not specified.

        See Also
        --------
        normal :
            Equivalent function with additional ``loc`` and ``scale`` arguments
            for setting the mean and standard deviation.
        random.Generator.standard_normal: which should be used for new code.

        Notes
        -----
        For random samples from the normal distribution with mean ``mu`` and
        standard deviation ``sigma``, use one of::

            mu + sigma * np.random.standard_normal(size=...)
            np.random.normal(mu, sigma, size=...)

        Examples
        --------
        >>> np.random.standard_normal()
        2.1923875335537315 #random

        >>> s = np.random.standard_normal(8000)
        >>> s
        array([ 0.6888893 ,  0.78096262, -0.89086505, ...,  0.49876311,  # random
               -0.38672696, -0.4685006 ])                                # random
        >>> s.shape
        (8000,)
        >>> s = np.random.standard_normal(size=(3, 4, 2))
        >>> s.shape
        (3, 4, 2)

        Two-by-four array of samples from the normal distribution with
        mean 3 and standard deviation 2.5:

        >>> 3 + 2.5 * np.random.standard_normal(size=(2, 4))
        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random
               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random

        
        standard_t(df, size=None)

        Draw samples from a standard Student's t distribution with `df` degrees
        of freedom.

        A special case of the hyperbolic distribution.  As `df` gets
        large, the result resembles that of the standard normal
        distribution (`standard_normal`).

        .. note::
            New code should use the `~numpy.random.Generator.standard_t`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        df : float or array_like of floats
            Degrees of freedom, must be > 0.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``df`` is a scalar.  Otherwise,
            ``np.array(df).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized standard Student's t distribution.

        See Also
        --------
        random.Generator.standard_t: which should be used for new code.

        Notes
        -----
        The probability density function for the t distribution is

        .. math:: P(x, df) = \frac{\Gamma(\frac{df+1}{2})}{\sqrt{\pi df}
                  \Gamma(\frac{df}{2})}\Bigl( 1+\frac{x^2}{df} \Bigr)^{-(df+1)/2}

        The t test is based on an assumption that the data come from a
        Normal distribution. The t test provides a way to test whether
        the sample mean (that is the mean calculated from the data) is
        a good estimate of the true mean.

        The derivation of the t-distribution was first published in
        1908 by William Gosset while working for the Guinness Brewery
        in Dublin. Due to proprietary issues, he had to publish under
        a pseudonym, and so he used the name Student.

        References
        ----------
        .. [1] Dalgaard, Peter, "Introductory Statistics With R",
               Springer, 2002.
        .. [2] Wikipedia, "Student's t-distribution"
               https://en.wikipedia.org/wiki/Student's_t-distribution

        Examples
        --------
        From Dalgaard page 83 [1]_, suppose the daily energy intake for 11
        women in kilojoules (kJ) is:

        >>> intake = np.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, \
        ...                    7515, 8230, 8770])

        Does their energy intake deviate systematically from the recommended
        value of 7725 kJ? Our null hypothesis will be the absence of deviation,
        and the alternate hypothesis will be the presence of an effect that could be
        either positive or negative, hence making our test 2-tailed.

        Because we are estimating the mean and we have N=11 values in our sample,
        we have N-1=10 degrees of freedom. We set our significance level to 95% and
        compute the t statistic using the empirical mean and empirical standard
        deviation of our intake. We use a ddof of 1 to base the computation of our
        empirical standard deviation on an unbiased estimate of the variance (note:
        the final estimate is not unbiased due to the concave nature of the square
        root).

        >>> np.mean(intake)
        6753.636363636364
        >>> intake.std(ddof=1)
        1142.1232221373727
        >>> t = (np.mean(intake)-7725)/(intake.std(ddof=1)/np.sqrt(len(intake)))
        >>> t
        -2.8207540608310198

        We draw 1000000 samples from Student's t distribution with the adequate
        degrees of freedom.

        >>> import matplotlib.pyplot as plt
        >>> s = np.random.standard_t(10, size=1000000)
        >>> h = plt.hist(s, bins=100, density=True)

        Does our t statistic land in one of the two critical regions found at
        both tails of the distribution?

        >>> np.sum(np.abs(t) < np.abs(s)) / float(len(s))
        0.018318  #random < 0.05, statistic is in critical region

        The probability value for this 2-tailed test is about 1.83%, which is
        lower than the 5% pre-determined significance threshold.

        Therefore, the probability of observing values as extreme as our intake
        conditionally on the null hypothesis being true is too low, and we reject
        the null hypothesis of no deviation.

        state dictionary is not valid.state must be a dict or a tuple.sum(pvals[:-1]) > 1.0sum(pvals[:-1].astype(np.float64)) > 1.0. The pvals array is cast to 64-bit floating point prior to checking the sum. Precision changes when casting may cause problems even if the sum of the original pvals is valid.
        tomaxint(size=None)

        Return a sample of uniformly distributed random integers in the interval
        [0, ``np.iinfo("long").max``].

        .. warning::
           This function uses the C-long dtype, which is 32bit on windows
           and otherwise 64bit on 64bit platforms (and 32bit on 32bit ones).
           Since NumPy 2.0, NumPy's default integer is 32bit on 32bit platforms
           and 64bit on 64bit platforms.

        Parameters
        ----------
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  Default is None, in which case a
            single value is returned.

        Returns
        -------
        out : ndarray
            Drawn samples, with shape `size`.

        See Also
        --------
        randint : Uniform sampling over a given half-open interval of integers.
        random_integers : Uniform sampling over a given closed interval of
            integers.

        Examples
        --------
        >>> rs = np.random.RandomState() # need a RandomState object
        >>> rs.tomaxint((2,2,2))
        array([[[1170048599, 1600360186], # random
                [ 739731006, 1947757578]],
               [[1871712945,  752307660],
                [1601631370, 1479324245]]])
        >>> rs.tomaxint((2,2,2)) < np.iinfo(np.int_).max
        array([[[ True,  True],
                [ True,  True]],
               [[ True,  True],
                [ True,  True]]])

        
        triangular(left, mode, right, size=None)

        Draw samples from the triangular distribution over the
        interval ``[left, right]``.

        The triangular distribution is a continuous probability
        distribution with lower limit left, peak at mode, and upper
        limit right. Unlike the other distributions, these parameters
        directly define the shape of the pdf.

        .. note::
            New code should use the `~numpy.random.Generator.triangular`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        left : float or array_like of floats
            Lower limit.
        mode : float or array_like of floats
            The value where the peak of the distribution occurs.
            The value must fulfill the condition ``left <= mode <= right``.
        right : float or array_like of floats
            Upper limit, must be larger than `left`.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``left``, ``mode``, and ``right``
            are all scalars.  Otherwise, ``np.broadcast(left, mode, right).size``
            samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized triangular distribution.

        See Also
        --------
        random.Generator.triangular: which should be used for new code.

        Notes
        -----
        The probability density function for the triangular distribution is

        .. math:: P(x;l, m, r) = \begin{cases}
                  \frac{2(x-l)}{(r-l)(m-l)}& \text{for $l \leq x \leq m$},\\
                  \frac{2(r-x)}{(r-l)(r-m)}& \text{for $m \leq x \leq r$},\\
                  0& \text{otherwise}.
                  \end{cases}

        The triangular distribution is often used in ill-defined
        problems where the underlying distribution is not known, but
        some knowledge of the limits and mode exists. Often it is used
        in simulations.

        References
        ----------
        .. [1] Wikipedia, "Triangular distribution"
               https://en.wikipedia.org/wiki/Triangular_distribution

        Examples
        --------
        Draw values from the distribution and plot the histogram:

        >>> import matplotlib.pyplot as plt
        >>> h = plt.hist(np.random.triangular(-3, 0, 8, 100000), bins=200,
        ...              density=True)
        >>> plt.show()

        <u4
        uniform(low=0.0, high=1.0, size=None)

        Draw samples from a uniform distribution.

        Samples are uniformly distributed over the half-open interval
        ``[low, high)`` (includes low, but excludes high).  In other words,
        any value within the given interval is equally likely to be drawn
        by `uniform`.

        .. note::
            New code should use the `~numpy.random.Generator.uniform`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        low : float or array_like of floats, optional
            Lower boundary of the output interval.  All values generated will be
            greater than or equal to low.  The default value is 0.
        high : float or array_like of floats
            Upper boundary of the output interval.  All values generated will be
            less than or equal to high.  The high limit may be included in the
            returned array of floats due to floating-point rounding in the
            equation ``low + (high-low) * random_sample()``.  The default value
            is 1.0.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``low`` and ``high`` are both scalars.
            Otherwise, ``np.broadcast(low, high).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized uniform distribution.

        See Also
        --------
        randint : Discrete uniform distribution, yielding integers.
        random_integers : Discrete uniform distribution over the closed
                          interval ``[low, high]``.
        random_sample : Floats uniformly distributed over ``[0, 1)``.
        random : Alias for `random_sample`.
        rand : Convenience function that accepts dimensions as input, e.g.,
               ``rand(2,2)`` would generate a 2-by-2 array of floats,
               uniformly distributed over ``[0, 1)``.
        random.Generator.uniform: which should be used for new code.

        Notes
        -----
        The probability density function of the uniform distribution is

        .. math:: p(x) = \frac{1}{b - a}

        anywhere within the interval ``[a, b)``, and zero elsewhere.

        When ``high`` == ``low``, values of ``low`` will be returned.
        If ``high`` < ``low``, the results are officially undefined
        and may eventually raise an error, i.e. do not rely on this
        function to behave when passed arguments satisfying that
        inequality condition. The ``high`` limit may be included in the
        returned array of floats due to floating-point rounding in the
        equation ``low + (high-low) * random_sample()``. For example:

        >>> x = np.float32(5*0.99999999)
        >>> x
        np.float32(5.0)


        Examples
        --------
        Draw samples from the distribution:

        >>> s = np.random.uniform(-1,0,1000)

        All values are within the given interval:

        >>> np.all(s >= -1)
        True
        >>> np.all(s < 0)
        True

        Display the histogram of the samples, along with the
        probability density function:

        >>> import matplotlib.pyplot as plt
        >>> count, bins, ignored = plt.hist(s, 15, density=True)
        >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')
        >>> plt.show()

        
        vonmises(mu, kappa, size=None)

        Draw samples from a von Mises distribution.

        Samples are drawn from a von Mises distribution with specified mode
        (mu) and concentration (kappa), on the interval [-pi, pi].

        The von Mises distribution (also known as the circular normal
        distribution) is a continuous probability distribution on the unit
        circle.  It may be thought of as the circular analogue of the normal
        distribution.

        .. note::
            New code should use the `~numpy.random.Generator.vonmises`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        mu : float or array_like of floats
            Mode ("center") of the distribution.
        kappa : float or array_like of floats
            Concentration of the distribution, has to be >=0.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``mu`` and ``kappa`` are both scalars.
            Otherwise, ``np.broadcast(mu, kappa).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized von Mises distribution.

        See Also
        --------
        scipy.stats.vonmises : probability density function, distribution, or
            cumulative density function, etc.
        random.Generator.vonmises: which should be used for new code.

        Notes
        -----
        The probability density for the von Mises distribution is

        .. math:: p(x) = \frac{e^{\kappa cos(x-\mu)}}{2\pi I_0(\kappa)},

        where :math:`\mu` is the mode and :math:`\kappa` the concentration,
        and :math:`I_0(\kappa)` is the modified Bessel function of order 0.

        The von Mises is named for Richard Edler von Mises, who was born in
        Austria-Hungary, in what is now the Ukraine.  He fled to the United
        States in 1939 and became a professor at Harvard.  He worked in
        probability theory, aerodynamics, fluid mechanics, and philosophy of
        science.

        References
        ----------
        .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). "Handbook of
               Mathematical Functions with Formulas, Graphs, and Mathematical
               Tables, 9th printing," New York: Dover, 1972.
        .. [2] von Mises, R., "Mathematical Theory of Probability
               and Statistics", New York: Academic Press, 1964.

        Examples
        --------
        Draw samples from the distribution:

        >>> mu, kappa = 0.0, 4.0 # mean and concentration
        >>> s = np.random.vonmises(mu, kappa, 1000)

        Display the histogram of the samples, along with
        the probability density function:

        >>> import matplotlib.pyplot as plt
        >>> from scipy.special import i0  # doctest: +SKIP
        >>> plt.hist(s, 50, density=True)
        >>> x = np.linspace(-np.pi, np.pi, num=51)
        >>> y = np.exp(kappa*np.cos(x-mu))/(2*np.pi*i0(kappa))  # doctest: +SKIP
        >>> plt.plot(x, y, linewidth=2, color='r')  # doctest: +SKIP
        >>> plt.show()

        
        wald(mean, scale, size=None)

        Draw samples from a Wald, or inverse Gaussian, distribution.

        As the scale approaches infinity, the distribution becomes more like a
        Gaussian. Some references claim that the Wald is an inverse Gaussian
        with mean equal to 1, but this is by no means universal.

        The inverse Gaussian distribution was first studied in relationship to
        Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian
        because there is an inverse relationship between the time to cover a
        unit distance and distance covered in unit time.

        .. note::
            New code should use the `~numpy.random.Generator.wald`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        mean : float or array_like of floats
            Distribution mean, must be > 0.
        scale : float or array_like of floats
            Scale parameter, must be > 0.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``mean`` and ``scale`` are both scalars.
            Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Wald distribution.

        See Also
        --------
        random.Generator.wald: which should be used for new code.

        Notes
        -----
        The probability density function for the Wald distribution is

        .. math:: P(x;mean,scale) = \sqrt{\frac{scale}{2\pi x^3}}e^
                                    \frac{-scale(x-mean)^2}{2\cdotp mean^2x}

        As noted above the inverse Gaussian distribution first arise
        from attempts to model Brownian motion. It is also a
        competitor to the Weibull for use in reliability modeling and
        modeling stock returns and interest rate processes.

        References
        ----------
        .. [1] Brighton Webs Ltd., Wald Distribution,
               https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp
        .. [2] Chhikara, Raj S., and Folks, J. Leroy, "The Inverse Gaussian
               Distribution: Theory : Methodology, and Applications", CRC Press,
               1988.
        .. [3] Wikipedia, "Inverse Gaussian distribution"
               https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution

        Examples
        --------
        Draw values from the distribution and plot the histogram:

        >>> import matplotlib.pyplot as plt
        >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)
        >>> plt.show()

        
        weibull(a, size=None)

        Draw samples from a Weibull distribution.

        Draw samples from a 1-parameter Weibull distribution with the given
        shape parameter `a`.

        .. math:: X = (-ln(U))^{1/a}

        Here, U is drawn from the uniform distribution over (0,1].

        The more common 2-parameter Weibull, including a scale parameter
        :math:`\lambda` is just :math:`X = \lambda(-ln(U))^{1/a}`.

        .. note::
            New code should use the `~numpy.random.Generator.weibull`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        a : float or array_like of floats
            Shape parameter of the distribution.  Must be nonnegative.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``a`` is a scalar.  Otherwise,
            ``np.array(a).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Weibull distribution.

        See Also
        --------
        scipy.stats.weibull_max
        scipy.stats.weibull_min
        scipy.stats.genextreme
        gumbel
        random.Generator.weibull: which should be used for new code.

        Notes
        -----
        The Weibull (or Type III asymptotic extreme value distribution
        for smallest values, SEV Type III, or Rosin-Rammler
        distribution) is one of a class of Generalized Extreme Value
        (GEV) distributions used in modeling extreme value problems.
        This class includes the Gumbel and Frechet distributions.

        The probability density for the Weibull distribution is

        .. math:: p(x) = \frac{a}
                         {\lambda}(\frac{x}{\lambda})^{a-1}e^{-(x/\lambda)^a},

        where :math:`a` is the shape and :math:`\lambda` the scale.

        The function has its peak (the mode) at
        :math:`\lambda(\frac{a-1}{a})^{1/a}`.

        When ``a = 1``, the Weibull distribution reduces to the exponential
        distribution.

        References
        ----------
        .. [1] Waloddi Weibull, Royal Technical University, Stockholm,
               1939 "A Statistical Theory Of The Strength Of Materials",
               Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939,
               Generalstabens Litografiska Anstalts Forlag, Stockholm.
        .. [2] Waloddi Weibull, "A Statistical Distribution Function of
               Wide Applicability", Journal Of Applied Mechanics ASME Paper
               1951.
        .. [3] Wikipedia, "Weibull distribution",
               https://en.wikipedia.org/wiki/Weibull_distribution

        Examples
        --------
        Draw samples from the distribution:

        >>> a = 5. # shape
        >>> s = np.random.weibull(a, 1000)

        Display the histogram of the samples, along with
        the probability density function:

        >>> import matplotlib.pyplot as plt
        >>> x = np.arange(1,100.)/50.
        >>> def weib(x,n,a):
        ...     return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)

        >>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000))
        >>> x = np.arange(1,100.)/50.
        >>> scale = count.max()/weib(x, 1., 5.).max()
        >>> plt.plot(x, weib(x, 1., 5.)*scale)
        >>> plt.show()

        x must be an integer or at least 1-dimensionalyou are shuffling a '
        zipf(a, size=None)

        Draw samples from a Zipf distribution.

        Samples are drawn from a Zipf distribution with specified parameter
        `a` > 1.

        The Zipf distribution (also known as the zeta distribution) is a
        discrete probability distribution that satisfies Zipf's law: the
        frequency of an item is inversely proportional to its rank in a
        frequency table.

        .. note::
            New code should use the `~numpy.random.Generator.zipf`
            method of a `~numpy.random.Generator` instance instead;
            please see the :ref:`random-quick-start`.

        Parameters
        ----------
        a : float or array_like of floats
            Distribution parameter. Must be greater than 1.
        size : int or tuple of ints, optional
            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then
            ``m * n * k`` samples are drawn.  If size is ``None`` (default),
            a single value is returned if ``a`` is a scalar. Otherwise,
            ``np.array(a).size`` samples are drawn.

        Returns
        -------
        out : ndarray or scalar
            Drawn samples from the parameterized Zipf distribution.

        See Also
        --------
        scipy.stats.zipf : probability density function, distribution, or
            cumulative density function, etc.
        random.Generator.zipf: which should be used for new code.

        Notes
        -----
        The probability mass function (PMF) for the Zipf distribution is

        .. math:: p(k) = \frac{k^{-a}}{\zeta(a)},

        for integers :math:`k \geq 1`, where :math:`\zeta` is the Riemann Zeta
        function.

        It is named for the American linguist George Kingsley Zipf, who noted
        that the frequency of any word in a sample of a language is inversely
        proportional to its rank in the frequency table.

        References
        ----------
        .. [1] Zipf, G. K., "Selected Studies of the Principle of Relative
               Frequency in Language," Cambridge, MA: Harvard Univ. Press,
               1932.

        Examples
        --------
        Draw samples from the distribution:

        >>> a = 4.0
        >>> n = 20000
        >>> s = np.random.zipf(a, n)

        Display the histogram of the samples, along with
        the expected histogram based on the probability
        density function:

        >>> import matplotlib.pyplot as plt
        >>> from scipy.special import zeta  # doctest: +SKIP

        `bincount` provides a fast histogram for small integers.

        >>> count = np.bincount(s)
        >>> k = np.arange(1, s.max() + 1)

        >>> plt.bar(k, count[1:], alpha=0.5, label='sample count')
        >>> plt.plot(k, n*(k**-a)/zeta(a), 'k.-', alpha=0.5,
        ...          label='expected count')   # doctest: +SKIP
        >>> plt.semilogy()
        >>> plt.grid(alpha=0.4)
        >>> plt.legend()
        >>> plt.title(f'Zipf sample, a={a}, size={n}')
        >>> plt.show()

        _MT19937MT19937__Pyx_PyDict_NextRefRandomStateRandomState.__getstate__RandomState.__reduce__RandomState.__setstate___RandomState__randomstate_ctorRandomState.betaRandomState.binomialRandomState.bytesRandomState.chisquareRandomState.choiceRandomState.dirichletRandomState.exponentialRandomState.fRandomState.gammaRandomState.geometricRandomState.get_stateRandomState.gumbelRandomState.hypergeometricRandomState.laplaceRandomState.logisticRandomState.lognormalRandomState.logseriesRandomState.multinomialRandomState.multivariate_normalRandomState.negative_binomialRandomState.noncentral_chisquareRandomState.noncentral_fRandomState.normalRandomState.paretoRandomState.permutationRandomState.poissonRandomState.powerRandomState.randRandomState.randintRandomState.randnRandomState.randomRandomState.random_integersRandomState.random_sampleRandomState.rayleighRandomState.seedRandomState.set_stateRandomState.shuffleRandomState.standard_cauchyRandomState.standard_exponentialRandomState.standard_gammaRandomState.standard_normalRandomState.standard_tRandomState.tomaxintRandomState.triangularRandomState.uniformRandomState.vonmisesRandomState.waldRandomState.weibullRandomState.zipfSequenceTX_aaccaddahighall__all__allclosealowalphaalpha_arralpha_dataanyarangeargsarrarrayasarrayastypeasyncio.coroutinesatolbbetabg_typebinomialbit_generator_bit_generatorbitgenboolbufbuf_ptrbytescapsulecastingcdfcheck_validchisquarechoice__class____class_getitem__cline_in_tracebackcntcollections.abccopycount_nonzerocovcumsumddfdfdendfnumdiricdirichletdotdouble_dpdtype_dtypeemptyempty_like_endpoint__enter__epsequal__exit__exponentialffinal_shapefinfoflagsflat_foundfleftfloat64fmodefoundfright__func__gammagaussgeometricgetget_bit_generatorget_state__getstate__greatergumbelhas_gausshigh_highhypergeometriciididxignore_inindexint16int32int64int8intpinvacc_is_coroutineis_scalarisfiniteisnanisnativeisscalarissubdtypeititemitemsitemsizejkkappakeykwargsllamlaplaceleftlegacy_legacy_seedinglengthlessless_equallnbadlngoodlnsampleloclocklogical_orlogisticlognormallogserieslonglow_low__main___maskedmay_share_memorymeanmethodmethod_namemnarrmnixmode__module__msg_mt19937mumultinmultinomialmultivariate_normalnn_arrn_uint32n_uniq__name__nbadndimnegative_binomialnewnewbyteorderngoodniniternoncnoncentral_chisquarenoncentral_fnormalnpnsamplenumpynumpy.linalgnumpy.random.mtrandobject_offsetoleftomodeonbadongoodonsampleoperatororightoutpp_arrp_sumparetoparrpermutation_picklepixpoisson_poisson_lam_maxpoppop_sizepospowerprodpsdpvals__pyx_vtable____qualname__raiserand_randrandintrandnrandomrandom_integersrandom_samplerandomsrandoms_data__randomstate_ctorranfrangeravelrayleighreduce__reduce__replaceresreshaperesult_typeretreturn_indexreversedrightrtolssamplescalesearchsortedseedselfset_bit_generator__set_name__set_statesetdefault__setstate__shapeshufflesidesigmasingletonsizesortsqrtststacklevelstandard_cauchystandard_exponentialstandard_gammastandard_normalstandard_tstatestridestridessubtractsumsvdsztaketemp__test__tobytestoltomaxinttotsizetriangulartype_uuint16uint32uint64uint8uniformuniform_samplesuniqueunique_indicesunsafevval_arrval_datavaluesvonmiseswaldwarnwarningsweibullwriteablexx_ptrzeroszipfPyObject *(PyObject *, PyArrayObject *) PyObject *(void *, bitgen_t *, PyObject *, PyObject *, PyObject *) PyObject *(void *, void *, PyObject *, PyObject *, PyArrayObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyArrayObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyArrayObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type)  PyObject *(void *, void *, PyObject *, PyObject *, int, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyObject *) PyObject *(void *, void *, PyObject *, PyObject *, int, int, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type, PyObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type) double (double *, npy_intp) int (PyArrayObject *, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type) int (double, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type) int (int64_t, PyObject *, __pyx_t_5numpy_6random_7_common_constraint_type) validate_output_shape double_fill cont_broadcast_3 discrete_broadcast_iii cont disc kahan_sum check_array_constraint __pyx_fuse_0check_constraint __pyx_fuse_1check_constraintPyObject *(PyObject *, PyObject *, PyObject *, int, int, bitgen_t *, PyObject *)         _rand_bool _rand_int16 _rand_int32 _rand_int64 _rand_int8 _rand_uint16 _rand_uint32 _rand_uint64 _rand_uint8double  uint64_t LEGACY_POISSON_LAM_MAX POISSON_LAM_MAX MAXSIZE0 5#1P 	t1A-Qd-vTPQ[TE[PQ(1` 	51E1(1! E1%QfAQt81EAV2SV6+1` 	CqN"2!]#Q!Q2T"Kq1*AQ[Qa51QqqQfCq&!,a;m1AAM!"BaaEaqAQau$9!4q:DAQ$b2Q!1EaqARrhar3bBbq1V 	/qq/qq0/]!7%}A\a{Z[$AQ%Qa$AQvRqjvRqjvSj4q,AT6WAt1t1 Kq2T"HAWA*AQ2T"HAWA*AQ2T"F!7!*AQq!4AT6Q#4q#4q$D#1~ 	t1A^1DV4wa&&&!1^ 	t1A^1DV4wa9A9A[+1n 	d!1.at=d'QTTUe1e1A}AQ1r 	d!1(ZvT1e1AA}AQ#1r 	t1AZqMt7!9A9A[22DA !N 	! 	rqbaq51AqwaAQA3at83a*AQCq83cSas#Saq*AQ4vQcCvQa*AQ 	d!57!4vQaD XRs$fAQ" 	c1	SS<s!|3gTSj"IQbAQc3d%uEat1<s!E!*ABd!3bQbF"AQ	%qq2!b 	t1A2!4}F$gUVa(![2 'q4A^ 	t1A*!4}F$gQ9A9A("5Q( 	4z$/q)1A/qQ5QD 	~-Q]#U*=T]!6A)1Am1AkaqavYa2T!5#SBa 
!9A+Qe:QWCqTBaq a*AQ51QqqQfCq6'rAyQa}AQQU!3e7!U!1)!4zQd!9EQTTUUYYZ!q
 5b8L 	0./qa>!2!;nA]!85Ql-qP]]^YaIQywbbj$aq6at:V4wVYYZyha!A=2T"E"D*AQ$AQ&C1D
RXX\\]%-Ya%,HA%/{!}AQAN 	3avS4~Q4~Qe1AP 	t1A^1DV4wauAQ[*AX 	d!1+1D
&G3aqAA}AQA~ 	3avS4'q4'qQA+81H 	Bhaq1F#Q86!5jy2T5s!jfCq*AQqaqy2T5s!j2WA1A2U!2V1Biqz%q2[*AavRuARvQawa/q_$7t1+]!1qcjqcjIQe1rqjrG1Bbjs!64rj 	EA4qA2U!7&!A1 	1rawas"A"$nAQca'8Q bWARwhad(!3jQuBajbjr2^1Bb2Q*AQAU!&bU&gRqE%rwb*AR{!"G1A3b#]!3e1('%}A"%q#U!1awgRs)1cad,ay!9A:T1G1#U!1 	1F#Q14zSc "F!4vQaqaq1qAJaqA\ ##Qa 	:Qe:TQfA*AQ4q5	QfCrQa nAQQhaqqa
 "F!:V2QaqQ 9CqQc)>hgQQc87!qQqcqc4qfCrQ &["Kq#QQE%q1qZqrAqqQe1AQQe1 t:QcQ+1D1
 "AQE%q1qZqQd!1E!4qA^ 	:Qd'"G1CvR|1Cr1b3fBa*AQ 	3fCqr"!5baq1 	bq6$fBaHAQs!1A< 	&WBcBb 	t81C|5""HG1F("BaAoQ 	$D(<D
!7RSAt:QgQAd 	51Q*!1D,bavV2Q|=m1AEaqWAAU"5Qat1qAh 	:QgQwfCxwajt:QhgQiq5Cq*AQ'uAQ uATQa3awbae1Aa{%qBd!9ARt1M9A=y*JaB 	~.awoQ/qq]!6m1Ja#1A$AQF"At2Yaqm1A4q)$jd'd!t1Tr!7!! 	31A4rQb	!-qt1A%Qd*F$gQ$aDQJaN 	t1A_ATfDqQ9AQJan 	t1A_AT6WA9A[(L 	t1A2!4}F$gUV&&& 
!N 	t1A)$m6WA9AQQ!N 	t1A'qMt7!aQ[QD 	t1A_ATfDquAQ[%QP 	t1A]!4}F$gQ(!9A[)X 	t1A,ATfDq9AQQ"!Z 	t1A(]&G1at1t1ZqP 	t1A&at:V4wa9AQ[+Zqr 	t1A%Qd*F$gQ9A[aF 	t1A%Qd-vTuAQ[a^ 	t1A]!4}F$gQuAuA[ b 	d!1&at:V4wce1AA}AQ!f 	{!1:!4ztSZZ[;jb 	t1A&at:V4wa9A[ n 	d!1-Qd*F$gSPQe1AA}AQqP 	T2Qs*DE!45Qad+Qa{$k7$d*AT):!*A 	1Ba)1HAXRqa~Rqq <qf 	511!6*F'F!14vQE! )*V= 	Aa7#Rq+Qe6y1D
RVVWCr+Qe6y1D
RVVWCr+Qe6y1D
RVVWCr*AU&i{!4zQUUVCr,auF&	ATSWWXCr,auF&	ATSWWXCr,auF&	ATSWWXCr+Qe6y1D
RVVWCr*AU&i{!4zQUUV)1?r55V3e3fCqrqG3auAQq'qh 	t1A&at:V4waa9A[[
!^ 	t1A'qMt7!(!9A[! 	t>%q"!z 	!qa 	/q_AJfM'A/q]!JfM'A4q"!7%q"!7%quG1,bavRq-QgQ,bar1M!))7!!"HAWAEaq;&=Qd#Qa++B!4s!15Qd#Qa.aqJe1/0A-Qa1aqae1e151Qv31AT545T,bavRqQazaqU!1AU"8$jQ9:$aq	$ z%(uE!$auA_IWAU! l       s   t   r   e   a   m   l   i   t   
   $       s   t   r   e   a   m   l   i   t       h   e   l   l   o   
   `   `   `   
   
   I   f       t   h   i   s       o   p   e   n   s       o   u   r       s   w   e   e   t       _   S   t   r   e   a   m   l   i   t       H   e   l   l   o   _       a   p   p       i   n       y   o   u   r       b   r   o   w   s   e   r   ,       y   o   u   '   r   e       a   l   l       s   e   t   !       I   f       n   o   t   ,       h   e   a   d       o   v   e   r       t   o       [   o   u   r       d   o   c   s   ]   (   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   g   e   t   -   s   t   a   r   t   e   d   )       f   o   r       s   p   e   c   i   f   i   c       i   n   s   t   a   l   l   s   .   
   
   T   h   e       a   p   p       f   e   a   t   u   r   e   s       a       b   u   n   c   h       o   f       e   x   a   m   p   l   e   s       o   f       w   h   a   t       y   o   u       c   a   n       d   o       w   i   t   h       S   t   r   e   a   m   l   i   t   .       J   u   m   p       t   o       t   h   e       [   q   u   i   c   k   s   t   a   r   t   ]   (   #   q   u   i   c   k   s   t   a   r   t   )       s   e   c   t   i   o   n       t   o       u   n   d   e   r   s   t   a   n   d       h   o   w       t   h   a   t       a   l   l       w   o   r   k   s   .   
   
   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   7   9   3   6   4   8   7   -   1   0   1   7   7   8   4   e   -   6   8   e   c   -   4   e   0   d   -   a   7   f   6   -   6   b   9   7   5   2   5   d   d   f   8   8   .   g   i   f   "       a   l   t   =   "   S   t   r   e   a   m   l   i   t       H   e   l   l   o   "       w   i   d   t   h   =   5   0   0       h   r   e   f   =   "   n   o   n   e   "   >   <   /   i   m   g   >   
   
   #   #       Q   u   i   c   k   s   t   a   r   t   
   
   #   #   #       A       l   i   t   t   l   e       e   x   a   m   p   l   e   
   
   C   r   e   a   t   e       a       n   e   w       f   i   l   e       n   a   m   e   d       `   s   t   r   e   a   m   l   i   t   _   a   p   p   .   p   y   `       i   n       y   o   u   r       p   r   o   j   e   c   t       d   i   r   e   c   t   o   r   y       w   i   t   h       t   h   e       f   o   l   l   o   w   i   n   g       c   o   d   e   :   
   `   `   `   p   y   t   h   o   n   
   i   m   p   o   r   t       s   t   r   e   a   m   l   i   t       a   s       s   t   
   x       =       s   t   .   s   l   i   d   e   r   (   "   S   e   l   e   c   t       a       v   a   l   u   e   "   )   
   s   t   .   w   r   i   t   e   (   x   ,       "   s   q   u   a   r   e   d       i   s   "   ,       x       *       x   )   
   `   `   `   
   
   N   o   w       r   u   n       i   t       t   o       o   p   e   n       t   h   e       a   p   p   !   
   `   `   `   
   $       s   t   r   e   a   m   l   i   t       r   u   n       s   t   r   e   a   m   l   i   t   _   a   p   p   .   p   y   
   `   `   `   
   
   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   5   1   7   2   9   1   5   -   c   f   0   8   7   c   5   6   -   e   7   a   e   -   4   4   9   a   -   8   3   a   4   -   b   5   f   a   0   3   2   8   d   9   5   4   .   g   i   f   "       w   i   d   t   h   =   3   0   0       a   l   t   =   "   L   i   t   t   l   e       e   x   a   m   p   l   e   "   >   <   /   i   m   g   >   
   
   #   #   #       G   i   v   e       m   e       m   o   r   e   !   
   
   S   t   r   e   a   m   l   i   t       c   o   m   e   s       i   n       w   i   t   h       [   a       t   o   n       o   f       a   d   d   i   t   i   o   n   a   l       p   o   w   e   r   f   u   l       e   l   e   m   e   n   t   s   ]   (   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   a   p   i   -   r   e   f   e   r   e   n   c   e   )       t   o       s   p   i   c   e       u   p       y   o   u   r       d   a   t   a       a   p   p   s       a   n   d       d   e   l   i   g   h   t       y   o   u   r       v   i   e   w   e   r   s   .       S   o   m   e       e   x   a   m   p   l   e   s   :   
   
   <   t   a   b   l   e       b   o   r   d   e   r   =   "   0   "   >   
           <   t   r   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   a   p   i   -   r   e   f   e   r   e   n   c   e   /   w   i   d   g   e   t   s   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   7   9   3   6   0   9   9   -   1   2   c   1   6   f   8   c   -   7   f   e   4   -   4   4   b   1   -   8   8   9   a   -   1   a   c   9   e   e   6   a   1   b   4   4   .   p   n   g   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   a   p   i   -   r   e   f   e   r   e   n   c   e   /   d   a   t   a   /   s   t   .   d   a   t   a   f   r   a   m   e   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   5   1   1   0   0   6   4   -   5   e   b   4   e   2   9   4   -   8   f   3   0   -   4   9   3   3   -   9   5   6   3   -   0   2   7   5   2   3   0   e   5   2   b   5   .   g   i   f   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   a   p   i   -   r   e   f   e   r   e   n   c   e   /   c   h   a   r   t   s   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   5   1   7   4   4   7   2   -   b   c   a   8   a   0   d   7   -   c   f   4   b   -   4   2   6   8   -   9   c   3   b   -   8   c   0   3   d   a   d   5   0   b   c   d   .   g   i   f   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   a   p   i   -   r   e   f   e   r   e   n   c   e   /   l   a   y   o   u   t   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   7   9   3   6   1   4   9   -   a   3   5   c   3   5   b   e   -   0   d   9   6   -   4   c   6   3   -   8   c   6   a   -   1   c   4   b   5   2   a   a   8   f   6   0   .   p   n   g   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   d   o   c   s   .   s   t   r   e   a   m   l   i   t   .   i   o   /   d   e   v   e   l   o   p   /   c   o   n   c   e   p   t   s   /   m   u   l   t   i   p   a   g   e   -   a   p   p   s   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   5   1   7   3   8   8   3   -   e   a   e   0   d   e   6   9   -   7   c   1   d   -   4   d   7   8   -   9   7   d   0   -   3   b   c   1   a   b   8   6   5   e   5   b   .   g   i   f   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
                   <   t   d   >   
                           <   a       t   a   r   g   e   t   =   "   _   b   l   a   n   k   "       h   r   e   f   =   "   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   g   a   l   l   e   r   y   "   >   
                                   <   i   m   g       s   r   c   =   "   h   t   t   p   s   :   /   /   u   s   e   r   -   i   m   a   g   e   s   .   g   i   t   h   u   b   u   s   e   r   c   o   n   t   e   n   t   .   c   o   m   /   7   1   6   4   8   6   4   /   2   1   5   1   0   9   2   2   9   -   6   a   e   9   1   1   1   f   -   e   5   c   1   -   4   f   0   b   -   b   3   a   2   -   8   7   a   7   9   2   6   8   c   c   c   9   .   g   i   f   "       s   t   y   l   e   =   "   m   a   x   -   h   e   i   g   h   t   :   1   5   0   p   x   ;       w   i   d   t   h   :   a   u   t   o   ;       d   i   s   p   l   a   y   :   b   l   o   c   k   ;   "   >   
                           <   /   a   >   
                   <   /   t   d   >   
           <   /   t   r   >   
           <   t   r   >   
                   <   t   d   >   I   n   p   u   t       w   i   d   g   e   t   s   <   /   t   d   >   
                   <   t   d   >   D   a   t   a   f   r   a   m   e   s   <   /   t   d   >   
                   <   t   d   >   C   h   a   r   t   s   <   /   t   d   >   
                   <   t   d   >   L   a   y   o   u   t   <   /   t   d   >   
                   <   t   d   >   M   u   l   t   i   -   p   a   g   e       a   p   p   s   <   /   t   d   >   
                   <   t   d   >   F   u   n   <   /   t   d   >   
           <   /   t   r   >   
   <   /   t   a   b   l   e   >   
   
   
   O   u   r       v   i   b   r   a   n   t       c   r   e   a   t   o   r   s       c   o   m   m   u   n   i   t   y       a   l   s   o       e   x   t   e   n   d   s       S   t   r   e   a   m   l   i   t       c   a   p   a   b   i   l   i   t   i   e   s       u   s   i   n   g               [   S   t   r   e   a   m   l   i   t       C   o   m   p   o   n   e   n   t   s   ]   (   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   c   o   m   p   o   n   e   n   t   s   )   .   
   
   #   #       G   e   t       i   n   s   p   i   r   e   d   
   
   T   h   e   r   e   '   s       s   o       m   u   c   h       y   o   u       c   a   n       b   u   i   l   d       w   i   t   h       S   t   r   e   a   m   l   i   t   :   
   -              [   L   L   M   s       &       c   h   a   t   b   o   t       a   p   p   s   ]   (   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   g   a   l   l   e   r   y   ?   c   a   t   e   g   o   r   y   =   l   l   m   s   )   
   -              [   S   c   i   e   n   c   e       &       t   e   c   h   n   o   l   o   g   y       a   p   p   s   ]   (   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   g   a   l   l   e   r   y   ?   c   a   t   e   g   o   r   y   =   s   c   i   e   n   c   e   -   t   e   c   h   n   o   l   o   g   y   )   
   -              [   N   L   P       &       l   a   n   g   u   a   g   e       a   p   p   s   ]   (   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   g   a   l   l   e   r   y   ?   c   a   t   e   g   o   r   y   =   n   l   p   -   l   a   n   g   u   a   g   e   )   
   -              [   F   i   n   a   n   c   e       &       b   u   s   i   n   e   s   s       a   p   p   s   ]   (   h   t   t   p   s   :   /   /   s   t   r   e   a   m   l   i   t   .   i   o   /   g   a   l   l   e   r   y   ?   c   a   t   e   g   o   r   y   =   f   i   n   a   n   c   e   -   b   u   s           U    :      
    fi/                       d Z ddlmZ ddlmZmZ ddlZddlZddl	m
Z
mZ ddlmZ ddlmZ ddlmZ dd	lmZ dd
lmZ ddlmZmZ ddlmZ ddlmZ ddlmZmZ ddl m!c m"Z# ddl$m%Z% ddl&m'Z' ddl(m)Z) ddl*m+Z+m,Z,m-Z- ddl.m/Z/ ddl0m1Z1 erddl2m3Z3m4Z4 ddl5m6Z6m7Z7m8Z8m9Z9 ddl:m;Z;  G d d      Z<e G d d             Z=	 	 	 	 	 	 	 d	 	 	 	 	 	 	 	 	 	 	 	 	 d dZ>d!dZ?d"dZ@y)#z]
Provide user facing operators for doing the split part of the
split-apply-combine paradigm.
    )annotations)TYPE_CHECKINGfinalN)using_copy_on_writewarn_copy_on_write)lib)OutOfBoundsDatetime)InvalidIndexError)cache_readonly)find_stack_level)is_list_like	is_scalar)CategoricalDtype)
algorithms)CategoricalExtensionArray)	DataFrame)ops)recode_for_groupby)CategoricalIndexIndex
MultiIndex)Series)pprint_thing)HashableIterator)	ArrayLikeAxisNDFrameTnpt)NDFramec                  ^    e Zd ZU dZded<   ded<   ded<   ded<   dZd	ed
<    fdZdddej                  ddf	 	 	 	 	 	 	 ddZ		 d	 	 	 	 	 ddZ
	 ddd	 	 	 	 	 	 	 ddZeedd              Zeed               Zeed               Zeed               Zeed               Zedd       Z xZS ) Groupera  
    A Grouper allows the user to specify a groupby instruction for an object.

    This specification will select a column via the key parameter, or if the
    level and/or axis parameters are given, a level of the index of the target
    object.

    If `axis` and/or `level` are passed as keywords to both `Grouper` and
    `groupby`, the values passed to `Grouper` take precedence.

    Parameters
    ----------
    key : str, defaults to None
        Groupby key, which selects the grouping column of the target.
    level : name/number, defaults to None
        The level for the target index.
    freq : str / frequency object, defaults to None
        This will groupby the specified frequency if the target selection
        (via key or level) is a datetime-like object. For full specification
        of available frequencies, please see `here
        <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_.
    axis : str, int, defaults to 0
        Number/name of the axis.
    sort : bool, default to False
        Whether to sort the resulting labels.
    closed : {'left' or 'right'}
        Closed end of interval. Only when `freq` parameter is passed.
    label : {'left' or 'right'}
        Interval boundary to use for labeling.
        Only when `freq` parameter is passed.
    convention : {'start', 'end', 'e', 's'}
        If grouper is PeriodIndex and `freq` parameter is passed.

    origin : Timestamp or str, default 'start_day'
        The timestamp on which to adjust the grouping. The timezone of origin must
        match the timezone of the index.
        If string, must be one of the following:

        - 'epoch': `origin` is 1970-01-01
        - 'start': `origin` is the first value of the timeseries
        - 'start_day': `origin` is the first day at midnight of the timeseries

        - 'end': `origin` is the last value of the timeseries
        - 'end_day': `origin` is the ceiling midnight of the last day

        .. versionadded:: 1.3.0

    offset : Timedelta or str, default is None
        An offset timedelta added to the origin.

    dropna : bool, default True
        If True, and if group keys contain NA values, NA values together with
        row/column will be dropped. If False, NA values will also be treated as
        the key in groups.

    Returns
    -------
    Grouper or pandas.api.typing.TimeGrouper
        A TimeGrouper is returned if ``freq`` is not ``None``. Otherwise, a Grouper
        is returned.

    Examples
    --------
    ``df.groupby(pd.Grouper(key="Animal"))`` is equivalent to ``df.groupby('Animal')``

    >>> df = pd.DataFrame(
    ...     {
    ...         "Animal": ["Falcon", "Parrot", "Falcon", "Falcon", "Parrot"],
    ...         "Speed": [100, 5, 200, 300, 15],
    ...     }
    ... )
    >>> df
       Animal  Speed
    0  Falcon    100
    1  Parrot      5
    2  Falcon    200
    3  Falcon    300
    4  Parrot     15
    >>> df.groupby(pd.Grouper(key="Animal")).mean()
            Speed
    Animal
    Falcon  200.0
    Parrot   10.0

    Specify a resample operation on the column 'Publish date'

    >>> df = pd.DataFrame(
    ...    {
    ...        "Publish date": [
    ...             pd.Timestamp("2000-01-02"),
    ...             pd.Timestamp("2000-01-02"),
    ...             pd.Timestamp("2000-01-09"),
    ...             pd.Timestamp("2000-01-16")
    ...         ],
    ...         "ID": [0, 1, 2, 3],
    ...         "Price": [10, 20, 30, 40]
    ...     }
    ... )
    >>> df
      Publish date  ID  Price
    0   2000-01-02   0     10
    1   2000-01-02   1     20
    2   2000-01-09   2     30
    3   2000-01-16   3     40
    >>> df.groupby(pd.Grouper(key="Publish date", freq="1W")).mean()
                   ID  Price
    Publish date
    2000-01-02    0.5   15.0
    2000-01-09    2.0   30.0
    2000-01-16    3.0   40.0

    If you want to adjust the start of the bins based on a fixed timestamp:

    >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'
    >>> rng = pd.date_range(start, end, freq='7min')
    >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
    >>> ts
    2000-10-01 23:30:00     0
    2000-10-01 23:37:00     3
    2000-10-01 23:44:00     6
    2000-10-01 23:51:00     9
    2000-10-01 23:58:00    12
    2000-10-02 00:05:00    15
    2000-10-02 00:12:00    18
    2000-10-02 00:19:00    21
    2000-10-02 00:26:00    24
    Freq: 7min, dtype: int64

    >>> ts.groupby(pd.Grouper(freq='17min')).sum()
    2000-10-01 23:14:00     0
    2000-10-01 23:31:00     9
    2000-10-01 23:48:00    21
    2000-10-02 00:05:00    54
    2000-10-02 00:22:00    24
    Freq: 17min, dtype: int64

    >>> ts.groupby(pd.Grouper(freq='17min', origin='epoch')).sum()
    2000-10-01 23:18:00     0
    2000-10-01 23:35:00    18
    2000-10-01 23:52:00    27
    2000-10-02 00:09:00    39
    2000-10-02 00:26:00    24
    Freq: 17min, dtype: int64

    >>> ts.groupby(pd.Grouper(freq='17min', origin='2000-01-01')).sum()
    2000-10-01 23:24:00     3
    2000-10-01 23:41:00    15
    2000-10-01 23:58:00    45
    2000-10-02 00:15:00    45
    Freq: 17min, dtype: int64

    If you want to adjust the start of the bins with an `offset` Timedelta, the two
    following lines are equivalent:

    >>> ts.groupby(pd.Grouper(freq='17min', origin='start')).sum()
    2000-10-01 23:30:00     9
    2000-10-01 23:47:00    21
    2000-10-02 00:04:00    54
    2000-10-02 00:21:00    24
    Freq: 17min, dtype: int64

    >>> ts.groupby(pd.Grouper(freq='17min', offset='23h30min')).sum()
    2000-10-01 23:30:00     9
    2000-10-01 23:47:00    21
    2000-10-02 00:04:00    54
    2000-10-02 00:21:00    24
    Freq: 17min, dtype: int64

    To replace the use of the deprecated `base` argument, you can now use `offset`,
    in this example it is equivalent to have `base=2`:

    >>> ts.groupby(pd.Grouper(freq='17min', offset='2min')).sum()
    2000-10-01 23:16:00     0
    2000-10-01 23:33:00     9
    2000-10-01 23:50:00    36
    2000-10-02 00:07:00    39
    2000-10-02 00:24:00    24
    Freq: 17min, dtype: int64
    boolsortdropnaIndex | None
_gpr_index_grouper)keylevelfreqaxisr%   r&   ztuple[str, ...]_attributesc                T    |j                  d      ddlm} |} t        |   |       S )Nr,   r   )TimeGrouper)getpandas.core.resampler0   super__new__)clsargskwargsr0   	__class__s       {/Users/abdullahkazmi/Downloads/GenAi-Session-RAG-Pipeline/.venv/lib/python3.12/site-packages/pandas/core/groupby/grouper.pyr4   zGrouper.__new__   s)    ::f)8Cws##    NFTc                v   t        |       t        u r9|t        j                  ur%t	        j
                  dt        t                      nd}|t        j                  u rd}|| _        || _	        || _
        || _        || _        || _        d | _        d | _        d | _        d | _        d | _        d | _        d | _        y )Nz~Grouper axis keyword is deprecated and will be removed in a future version. To group on axis=1, use obj.T.groupby(...) instead
stacklevelr   )typer#   r   
no_defaultwarningswarnFutureWarningr   r*   r+   r,   r-   r%   r&   _grouper_deprecated_indexer_deprecated_obj_deprecatedr(   binnerr)   _indexer)selfr*   r+   r,   r-   r%   r&   s          r9   __init__zGrouper.__init__  s     : 3>>) "/1 3>>!D
			#' @D #59r:   c           	         | j                  |      \  }}}t        || j                  g| j                  | j                  | j
                  || j                        \  }}}|| _        ||fS )z
        Parameters
        ----------
        obj : Series or DataFrame
        validate : bool, default True
            if True, validate the grouper

        Returns
        -------
        a tuple of grouper, obj (possibly sorted)
        )r-   r+   r%   validater&   )_set_grouperget_grouperr*   r-   r+   r%   r&   rC   )rH   objrK   _groupers        r9   _get_grouperzGrouper._get_grouper,  si     %%c*	Q%XXJ**;;
C $+ |r:   )	gpr_indexc                  |J | j                   | j                  t        d      | j                  || _        | j                  | _        | j                   | j                   }t        |dd      |k(  rt        |t              r| j                  J | j
                  Q| j
                  j                         }| j                  j                  |      }|j                  |j                        }n| j                  j                  |j                        }n||j                  vrt        d| d      t        ||   |      }n|j                  | j                         }| j                  v| j                  }t        |t"              r;|j%                  |      }t        |j'                  |      |j(                  |         }n|d|j*                  fvrt        d| d	      d}	| j,                  s|r^|j.                  sR|j0                  j                  d
d      x}	| _        |j                  |	      }|j                  |	| j                         }|| _        || _        |||	fS )a  
        given an object and the specifications, setup the internal grouper
        for this particular specification

        Parameters
        ----------
        obj : Series or DataFrame
        sort : bool, default False
            whether the resulting grouper should be sorted
        gpr_index : Index or None, default None

        Returns
        -------
        NDFrame
        Index
        np.ndarray[np.intp] | None
        Nz2The Grouper cannot specify both a key and a level!namezThe grouper name z is not foundrT   r   z
The level z is not valid	mergesortfirst)kindna_positionr-   )r*   r+   
ValueErrorr)   rD   rG   getattr
isinstancer   argsorttakeindex
_info_axisKeyErrorr   	_get_axisr-   r   _get_level_number_get_level_valuesnamesrT   r%   is_monotonic_increasingarrayrE   r(   )
rH   rN   r%   rR   r*   reverse_indexerunsorted_axaxr+   indexers
             r9   rL   zGrouper._set_grouperK  s*   ( 88DJJ$:QRR == %DM 44DM 88((Cy&$/36:c6;R
 }}000==,&*mm&;&;&=O"&--"4"4_"EK$))#))4B++CII6Bcnn,"%6se=#IJJ3s8#. tyy)Bzz%

 b*-007Er33E:%QB QL0(:eWM)JKK 04IIr'A'A 241A1A g 2B 2 Gd. !B((7(3C  #Br:   c                    t        j                  t        |       j                   dt        t                      | j                  }|t        d      |S )NzS.ax is deprecated and will be removed in a future version. Use Resampler.ax insteadr<   z1_set_grouper must be called before ax is accessed)r@   rA   r>   __name__rB   r   r(   r[   )rH   r`   s     r9   rk   z
Grouper.ax  sT     	Dz""# $7 7')		
 =PQQr:   c                    t        j                  t        |       j                   dt        t                      | j                  S )Nz^.indexer is deprecated and will be removed in a future version. Use Resampler.indexer instead.r<   )r@   rA   r>   rn   rB   r   rD   rH   s    r9   rl   zGrouper.indexer  sC     	Dz""# $B B')		
 '''r:   c                    t        j                  t        |       j                   dt        t                      | j                  S )NzX.obj is deprecated and will be removed in a future version. Use GroupBy.indexer instead.r<   )r@   rA   r>   rn   rB   r   rE   rp   s    r9   rN   zGrouper.obj  sC    
 	Dz""# $@ @')		
 ###r:   c                    t        j                  t        |       j                   dt        t                      | j                  S )Nz\.grouper is deprecated and will be removed in a future version. Use GroupBy.grouper instead.r<   )r@   rA   r>   rn   rB   r   rC   rp   s    r9   rP   zGrouper.grouper  sC     	Dz""# $@ @')		
 '''r:   c                    t        j                  t        |       j                   dt        t                      | j                  j                  S )NzZ.groups is deprecated and will be removed in a future version. Use GroupBy.groups instead.r<   )r@   rA   r>   rn   rB   r   rC   groupsrp   s    r9   rt   zGrouper.groups  sG     	Dz""# $? ?')		
 ''...r:   c                      fd j                   D        }dj                  |      }t               j                  }| d| dS )Nc           	   3  j   K   | ]*  }t        |      | dt        t        |              , y w)N=)r\   repr).0	attr_namerH   s     r9   	<genexpr>z#Grouper.__repr__.<locals>.<genexpr>  s>      
-	tY'3 k4i 89:;-s   03z, ())r.   joinr>   rn   )rH   
attrs_listattrscls_names   `   r9   __repr__zGrouper.__repr__  sJ    
!--


 		*%:&&1UG1%%r:   )r-   zAxis | lib.NoDefaultr%   r$   r&   r$   returnNone)T)rN   r   rK   r$   r   z tuple[ops.BaseGrouper, NDFrameT])F)rN   r   r%   r$   rR   r'   r   z3tuple[NDFrameT, Index, npt.NDArray[np.intp] | None]r   r   r   str)rn   
__module____qualname____doc____annotations__r.   r4   r   r?   rI   rQ   rL   r   propertyrk   rl   rN   rP   rt   r   __classcell__)r8   s   @r9   r#   r#   B   ss   rh JL#UKU$ %(^^%:
 #%: %: %: 
%:P /3'+	)@ +0R NRR R #'R ?KR 	<R h 
  
 (  ( 	$  	$ (  ( /  / & &r:   r#   c                     e Zd ZU dZdZded<   ded<   ded<   d	ed
<   	 	 	 	 	 	 	 	 d	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 ddZddZddZe	d d       Z
e	d!d       Ze	d"d       Zed#d       Ze	d$d       Zed%d       Ze	d&d       Zed&d       Ze	d'd       Zed'd       Ze	d'd       Zed'd       Ze	d(d       Ze	d)d       Zy)*Groupingah  
    Holds the grouping information for a single key

    Parameters
    ----------
    index : Index
    grouper :
    obj : DataFrame or Series
    name : Label
    level :
    observed : bool, default False
        If we are a Categorical, use the observed values
    in_axis : if the Grouping is a column in self.obj and hence among
        Groupby.exclusions list
    dropna : bool, default True
        Whether to drop NA groups.
    uniques : Array-like, optional
        When specified, will be used for unique values. Enables including empty groups
        in the result for a BinGrouper. Must not contain duplicates.

    Attributes
    -------
    indices : dict
        Mapping of {group -> index_list}
    codes : ndarray
        Group codes
    group_index : Index or None
        unique groups
    groups : dict
        Mapping of {group -> label_list}
    Nz$npt.NDArray[np.signedinteger] | None_codeszCategorical | None_all_grouperr'   
_orig_catsr   _indexc
                   || _         || _        t        ||      }
d | _        d | _        || _        || _        || _        || _        || _	        || _
        |	| _        | j                  }|?t        |t              r|j                  |      }n|}|
|}
n^|
}|j!                  |      }
nIt        |
t"              r| j                  J |
j%                  | j                  d      \  }}|| _        t        |t&        j(                        r|}
n|j*                  d   j,                  }t/        ||j0                  j2                        }
nt        |
t4        t.        t6        t8        j:                  f      st=        |
dd      dk7  r#t?        tA        |
            }tC        d| d      |j!                  |
      }
tE        |
d	      rtG        |
      tG        |      k(  stI        |
      }d
| }tK        |      t        |
t8        j:                        r9|
jL                  jN                  dv rbt5        |
      jQ                         }
|
| _        y t        t=        |
dd       tR              r&|
jT                  | _        tW        |
||      \  }
| _        |
| _        y )NFrK   r   rU   ndim   Grouper for '' not 1-dimensional__len__z9Grouper result violates len(labels) == len(data)
result: mMdtype),r+   _orig_grouper_convert_grouperr   r   r   _sortrN   	_observedin_axis_dropna_uniques_ilevelr]   r   get_level_valuesmapr#   rQ   r   
BinGrouper	groupingsgrouping_vectorr   result_indexrT   r   r   npndarrayr\   r   r>   r[   hasattrlenr   AssertionErrorr   rX   to_numpyr   
categoriesr   )rH   r`   rP   rN   r+   r%   observedr   r&   uniquesr   ilevelindex_levelmapper
newgroupernewobjngtgrpererrmsgs                       r9   rI   zGrouping.__init__  sf    
$*5': 
!
  %,#44V<#&"-("-//&"9 1
 88'''!0!=!=dhhQV!=!WJDH*cnn5 #-  ))!,<<"'1H1H1M1M"Nfe^RZZH
 2a7_-. =3F!GHH#ii8O 3(CJ6$_5**/2  %V,,orzz2$$))T1
 #)"9"B"B"D  / $?AQR-88DO1Cx2.OT.  /r:   c                "    d| j                    dS )Nz	Grouping(r}   rU   rp   s    r9   r   zGrouping.__repr__x  s    499+Q''r:   c                ,    t        | j                        S N)iterindicesrp   s    r9   __iter__zGrouping.__iter__{  s    DLL!!r:   c                P    t        | j                  dd       }t        |t              S )Nr   )r\   r   r]   r   )rH   r   s     r9   _passed_categoricalzGrouping._passed_categorical~  s$    ,,gt<%!122r:   c                   | j                   }|| j                  j                  |   S t        | j                  t
        t        f      r| j                  j                  S t        | j                  t        j                        r | j                  j                  j                  S t        | j                  t
              r| j                  j                  S y r   )r   r   rf   r]   r   r   r   rT   r   r   BaseGrouperr   )rH   r   s     r9   rT   zGrouping.name  s    ;;$$V,,d((5&/:%%***,,coo>''44999,,e4'',,, r:   c                    | j                   }|yt        |t              sD| j                  }||j                  vrt        d| d      |j                  j                  |      S |S )zS
        If necessary, converted index level name to index level position.
        NzLevel z not in index)r+   r]   intr   rf   r   r`   )rH   r+   r`   s      r9   r   zGrouping._ilevel  sb    
 

=%%KKEEKK'$veWM%BCC;;$$U++r:   c                ,    t        | j                        S r   )r   _group_indexrp   s    r9   ngroupszGrouping.ngroups  s    4$$%%r:   c                    t        | j                  t        j                        r| j                  j                  S t        | j                        }|j                         S r   )r]   r   r   r   r   r   _reverse_indexer)rH   valuess     r9   r   zGrouping.indices  sI     d**COO<''///T112&&((r:   c                     | j                   d   S )Nr   )_codes_and_uniquesrp   s    r9   codeszGrouping.codes  s    &&q))r:   c                    | j                   | j                  j                  S | j                  r| j                  j                  S | j
                  d   S )v
        Analogous to result_index, but holding an ArrayLike to ensure
        we can retain ExtensionDtypes.
        r   )r   _result_index_valuesr   r   r   rp   s    r9   _group_arraylikezGrouping._group_arraylike  sN     (%%---%%$$,,,&&q))r:   c                b    t        j                  dt        t                      | j                  S )r   zOgroup_arraylike is deprecated and will be removed in a future version of pandascategoryr=   )r@   rA   rB   r   r   rp   s    r9   group_arraylikezGrouping.group_arraylike  s,     	 "')		
 $$$r:   c                    | j                   ;| j                  }t        |t              sJ | j                  }|j                  |      S | j                  S r   )r   r   r]   r   r   set_categories)rH   	group_idxcatss      r9   r   zGrouping._result_index  sR     ())Ii)9:::??D++D11   r:   c                b    t        j                  dt        t                      | j                  S )NzLresult_index is deprecated and will be removed in a future version of pandasr   )r@   rA   rB   r   r   rp   s    r9   r   zGrouping.result_index  s*     "')		
 !!!r:   c                   | j                   \  }}| j                  s7| j                  r*t        |t              sJ | j
                  r^|t        |      k(  j                         rBt	        j                  t        j                  |j                  dg      |j                  d      }nt        |      dkD  r| j                  }|j                  dk  j                         }|j                  |   dk  ret        j                   |j                  d |       }t        j"                  |j                  |d      }t	        j                  ||j                  d      }t%        j&                  || j(                        S )NFr   r   rU   )r   r   r   r]   r   r   r   any
from_codesr   appendr   r   r   argmaxr   nunique_intsinsertr   _with_inferrT   )rH   r   r   catna_idxna_unique_idx	new_codess          r9   r   zGrouping._group_index  s    00w|| 8 8g{333zzuG499;%00IIgmmbT2G4F4FQV Ua**))a-//199V$q($.$;$;CIIgv<N$OM "		'-- KI)44!7#5#5G   tyy99r:   c                b    t        j                  dt        t                      | j                  S )NzKgroup_index is deprecated and will be removed in a future version of pandasr   )r@   rA   rB   r   r   rp   s    r9   group_indexzGrouping.group_index  s*     "')		
    r:   c                   | j                   r| j                  }|j                  }| j                  rIt	        j
                  |j                        }||dk7     }| j                  r4t        j                  |      }nt        j                  t        |            }t        j                  |||j                  d      }|j                  }| j                  s|dk  }t        j                   |      r| j                  r#t        |      }t        j"                  |||      }n\|j%                         }t	        j&                  |d |       }t        j"                  ||k\  |dz   |      }t        j"                  |||      }| j                  s|j)                  | j*                        }||fS t-        | j                  t.        j0                        r:| j                  j2                  }| j                  j4                  j6                  }||fS | j8                  =t        | j                  | j8                        }|j                  }| j8                  }||fS t	        j:                  | j                  | j                  | j                        \  }}||fS )Nr   F)r   r   orderedrK   r   r   )r   )r%   use_na_sentinel)r   r   r   r   r   unique1dr   r   r   r%   aranger   r   r   r   r   r   wherer   r   reorder_categoriesr   r]   r   r   
codes_infor   r   r   	factorize)	rH   r   r   ucodesr   r   na_maskna_coder   s	            r9   r   zGrouping._codes_and_uniques	  s    ## &&CJ~~#,,SYY7"-::WWV_F3z?3!,,S[[SXG IIE<<!)66'?zz"%j/ "'5 A ")!1","9"9%."I "')9519e L "'5 A>>!44T__E'>!,,coo>((33E**77??G g~ ]]& d22t}}MCIIEmmG g~ (11$$4::t||NE7 g~r:   c                    t        j                  | j                  | j                  d      }| j                  j                  |      S )NFr   )r   r   r   r   r   groupby)rH   r   s     r9   rt   zGrouping.groupsH  s5    %%djj$2C2CeT{{""4((r:   )NNNTFFTN)r`   r   rN   zNDFrame | Noner%   r$   r   r$   r   r$   r&   r$   r   zArrayLike | Noner   r   r   )r   r   r   r$   )r   r   )r   z
int | None)r   r   )r   z$dict[Hashable, npt.NDArray[np.intp]])r   znpt.NDArray[np.signedinteger])r   r   r   )r   z/tuple[npt.NDArray[np.signedinteger], ArrayLike])r   zdict[Hashable, np.ndarray])rn   r   r   r   r   r   rI   r   r   r   r   rT   r   r   r   r   r   r   r   r   r   r   r   r   rt    r:   r9   r   r     s   @ 48F07$$M
 "$(g/g/ 	g/ g/ g/ g/ g/ "g/ 
g/R(" 3 3  "   & & ) ) * * * * % % 	! 	! " " : :, ! ! < <| ) )r:   r   c                .	     j                  |      }|t        |t              r?t        |      rt	        |      dk(  r|d   }|t        |      r|j                  |      }d}nt        |      r1t	        |      }	|	dk(  r|d   }n|	dk(  rt        d      t        d      t        |t              r> j                  |      j                  |k7  r5t        d| d j                  |             |dkD  s|dk  rt        d	      d}|}t        |t              rH|j                   d
      \  }
 |j                  |
t                fS |
t        |j                  h       fS t        |t        j                         r|t                fS t        |t"              s|g}d
}n|}t	        |      t	        |      k(  }t%        d |D              }t%        d |D              }t%        d |D              }|sk|si|sg|re|ct         t&              rt)         fd|D              }n&t         t*              sJ t)         fd|D              }|st-        j.                  |      g}t        |t0        t"        f      r|dgt	        |      z  }|}n|gt	        |      z  }g }t3               }d fd}d fd}t5        ||      D ]<  \  }}t         t&              r& ||      rd}|j7                  |j                         n ||      r j8                  dk7  rR| v rN|r j;                  ||       d| |   }}}|j8                  dk7  rt        d| d      |j7                  |       na j=                  ||      rd
|d}}}nGt?        |      t        |t              r*|j                  |j7                  |j                         d}nd
}t        |t@              stA        || |||||      n|}|jC                  |       ? t	        |      dk(  rt	               rt        d      t	        |      dk(  rI|jC                  tA        tE        g d      tG        jH                  g tF        jJ                                     t        j                   ||||      }
|
t        |       fS )a  
    Create and return a BaseGrouper, which is an internal
    mapping of how to create the grouper indexers.
    This may be composed of multiple Grouping objects, indicating
    multiple groupers

    Groupers are ultimately index mappings. They can originate as:
    index mappings, keys to columns, functions, or Groupers

    Groupers enable local references to axis,level,sort, while
    the passed in axis, level, and sort are 'global'.

    This routine tries to figure out what the passing in references
    are and then creates a Grouping for each one, combined into
    a BaseGrouper.

    If observed & we have a categorical grouper, only show the observed
    values.

    If validate, then check for key/level overlaps.

    Nr   r   zNo group keys passed!z*multiple levels only valid with MultiIndexzlevel name z is not the name of the r   z2level > 0 or level < -1 only valid with MultiIndexFr   c              3  V   K   | ]!  }t        |      xs t        |t               # y wr   )callabler]   dictry   gs     r9   r{   zget_grouper.<locals>.<genexpr>  s$     H4ax{9jD&994s   ')c              3  H   K   | ]  }t        |t        t        f        y wr   )r]   r#   r   r  s     r9   r{   zget_grouper.<locals>.<genexpr>  s     H4az!gx%894s    "c           	   3  z   K   | ]3  }t        |t        t        t        t        t
        j                  f       5 y wr   )r]   listtupler   r   r   r   r  s     r9   r{   zget_grouper.<locals>.<genexpr>  s*      IMA
1tUFE2::>?s   9;c              3  n   K   | ],  }|j                   v xs |j                  j                  v  . y wr   )columnsr`   rf   ry   r  rN   s     r9   r{   zget_grouper.<locals>.<genexpr>  s3      'BFQS[[ 8A$88$s   25c              3  N   K   | ]  }|j                   j                  v   y wr   )r`   rf   r  s     r9   r{   zget_grouper.<locals>.<genexpr>  s     &JTqCIIOO';Ts   "%c                    t        |       s2j                  dk(  ryj                  d   }	 |j                  |        yy# t        t
        t        f$ r Y yw xY w)Nr   Fr   T)_is_label_liker   axesget_locrb   	TypeErrorr
   )r*   itemsrN   s     r9   
is_in_axiszget_grouper.<locals>.is_in_axis  sZ    c"xx1} HHRLEc"
 	 i):; s   A   AAc                   t        | d      syt               s
t               rW	 | j                     }t        | t              r6t        |t              r&| j                  j                  |j                  d      S y	 | | j                     u S # t        t
        t        t        f$ r Y yw xY w# t        t
        t        t        f$ r Y yw xY w)NrT   Fr   )r   r   r   rT   rb   
IndexErrorr
   r	   r]   r   _mgrreferences_same_values)gprobj_gpr_columnrN   s     r9   	is_in_objzget_grouper.<locals>.is_in_obj  s    sF# $6$8!$SXX #v&:nf+Mxx66"''  		#chh-'' j*;=PQ  *&79LM 	 	s#   B ;B+ B('B(+CCTrZ   r   r   )rN   r+   r%   r   r   r&   r   )r   )r%   r&   r   )&rc   r]   r   r   r   r   r   r[   r   rT   _get_axis_namer#   rQ   r*   	frozensetr   r   r  r   r   allr   comasarray_tuplesafer  setzipaddr   _check_label_or_level_ambiguity_is_level_referencerb   r   r   r   r   rh   intp)rN   r*   r-   r+   r%   r   rK   r&   
group_axisnlevelsrP   keysmatch_axis_lengthany_callableany_groupersany_arraylikeall_in_columns_indexlevelsr   
exclusionsr  r  r  r   rT   pings   `                         r9   rM   rM   N  s~   @ t$J  j*-E"s5zQa{y/ 11%8 E"e*a<!!HE\$%<==$%QRR%%==&++u4$%eW -""%"4"4T":!;=  ebj !UVV EC #w''e'<77?IK,,Iswwi0#55 
C	)IK$$c4 u!IZ8 H4HHLH4HHL IM M Mc9%#& 'BF' $  c6***#&&JT&J#J #))$/0D%%';6CJ&D3t9$ "I #J 4 $'
Uc9%)C.GNN388$_xx1}77$7G%)3Cs88q= %}TF:M%NOOt$((4(8&+S$sm#W%#''*=NN377#GG c8, !	  	 	W (Z 9~s3x011
9~%%"8"((2RWW:UVW ooj)$vNGIj)3..r:   c                T    t        | t        t        f      xs | d uxr t        |       S r   )r]   r   r  r   )vals    r9   r  r  8  s%    cC<(PS_-O3Pr:   c                   t        |t              r|j                  S t        |t              rB|j                  j                  |       r|j                  S |j                  |       j                  S t        |t              r|j                  S t        |t        t        t        t        t        j                  f      rOt        |      t        |       k7  rt!        d      t        |t        t        f      rt#        j$                  |      }|S |S )Nz$Grouper and axis must be same length)r]   r  r1   r   r`   equalsr   reindexr   r  r  r   r   r   r   r   r[   r  r  )r-   rP   s     r9   r   r   <  s    '4 {{	GV	$==%??"??4(000	GZ	(	GdE5+rzzJ	Kw<3t9$CDDge}-++G4Gr:   )Nr   NTFTT)rN   r   r-   r   r%   r$   r   r$   rK   r$   r&   r$   r   z5tuple[ops.BaseGrouper, frozenset[Hashable], NDFrameT]r   )r-   r   )Ar   
__future__r   typingr   r   r@   numpyr   pandas._configr   r   pandas._libsr   pandas._libs.tslibsr	   pandas.errorsr
   pandas.util._decoratorsr   pandas.util._exceptionsr   pandas.core.dtypes.commonr   r   pandas.core.dtypes.dtypesr   pandas.corer   pandas.core.arraysr   r   pandas.core.commoncorecommonr  pandas.core.framer   pandas.core.groupbyr   pandas.core.groupby.categoricalr   pandas.core.indexes.apir   r   r   pandas.core.seriesr   pandas.io.formats.printingr   collections.abcr   r   pandas._typingr   r   r   r    pandas.core.genericr!   r#   r   rM   r  r   r   r:   r9   <module>rO     s   #  
  3 + 2 4 7 " !   ' # > 
 & 3
  ,c& c&L b) b) b)N 	
g/	g/ g/
 g/ g/ g/ g/ ;g/TQr:     	 |||fD              s|
jI                  d
      }
|
S # 1 sw Y   xY w# 1 sw Y   hxY w# t:        tJ        tL        f$ r t        |   ||      cY S w xY w)z
        Parameters
        ----------
        other : Any
        op : callable that accepts 2 params
            perform the binary op
        rG   NmT)extract_numpyextract_rangeignore)rG  r8   c              3  2   K   | ]  }t        |        y wr/   )r   rF  s     r4   r   z+RangeIndex._arith_method.<locals>.<genexpr>q  s     E.Dz!}.Ds   r   )'r<   r   NotImplementedr   r_   timedelta64r   _arith_methodr   is_np_dtyper   operatorpowr   rpowmodrmodfloordiv	rfloordivdivmodrdivmodmulrmultruedivrtruedivr   errstaterF   r   rB   rsubrD   rE   r-  rk   rG  astyperA   ZeroDivisionError)r3   r   re  rF   r9  r8  rsteprstartrstopr1  rV   r   s              r4   rn  zRangeIndex._arith_method0  s    e./!!	2>>:; 7(33__WUGT:C@7(33LLHHLLHHMMKK	
 	
 7(33 $(,,(*:*:CLLIID e4tL 	4[[X. E2E /
 "%($$ ')CHHn
$))*DJJ.499e, + --dE:HT$Zu8DF
 Evue.DEEy1M3 /. +* I'89 	47(33	4sD   I3 (I<AI3 'I' AI3 I$ I3 'I0,I3 3$JJc                   |rt        j                  d|       t        |      rt        d      t	        |      }| j                  |||       t        |      dk(  r"t        j                  g | j                        }n|j                         }|t        |       k\  rt        d| dt        |              |j                         }|t        |        k  rt        d| dt        |              |j                  | j                  d      }|dk  r|t        |       z  }| j                  d	k7  r|| j                  z  }| j                  dk7  r|| j                  z  }| j                   j#                  || j$                  
      S )Nr   z!Expected indices to be array-liker   r^   rU  rV  safe)castingr:   r8   )r   validate_taker   rA   r   _maybe_disallow_fillrv   r_   arrayrG   rx   rX  r   r  rF   rD   r\   r>   r9   )	r3   indicesr   
allow_fill
fill_valuer   takenind_maxind_mins	            r4   takezRangeIndex.take|  sb    R(W?@@%g. 	!!*j'Bw<1HHRtzz2EkkmG#d)# WI%LSQUYKX  kkmG#d)# WI%LSQUYKX  NN4::vN>E{T"yyA~"zzQ#   ,,U,CCr6   )returnztype[libindex.Int64Engine])NNNNFN)rG   Dtype | Noner=   boolr9   Hashable | Noner  r%   )NN)rM   r*   rG   r  r  r%   r/   )rU   r*   r9   r  r  r%   )rG   r  r  None)r  ztype[Index])r  r,   )r  zlist[tuple[str, int]])ry   	list[str]rz   rw   r  r  )r  r   )F)r   r  r  r   )r  znp.dtype)r  r  )r   r	   r  r  )r  rw   )NNN)r   r   r   z
str | Noner   z
int | Noner  npt.NDArray[np.intp])r  z	list[int])r  zIterator[int])r9   r   )r  r%   r   )r9   r  r   r  r  r%   )r   rw   r  )r   r  r  r   )r  r  )FT)r   r  r   r  r  z'tuple[npt.NDArray[np.intp], RangeIndex])r   rP   r  r  )
r   zLiteral[False]r   r  r   r$   r   Callable | Noner  r%   )
r   zLiteral[True]r   r  r   r$   r   r  r  z$tuple[Self, np.ndarray | RangeIndex])
r   r  r   r  r   r$   r   r  r  z+Self | tuple[Self, np.ndarray | RangeIndex])FTlastN)r   r   r   r  )r  r   r  r   )r  r   r  r   r  ztuple[int, int, int])r   r*   r  r  )r   r   r   zbool | None)r0  r  )r  r   )r?  r   r  r   )rJ  zlist[Index]r9   r   r  r   )r[  r=  r  r%   )r   TN)r   r"   r  r  r  r   )KrK   
__module____qualname____doc___typr   rX   __annotations__propertyr5   rI   classmethodrN   r>   r;   r   r\   rb   re   rm   rr   r   rD   rE   rF   r   r   rG   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r=   r   r   rx   r   r   r   r   r   r   r   r  r   r  r  r,  r5  r>  rB  rH  rQ  rS  rY  rW  r!   r]  rG  rb  rd  rn  r  __classcell__)r   s   @r4   r(   r(   B   s   8t D"9;K!LM$ $ " $"/
 "/ "/ "/ 
"/H 0 06 48"1	     
 K KN
7D ! !"         0 
 
2     6 6 6 6"   	
 
 " )) ) 	) 
)<  ! 	  			5? D D
 	_ 
1##8  $

 
 
1	
%  *-"%" ' 	
    
  
 "%" & 	
    
.    #"%"  	
    
5  $VH=
  %"(#! !  !   	! 
 !  
5! ! L,\6
#"	GI0VUp @D"1$#,)*;-z   (.< n-+ .+$$ 
.H4^ 'D 'D 	'D 
'Dr6   r(   )G
__future__r   collections.abcr   r   datetimer   rp  sysr   typingr   r	   r
   r   r   r   numpyr_   pandas._libsr   r0   r   pandas._libs.algosr   pandas._libs.libr   pandas.compat.numpyr   r   pandas.util._decoratorsr   r   r   pandas.core.dtypes.commonr   r   r   r   r   r   pandas.core.dtypes.genericr   pandas.corer   pandas.core.commoncorecommonr?   pandas.core.constructionr   pandas.core.indexes.baserJ  baseri   r   r    pandas.core.ops.commonr!   pandas._typingr"   r#   r$   r%   r&   r*   r   rG   ra   r   r(   r   r6   r4   <module>r     s    "      - ' .   9      2 ( ( <  Qxrxx!aD aDr6     ents/lib/__pycache__/column_config_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/column_types.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/dialog.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/dicttools.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/file_uploader_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/form_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/image_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/js_number.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/layout_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/mutable_status_container.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/options_selector_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/pandas_styler_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/policies.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/shortcut_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/streamlit_plotly_theme.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/subtitle_utils.cpython-312.pyc,,
streamlit/elements/lib/__pycache__/utils.cpython-312.pyc,,
streamlit/elements/lib/built_in_chart_utils.py,sha256=oQqGp4ah5HTlmjeMTiiuwLGWGCbJFKU89U_GiZ03VXY,43782
streamlit/elements/lib/color_util.py,sha256=FNCrqLehlYLPmjMUUS-XxXCr0YbY44SUhSGFQMgCQzQ,8865
streamlit/elements/lib/column_config_utils.py,sha256=nciBn-iujks2QkUtbU_kU2V-9dWRRelA8A0PIAwk7NQ,16754
streamlit/elements/lib/column_types.py,sha256=JHI3VtHel7cc2ZU9UEZTZ0ujPBq9otRmmzyFbumGfgE,97240
streamlit/elements/lib/dialog.py,sha256=hfLgVaNjuI7RV2KzHtqL5XQiagqSBi0f6ouGJzyMAAQ,7165
streamlit/elements/lib/dicttools.py,sha256=L_WZK_88z_AfVKxRJaSTTD6B3BBr00zZzoxW0FSBX-w,3887
streamlit/elements/lib/file_uploader_utils.py,sha256=SqF6jIjFRT1sM-jbr_PyudR8lzRM37MWc26QRVemWPA,3258
streamlit/elements/lib/form_utils.py,sha256=jAJIUrWEddiGw4HEQZvOh-NH7MMxcCrN5J7p4w1HJMY,2587
streamlit/elements/lib/image_utils.py,sha256=pruzGHkkY0a61qPz2r9prUX7K1S_ohTx_uIA-tK831A,15964
streamlit/elements/lib/js_number.py,sha256=lBEWML4GY_ZW_W-JCeCJJMxZMzkDAvhz_0dkUnif5IU,3532
streamlit/elements/lib/layout_utils.py,sha256=cA4pnY5APqsr9SyYoEzH891NABzGPme1wwrFVnHMnLE,9887
streamlit/elements/lib/mutable_status_container.py,sha256=1trRQY2TOzlwcbDKTuH3s-heGvTAmpHj5t_OSCthN4I,7101
streamlit/elements/lib/options_selector_utils.py,sha256=cxqCESch2Xwfu29p5CEWpmZgya8H9xft96NVGD27P5Q,10054
streamlit/elements/lib/pandas_styler_utils.py,sha256=k7txr5MT86T3BaAEAq8OsRXYrcxNNwl_Na-Rkaj0tCk,9451
streamlit/elements/lib/policies.py,sha256=iwywfWrS4sVJC0kXn55-sOSSYMUzFJNaLWGtowSr-7Y,6877
streamlit/elements/lib/shortcut_utils.py,sha256=MMEMdYV67xjeKc0iRvhAwOXdawpN2MXLGNkX_ZORTRw,4375
streamlit/elements/lib/streamlit_plotly_theme.py,sha256=IhF5l7Ur8TLNVqJaEbdxf5tKuq8PByu1dfkT9ASnFOM,8221
streamlit/elements/lib/subtitle_utils.py,sha256=aRkbUWinloC9kUu1Lj_1wBuRZF1R_AyXGQ2KGGdq6jA,6216
streamlit/elements/lib/utils.py,sha256=p4xhjZIjnhPN4scOFcqFfsJjDpIjWKxme1wbCuznGZg,9729
streamlit/elements/map.py,sha256=e8cXE0uG1OSWtBdsoHPEqQ1-T0coMH3PLQagXHvHi44,18342
streamlit/elements/markdown.py,sha256=3buG_ERQZiRDQCSdtv1S7gUOuNtrF2euut6vmiphozA,21216
streamlit/elements/media.py,sha256=OiPa6Uu9KsCWmgnDxeFYcnHr4gU_x1LJzp5cdZjYN94,33512
streamlit/elements/metric.py,sha256=8WJ0C8cBuddB3JsolNxMarDhYgI4OYvjOoUBhfCt448,16114
streamlit/elements/pdf.py,sha256=UQHU0ClNMqXlkxPBmYlqB72XFdllHvBww1r8MDA-F18,7163
streamlit/elements/plotly_chart.py,sha256=XXbHomsjkFpG76_qVXBRGNsoCK6Hg6Fi4uLFIxLGJJ4,28513
streamlit/elements/progress.py,sha256=r8S8eWWSs8WZI6KfRglqzjrJPxZkf54GI-qyIiThClQ,6061
streamlit/elements/pyplot.py,sha256=tOw_lzub3SoO7ym_sapP6Iho3FDelgSAQvLC1U1FCPA,8438
streamlit/elements/snow.py,sha256=iP2HHz9Oljf-3s76flzK7C_bU1QdNkOCpYym-LSdQjw,1439
streamlit/elements/space.py,sha256=gW1zCE1AGiZawTDMR8pzRqrlG0Q9hP4DosVLp2fG4p4,3931
streamlit/elements/spinner.py,sha256=1ZILT7jSuwqFpu6f48bkkd_MsEIMSBGyykbN9q19vG4,4891
streamlit/elements/text.py,sha256=ePyEP0GQj3oxGc_iCCTcxaVhdnPsvVtlrJhbquRTym0,4261
streamlit/elements/toast.py,sha256=utmBB6YiACVSq15GO0C65ewIqJhSQwSE6SceIjs-MTk,6429
streamlit/elements/vega_charts.py,sha256=UfII4l9-ZiUSGXpUV9qDV4_HfRoZ0HWOkAc5SsYZKmM,98914
streamlit/elements/widgets/__init__.py,sha256=M4sIyiinWL04bSC-QUcfYDB8Gr-h0uXGjTmL6o2v8jc,616
streamlit/elements/widgets/__pycache__/__init__.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/audio_input.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/button.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/button_group.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/camera_input.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/chat.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/checkbox.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/color_picker.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/data_editor.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/file_uploader.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/multiselect.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/number_input.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/radio.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/select_slider.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/selectbox.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/slider.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/text_widgets.cpython-312.pyc,,
streamlit/elements/widgets/__pycache__/time_widgets.cpython-312.pyc,,
streamlit/elements/widgets/audio_input.py,sha256=r9KF0OS_rSu_0zo1iCjOZgdQ8LParO5hY2IR1HOeKMY,12524
streamlit/elements/widgets/button.py,sha256=qYrE0cVGpktKi1OFXvQW0JvGjHrffajyqyYQrgtt0EM,57689
streamlit/elements/widgets/button_group.py,sha256=eNFZuZiydrYRtWDQ4EjUaDRdSL6eelj_ZGUiaObw1Ek,44123
streamlit/elements/widgets/camera_input.py,sha256=eqbKk2ddzenhYQVCO58vecuHjb1X_TgxXi8Ar4XT3CM,10194
streamlit/elements/widgets/chat.py,sha256=-rimUxWORUaL6vFJkGAkqgTw75fCzSTU7KEAbdTtA1E,38599
streamlit/elements/widgets/checkbox.py,sha256=y-JxK_13taW1NQfWfTycTocpD11Ww8Fd4etHNv9SehQ,13996
streamlit/elements/widgets/color_picker.py,sha256=q1BUL-3jYkyu4GpBaildsfb-V3v68y9qdT7apIuWhQQ,10028
streamlit/elements/widgets/data_editor.py,sha256=dvD8FXyyZ-gC-_ULzG86WUzMOlUP_nWTBtdTReKKDz8,44341
streamlit/elements/widgets/file_uploader.py,sha256=5OshpgSGcOwfOi7DOvLUcwSGRTnwgxO3r0tStH66vKw,21218
streamlit/elements/widgets/multiselect.py,sha256=H-vpAG_GMqqqfO7zR217PIcsIx6vnwW6AisqcOYcrCA,21083
streamlit/elements/widgets/number_input.py,sha256=pBx5o6P76I6x1QfXzcLUbI1FysjIjVFprLu50LDTwgU,25195
streamlit/elements/widgets/radio.py,sha256=FqiGxN5kgS6HCMiU_-rZFsVV6YNSmuFWqAu3WijS9kM,16250
streamlit/elements/widgets/select_slider.py,sha256=j7gzv_lEeANOwwOH4BnHSMd_rFovLQIlO4Z0eLI45w4,16096
streamlit/elements/widgets/selectbox.py,sha256=UIUkNCq2Tgt9K_tn2tVvBXN7sqcw3pI8T0TiW26U63U,22620
streamlit/elements/widgets/slider.py,sha256=JQ7mrKdK1MxB2aYLHLGCT3Q9ealf32gDOZVVSGUeWEE,38248
streamlit/elements/widgets/text_widgets.py,sha256=ZKBI91uB6W7OONRfXMwpEQzHUWmxN8FQtyZR2Ye2ge8,26671
streamlit/elements/widgets/time_widgets.py,sha256=CoZQrdqseYytuGKwMmSQTOr1gIHCVVAug3UyYVAuI58,57739
streamlit/elements/write.py,sha256=l_QOdyzZS8a-RLLM87JttZobU2v6GuGKEs-L4UPb_ic,23035
streamlit/emojis.py,sha256=lzEZmAc8pNcQJcgq8NUijyAN4wa16t884wQh5nfAv24,85969
streamlit/env_util.py,sha256=QutZX4_wk0_pckYO_S9Jy1C14ilWMA9iFP25kJHY8-M,1767
streamlit/error_util.py,sha256=zQJGx2M_uE3Ib5J0vkN7yHJrHvFtK5V1ngaQdeRPf8w,3576
streamlit/errors.py,sha256=mlABAVinJx76JY3yWyRULlvHyV0-1lqj0OJBYIvzK2Q,23269
streamlit/external/__init__.py,sha256=M4sIyiinWL04bSC-QUcfYDB8Gr-h0uXGjTmL6o2v8jc,616
streamlit/external/__pycache__/__init__.cpython-312.pyc,,
streamlit/external/langchain/__init__.py,sha256=0Iqs-M7arkKHfwzhNAEey9V1UK6Bhh2LYyq9rlPBXpc,814
streamlit/external/langchain/__pycache__/__init__.cpython-312.pyc,,
streamlit/external/langchain/__pycache__/streamlit_callback_handler.cpython-312.pyc,,
streamlit/external/langchain/streamlit_callback_handler.py,sha256=NIDD3SoiBUxE41WSC3NJWU-KcQfTmbvPf05p76WQZWE,15639
streamlit/file_util.py,sha256=l8aG2bULnaHmC2SrLn89tWc_400XwIhqeqF24fYRAs0,7811
streamlit/git_util.py,sha256=IMvIAgXhgz8rKaETukTIh1lgDXq2HHHTSVX-mKqJ1PU,6516
streamlit/hello/__init__.py,sha256=M4sIyiinWL04bSC-QUcfYDB8Gr-h0uXGjTmL6o2v8jc,616
streamlit/hello/__pycache__/__init__.cpython-312.pyc,,
streamlit/hello/__pycache__/animation_demo.cpython-312.pyc,,
streamlit/hello/__pycache__/dataframe_demo.cpython-312.pyc,,
streamlit/hello/__pycache__/hello.cpython-312.pyc,,
streamlit/hello/__pycache__/mapping_demo.cpython-312.pyc,,
streamlit/hello/__pycache__/plotting_demo.cpython-312.pyc,,
streamlit/hello/__pycache__/streamlit_app.cpython-312.pyc,,
streamlit/hello/__pycache__/utils.cpython-312.pyc,,
streamlit/hello/animation_demo.py,sha256=pcNOtxg8qHsTFPIl9_F8z6Ae4AaEqFlPXdlhSOhV-qc,3031
streamlit/hello/dataframe_demo.py,sha256=THWSyQoaO0kvY6hM3_A0fPSU1pLMIoGQBQBdQigGI98,2484
streamlit/hello/hello.py,sha256=RTD-8Zv1rTscPwX2CMERW1Jl_q-dHdfE59VSVZr64Dc,1875
streamlit/hello/mapping_demo.py,sha256=fRDwDN5NH0HGToHmO9KZJr62AHXM0AlEDQgBRf3m9Qc,3744
streamlit/hello/plotting_demo.py,sha256=wLtsi8OlWii0JKmkLp-Bu8Q8ipud8hj0wogZDVRXF6o,1772
streamlit/hello/streamlit_app.py,sha256=LwKx5czUw-Ej6nXHVfYkusfxkAOfyG0sg8nANsZzGv0,1820
streamlit/hello/utils.py,sha256=hJgsh8SAnwyKCrUR9a7hvedwtY-X9qhMNsuDwgTYteQ,1080
streamlit/logger.py,sha256=6DsfhwA_SwwRm3OIgDWgkJwhVNzkqWMikCycQTsZOrQ,3966
streamlit/material_icon_names.py,sha256=ZY49gGrzmSFDQIsgjR7Z78U7-YQq76Gj4u8_-m8rmJg,68136
streamlit/navigation/__init__.py,sha256=M4sIyiinWL04bSC-QUcfYDB8Gr-h0uXGjTmL6o2v8jc,616
streamlit/navigation/__pycache__/__init__.cpython-312.pyc,,
streamlit/navigation/__pycache__/page.cpython-312.pyc,,
streamlit/navigation/page.py,sha256=KjZxy7YIepLvTrs5EMyfjNAyG05fReJJ1yFXBRv4yxI,12005
streamlit/net_util.py,sha256=e4PzILYO7L1wwdaCru4AEFU-k14XZgZqT12jADSldV4,3307
streamlit/platform.py,sha256=4duqQIzAlyyFQzsEi7oScC0_IAW8gN-ebZNohERk2as,1119
streamlit/proto/Alert_pb2.py,sha256=lUrZZZnsn-JtL1AAggvRVYUxgDsAq4A_t0bca4i65S4,1762
streamlit/proto/Alert_pb2.pyi,sha256=7USceOIhZE1LOfSp7jIdocaaazJfHu0Fd2aaygWikPQ,3608
streamlit/proto/AppPage_pb2.py,sha256=zc06HvAElRirQavLwn0TzwJFhB3kvYRxSRdCS1P9ozE,1443
streamlit/proto/AppPage_pb2.pyi,sha256=4VNPlYJHHntxtCTfKkktuBCUar8j3emrKm0doK1oAKo,2549
streamlit/proto/ArrowData_pb2.py,sha256=e6DKHHb76f4KCxqPeDlL3ze1F3xtPf7YaSi5h6zpX_8,1251
streamlit/proto/ArrowData_pb2.pyi,sha256=JSiR00X2i5Vv7T9IzsJU8nWgI80IQJZRMj3Rv6vga_U,1656
streamlit/proto/ArrowNamedDataSet_pb2.py,sha256=fs1L6uHwjjN5QTxzJIYs4dx3stb70zfZ_6_4X54aAbo,1512
streamlit/proto/ArrowNamedDataSet_pb2.pyi,sha256=UYsE_G-wO0kM15uOYwd688zKo7G6mPtcot5AOcGyzoM,2089
streamlit/proto/ArrowVegaLiteChart_pb2.py,sha256=3sta7qqtH2F5YsVOXIO3UqB8H7DItP8y_SPoSf748Zo,1924
streamlit/proto/ArrowVegaLiteChart_pb2.pyi,sha256=OkhW7VE3fNYqd510qcIDGhak_YHDL9M-5oX7iL_Aqvk,3732
streamlit/proto/Arrow_pb2.py,sha256=DMZmpi8KGsZaat0VfRDzqnR3jeARAnL-3wwI9ZvYT0o,3483
streamlit/proto/Arrow_pb2.pyi,sha256=azO7Evv64eD8xa8NQSLNU467lu59r0BQnu-BTCwsGaE,10471
streamlit/proto/AudioInput_pb2.py,sha256=qR8fMwUS087enemwBkiU7pQMACF-h7bHy05ODwfbeco,1720
streamlit/proto/AudioInput_pb2.pyi,sha256=bJ9uky3RsF1Kd8oPYBQypkEjocfczWk2HY-VZ-B15js,2694
streamlit/proto/Audio_pb2.py,sha256=ByAGNSulAL5bmprzlAYydocJEZAmevKVVcd7OB65FtY,1732
streamlit/proto/Audio_pb2.pyi,sha256=rRel56y5Jv0V8m13NOm82NRGLvsbocAthrER05PRAuQ,2820
streamlit/proto/AuthRedirect_pb2.py,sha256=Rt9ZeLmxTTeHiAaT8KYJI9pwWYlD_2NAJTy2vZsaris,1266
streamlit/proto/AuthRedirect_pb2.pyi,sha256=FxsNTXajloe9DeVGGNVdDeerEzmX0K5lQs0QnbMzQUs,1393
streamlit/proto/AutoRerun_pb2.py,sha256=6yfVi1ELwyubHsn9NN8jVjp8kGPPFGC5jA60Y8Wb1n8,1287
streamlit/proto/AutoRerun_pb2.pyi,sha256=IMoYJrxmbmn60601VmRC4DA1kaGiR_15S4k2uEieWOc,1608
streamlit/proto/BackMsg_pb2.py,sha256=XWLLc568ugzA3zwCVqNs6AGI52x5Q46njK6hlZnzgeA,2517
streamlit/proto/BackMsg_pb2.pyi,sha256=xYhPPXt4RZceWx3Fex4qRzF4ZOtg2SjNbjtK-NYNW7I,6296
streamlit/proto/Balloons_pb2.py,sha256=SdFGy06hEcjhIFgMZNSaj1B6A2kd3L-ON_OZay-cJGI,1277
streamlit/proto/Balloons_pb2.pyi,sha256=2MXRfEmlf-lP2td1Suirva_XNNrjFd8ZbX7Ezu_9uJs,1449
streamlit/proto/BidiComponent_pb2.py,sha256=DOmFOQBRt9HMwiY54Zai0ovxb50xvO6h-zHbnSLLcz0,2777
streamlit/proto/BidiComponent_pb2.pyi,sha256=ulL7rG5a50wtYVpwY3O2wZhh8CEcdnBGQU3H7EM7PKk,7468
streamlit/proto/Block_pb2.py,sha256=aPQP1f1F-hpGDWC382F2OhZR2PmzIvWF6WibPMGePxU,8046
streamlit/proto/Block_pb2.pyi,sha256=4ue99SJS7IR76oXTupgY2_zzpsL2PyxFLcjooW-gFs8,21506
streamlit/proto/BokehChart_pb2.py,sha256=5bYTs9OyXijfSgXLm42vYBVah0qcpp6dwtHlQO9sAp0,1337
streamlit/proto/BokehChart_pb2.pyi,sha256=epybNf-9KzKmDm9S1bIBwOkYD-1bCVgqFlAskpn-bQc,1878
streamlit/proto/ButtonGroup_pb2.py,sha256=0SN0oVHTDQfjFsk0vV25zxAbKE-AKCnTBXsxdMoPOWA,3198
streamlit/proto/ButtonGroup_pb2.pyi,sha256=kdwHyKpSkU9AHI5_j2zuRWTBe20Esy4ZDlVQzE23S6E,8715
streamlit/proto/Button_pb2.py,sha256=vTqISXieylH_aXF-tTf8lKZVWk1sUb_uYw7kbhEYPYE,1818
streamlit/proto/Button_pb2.pyi,sha256=YQN0bjuK1-MxfgP096Hxyn-mz7xJX1uLbYDmOwp39qw,2904
streamlit/proto/CameraInput_pb2.py,sha256=_WyewIqwj2k_XO6_hrZWh6FUIN2tF9-7mVcrKO1QNSo,1653
streamlit/proto/CameraInput_pb2.pyi,sha256=2ChoGPov07csnJ4u3nX63zDLWHjvHANAbpoXamShInA,2316
streamlit/proto/ChatInput_pb2.py,sha256=PLqpW2vm8Q0-4R2GrTOTirfXwDWvxZOT9IEcGFJcQlQ,2265
streamlit/proto/ChatInput_pb2.pyi,sha256=NZ6z9KicEO8fwUrTO4DGWR80rqVa20sqrSDzRywfk6Y,5456
streamlit/proto/Checkbox_pb2.py,sha256=9vgvZwCm6WrLYK2f_TgkNYlL9mFIva_cr6TzULsIBgQ,1996
streamlit/proto/Checkbox_pb2.pyi,sha256=ZCawlbAkJuf5-v66jZBA7xpiP-Tm6FV3LPrKztQIwpY,3512
streamlit/proto/ClientState_pb2.py,sha256=Wi59bnzOjSF5BVfMz4VpSGPuFV87G5eAWsFO89kZ9aY,2349
streamlit/proto/ClientState_pb2.pyi,sha256=YrjhzuwCvS4fg8Uy8WP3Uxkq-W6MOwYWT-RQrrkOaNM,5816
streamlit/proto/Code_pb2.py,sha256=XuWKZZY43nFroLnKxzSftPvvdICx5ic1z-hEZGX2Mec,1525
streamlit/proto/Code_pb2.pyi,sha256=_qCh1PKnBouqP1bCF7JqbaLNzEK6iS_Y8Q24ttULHz0,2037
streamlit/proto/ColorPicker_pb2.py,sha256=mRCJI52B9WnNjrQZ9uVizhXmzjxdWOiPI11i6faGM9k,1766
streamlit/proto/ColorPicker_pb2.pyi,sha256=PoZa47fSDJkpI5R91qQXNxHSR2LYhgW8y_fxQs72CDE,2693
streamlit/proto/Common_pb2.py,sha256=4qBvjvi45n6-m0KytBPYOqI816pKoOzaOW8BYOZCcWk,4016
streamlit/proto/Common_pb2.pyi,sha256=z1PX45Dl1yUtCaBbR6P0BYQ2iIV9TD18HvaiKJayIRg,11950
streamlit/proto/Components_pb2.py,sha256=hq516W9In9UshD6NEGkBY6W75EzM1gC7SDVv33VG140,2697
streamlit/proto/Components_pb2.pyi,sha256=S8G-cguadZxj9V8nDovm65X8olRaP5N3LrujpUhpE-U,7137
streamlit/proto/DataFrame_pb2.py,sha256=NcwejTZdJe1ZQpuAf9BSg7CaxoSGwWysTwm9KOWsK4g,4832
streamlit/proto/DataFrame_pb2.pyi,sha256=9iS5sQRVNb8h_fINekVZ_6_eUIyS0v1UT0PaHQEX73E,15411
streamlit/proto/DateInput_pb2.py,sha256=B6u2R3SclO7GzpEQqO_5CkJvfNYFRtkTEZv9-pVyTVM,1892
streamlit/proto/DateInput_pb2.pyi,sha256=O5Iw2Syy7YsutTX4rL4tl-YdPRNMNDZRSxNsljeGYLc,3475
streamlit/proto/DateTimeInput_pb2.py,sha256=CciZL5xJmOWU4AwVcg_iXf21GqAwvvBNTQbYk4DA9yI,1963
streamlit/proto/DateTimeInput_pb2.pyi,sha256=pdguXw5-f4ux0055jYw8mss9YL6cpY_Sp-Zh1dtVYfU,3597
streamlit/proto/DeckGlJsonChart_pb2.py,sha256=HqQqP3JxWaQAV1E4Bqn_D9wr6x8QishBIAN8JrEj02I,2456
streamlit/proto/DeckGlJsonChart_pb2.pyi,sha256=WNJWds_1M-mSj4aMKox99CAEI9GWs12-o9nAJ8COUGU,4409
streamlit/proto/Delta_pb2.py,sha256=ukKwSkss3tIX96I5j2FT_BiyZW2BRye2izmVCiNjU4c,2012
streamlit/proto/Delta_pb2.pyi,sha256=yYHrg25Kw7fLxHr-68N3hMf_EmweEiN6Cz7KS1F5G28,3331
streamlit/proto/DocString_pb2.py,sha256=8fEx1J2VxqPTdcio8IXt9wIPIie8O5c7EZ9urt4KD3c,1735
streamlit/proto/DocString_pb2.pyi,sha256=u7vYIxdyXrf9WMMsDTzYLT3QgEGtZl2F3VpRcIjKxEU,3562
streamlit/proto/DownloadButton_pb2.py,sha256=eR6WjuEQUSb2mCXlMMwMLilpw0hPmQ-s7Ecj8MwrOz0,1815
streamlit/proto/DownloadButton_pb2.pyi,sha256=zAD5BvsqAZfgtm2-29C9ILuro6s6fk8mRFMILSbvAGw,3292
streamlit/proto/Element_pb2.py,sha256=N0VITPaXooaZYca1dtLM27ciWQuN-Kpp_l5ExYX-izI,11978
streamlit/proto/Element_pb2.pyi,sha256=7-e3_y-QI9A17MKSDktu3nr3gX0OPXPv5p84hDBp-xg,20537
streamlit/proto/Empty_pb2.py,sha256=oDn0uIKO3tkG5QBuMfCeycUM8D8wES-sW_NsT7EyY60,1172
streamlit/proto/Empty_pb2.pyi,sha256=JDwtZLMBpYtYm6GLtIb5ooJVrDm6eYiToCgRwPVQf8A,1172
streamlit/proto/Exception_pb2.py,sha256=dopZDrruxBaX0xrUHbnfKxWgsWFdbpmoqAZ2vuMAw9I,1611
streamlit/proto/Exception_pb2.pyi,sha256=Uqx_uj9e8LcvpXJOtn6yL7wGWdXzbFBIDlX2C9yhi1M,3306
streamlit/proto/Favicon_pb2.py,sha256=3gc5No02EXCfsVFbMbeaJmqzs28FZ_GBVhTrMyOyX9A,1234
streamlit/proto/Favicon_pb2.pyi,sha256=CqQPvlZJ2mY1lNTWHUu2hl0Kj9EiCUR13UawmrjeL8Y,1349
streamlit/proto/FileUploader_pb2.py,sha256=EymSAWtzmSQcc0uDFOmm-0DgVihlawHdcOUfCYycUdo,1869
streamlit/proto/FileUploader_pb2.pyi,sha256=49jkoT37m8qGHojDJL2HzJxKiu_-czTWc4uitzLw4CE,3515
streamlit/proto/ForwardMsg_pb2.py,sha256=gDxf3Ib9ZNP4pT5rKVlO-gZ8WQQCLNZ7v-7tUtihf-w,6287
streamlit/proto/ForwardMsg_pb2.pyi,sha256=HQeoISGV9l0u94yFeQwYjF7DEl6Duvr_Hj9-O51Agpc,15405
streamlit/proto/GapSize_pb2.py,sha256=KzxY0KbtciCEck5GBn8nq90HhiK802dGsfI0AXcbtbo,1535
streamlit/proto/GapSize_pb2.pyi,sha256=TYuEcx4BjKMsLUfuK9vMGWC95zN6eKfqmwUqHwFKPpk,2498
streamlit/proto/GitInfo_pb2.py,sha256=OdMZE9PzOVB1K_CsCHi4OyurMH1KDUQl4wR4gH8ze0A,1700
streamlit/proto/GitInfo_pb2.pyi,sha256=hlpKGqcjKa2imrqZVFmlE6APIEdf0k52WpcigpMYPr0,3288
streamlit/proto/GraphVizChart_pb2.py,sha256=UC9SPvV-k7xHPBBgRBs2GJqyd-x-PdRChibZwe5ICU4,1647
streamlit/proto/GraphVizChart_pb2.pyi,sha256=bkj0OMJQe8hoiyJXO-llw3-yeUaVB3s30_XbeQsYBXY,2045
streamlit/proto/Heading_pb2.py,sha256=3-6kbWAef8_di0hbNisrcHzqPIpp8ZDUQKA0gqdaEmY,1413
streamlit/proto/Heading_pb2.pyi,sha256=0NFCJ2-lhWNrAz8wVG6RuFA9mI_ywH116PTYSy74ADg,1992
streamlit/proto/HeightConfig_pb2.py,sha256=EcrEdl67nBOTPfeLNhQMXq8NPP5e8K5T9KI-n3c3BG4,1451
streamlit/proto/HeightConfig_pb2.pyi,sha256=CSgJJwGUoMc3hCCLzvSKPFI4TKRkVQPjGLETgKujSB0,2281
streamlit/proto/Html_pb2.py,sha256=u1uQlIWInXe0VYKqsH10PHvaeMqmlZMraOmxyRNhPiE,1253
streamlit/proto/Html_pb2.pyi,sha256=oSA8wU7qj8xC7qKs2Zhkg8PeIuwEymke44qR4iGWA7g,1571
streamlit/proto/IFrame_pb2.py,sha256=Y7NKa8qtqOuegvu_XAYyqp1S4Hh3OpajKaFkKSyEnEU,2014
streamlit/proto/IFrame_pb2.pyi,sha256=Bj_nxVIvOnYHo5oR46hJxZVjMBZ1TQuElQHFDnwv-kU,2895
streamlit/proto/Image_pb2.py,sha256=Mk-8LRcJm2-Nnfk45fjBZ9pN7z3P7hMfGufHlWfi5kg,1682
streamlit/proto/Image_pb2.pyi,sha256=sNWfVH_fF1MN6_vacDEvbgoL8qHnfJZTnNkvP5Lfzpw,2570
streamlit/proto/Json_pb2.py,sha256=sEplgNXC96GqwcTL8f_HJz4fAhtA_AkAKEGH6GhKxX0,1335
streamlit/proto/Json_pb2.pyi,sha256=8Wk_QDhI1q--uCAcBYiURAbd2w0SUa4j-oGxPt0xGdA,2210
streamlit/proto/LabelVisibilityMessage_pb2.py,sha256=6l8ZHl-ii8Bu9UoPythcP1FiHkj7iCiDLa        U    0     
    fiv                   ,   d Z ddlmZ ddlmZmZmZmZ ddlZddl	m
Z
mZ ddlZddlmZ ddlmZmZmZmZmZmZmZ ddlZddlZddlmZ dd	lmZ dd
lmZm Z  ddl!m"Z" ddl#m$c m%Z& ddl'm(Z( ddl)m*Z*m+Z+m,Z,m-Z-m.Z.m/Z/m0Z0m1Z1m2Z2m3Z3m4Z4m5Z5m6Z6 ddl7m8Z9 ddl:m;Z;m<Z< ddl=m>Z>m?Z?m@Z@mAZA ddlBmCZC ddlDmEZEmFZF ddlGmHZHmIZImJZJmKZKmLZLmMZMmNZNmOZOmPZPmQZQmRZRmSZS ddlTmUZUmVZVmWZW ddlXmYZYmZZZ ddl[m\Z\ ddl]m^Z^ ddl_m`Z`maZambZbmcZcmdZdmeZemfZf ddlgmhZh ddlimjZjmkZk ddllmmZmmnZn ddlompc mqZr ddlsmtZt ddlumvZv ddlwmxZxmyZymzZz ddl{m|Z| dd l}m~Z~mZ dd!lmZmZmZmZmZ dd"lmZ dd#lmZ dd$lmZ dd%lmZmZ erdd&lmZ dd'lmZ dd(lmZmZmZ d)Zd*d+d,d-Zd.Zd/Zd0Zd1Zd2Zd3Ze G d4 d5em             Zeeee   eegef   eeegef      eeef   f   Z G d6 d7emene1   e~      Z ed8ev9      Z G d: d;ee1         Z eAe      	 	 	 	 d?	 	 	 	 	 	 	 	 	 	 	 d@d<       ZdAd=Zd>Zy)Ba  
Provide the groupby split-apply-combine paradigm. Define the GroupBy
class providing the base-class of operations.

The SeriesGroupBy and DataFrameGroupBy sub-class
(defined in pandas.core.groupby.generic)
expose these user-facing objects to provide specific functionality.
    )annotations)HashableIteratorMappingSequenceN)partialwraps)dedent)TYPE_CHECKINGCallableLiteralTypeVarUnioncastfinal)using_string_dtype)option_context)	Timestamplib)rank_1d)NA)AnyArrayLike	ArrayLikeAxisAxisIntDtypeObjFillnaOptions
IndexLabelNDFrameTPositionalIndexerRandomStateScalarTnpt)function)AbstractMethodError	DataError)AppenderSubstitutioncache_readonlydoc)find_stack_level)coerce_indexer_dtypeensure_dtype_can_hold_na)is_bool_dtypeis_float_dtypeis_hashable
is_integeris_integer_dtypeis_list_likeis_numeric_dtypeis_object_dtype	is_scalaris_string_dtypeneeds_i8_conversionpandas_dtype)isnana_value_for_dtypenotna)
algorithmssample)executor)warn_alias_replacement)ArrowExtensionArrayBaseMaskedArrayCategoricalExtensionArrayFloatingArrayIntegerArraySparseArray)StringDtype)ArrowStringArrayArrowStringArrayNumpySemantics)PandasObjectSelectionMixin)	DataFrame)NDFrame)basenumba_ops)get_grouper)GroupByIndexingMixinGroupByNthSelector)CategoricalIndexIndex
MultiIndex
RangeIndexdefault_index)ensure_block_shape)Series)get_group_index_sorter)get_jit_argumentsmaybe_use_numba)Any)	Resampler)ExpandingGroupbyExponentialMovingWindowGroupbyRollingGroupbyz
        See Also
        --------
        Series.%(name)s : Apply a function %(name)s to a Series.
        DataFrame.%(name)s : Apply a function %(name)s
            to each row or column of a DataFrame.
al	  
    Apply function ``func`` group-wise and combine the results together.

    The function passed to ``apply`` must take a {input} as its first
    argument and return a DataFrame, Series or scalar. ``apply`` will
    then take care of combining the results back together into a single
    dataframe or series. ``apply`` is therefore a highly flexible
    grouping method.

    While ``apply`` is a very flexible method, its downside is that
    using it can be quite a bit slower than using more specific methods
    like ``agg`` or ``transform``. Pandas offers a wide range of method that will
    be much faster than using ``apply`` for their specific purposes, so try to
    use them before reaching for ``apply``.

    Parameters
    ----------
    func : callable
        A callable that takes a {input} as its first argument, and
        returns a dataframe, a series or a scalar. In addition the
        callable may take positional and keyword arguments.
    include_groups : bool, default True
        When True, will attempt to apply ``func`` to the groupings in
        the case that they are columns of the DataFrame. If this raises a
        TypeError, the result will be computed with the groupings excluded.
        When False, the groupings will be excluded when applying ``func``.

        .. versionadded:: 2.2.0

        .. deprecated:: 2.2.0

           Setting include_groups to True is deprecated. Only the value
           False will be allowed in a future version of pandas.

    args, kwargs : tuple and dict
        Optional positional and keyword arguments to pass to ``func``.

    Returns
    -------
    Series or DataFrame

    See Also
    --------
    pipe : Apply function to the full GroupBy object instead of to each
        group.
    aggregate : Apply aggregate function to the GroupBy object.
    transform : Apply function column-by-column to the GroupBy object.
    Series.apply : Apply a function to a Series.
    DataFrame.apply : Apply a function to each row or column of a DataFrame.

    Notes
    -----

    .. versionchanged:: 1.3.0

        The resulting dtype will reflect the return value of the passed ``func``,
        see the examples below.

    Functions that mutate the passed object can produce unexpected
    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
    for more details.

    Examples
    --------
    {examples}
    a?  
    >>> df = pd.DataFrame({'A': 'a a b'.split(),
    ...                    'B': [1, 2, 3],
    ...                    'C': [4, 6, 5]})
    >>> g1 = df.groupby('A', group_keys=False)
    >>> g2 = df.groupby('A', group_keys=True)

    Notice that ``g1`` and ``g2`` have two groups, ``a`` and ``b``, and only
    differ in their ``group_keys`` argument. Calling `apply` in various ways,
    we can get different grouping results:

    Example 1: below the function passed to `apply` takes a DataFrame as
    its argument and returns a DataFrame. `apply` combines the result for
    each group together into a new DataFrame:

    >>> g1[['B', 'C']].apply(lambda x: x / x.sum())
              B    C
    0  0.333333  0.4
    1  0.666667  0.6
    2  1.000000  1.0

    In the above, the groups are not part of the index. We can have them included
    by using ``g2`` where ``group_keys=True``:

    >>> g2[['B', 'C']].apply(lambda x: x / x.sum())
                B    C
    A
    a 0  0.333333  0.4
      1  0.666667  0.6
    b 2  1.000000  1.0

    Example 2: The function passed to `apply` takes a DataFrame as
    its argument and returns a Series.  `apply` combines the result for
    each group together into a new DataFrame.

    .. versionchanged:: 1.3.0

        The resulting dtype will reflect the return value of the passed ``func``.

    >>> g1[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
         B    C
    A
    a  1.0  2.0
    b  0.0  0.0

    >>> g2[['B', 'C']].apply(lambda x: x.astype(float).max() - x.min())
         B    C
    A
    a  1.0  2.0
    b  0.0  0.0

    The ``group_keys`` argument has no effect here because the result is not
    like-indexed (i.e. :ref:`a transform <groupby.transform>`) when compared
    to the input.

    Example 3: The function passed to `apply` takes a DataFrame as
    its argument and returns a scalar. `apply` combines the result for
    each group together into a Series, including setting the index as
    appropriate:

    >>> g1.apply(lambda x: x.C.max() - x.B.min(), include_groups=False)
    A
    a    5
    b    2
    dtype: int64a  
    >>> s = pd.Series([0, 1, 2], index='a a b'.split())
    >>> g1 = s.groupby(s.index, group_keys=False)
    >>> g2 = s.groupby(s.index, group_keys=True)

    From ``s`` above we can see that ``g`` has two groups, ``a`` and ``b``.
    Notice that ``g1`` have ``g2`` have two groups, ``a`` and ``b``, and only
    differ in their ``group_keys`` argument. Calling `apply` in various ways,
    we can get different grouping results:

    Example 1: The function passed to `apply` takes a Series as
    its argument and returns a Series.  `apply` combines the result for
    each group together into a new Series.

    .. versionchanged:: 1.3.0

        The resulting dtype will reflect the return value of the passed ``func``.

    >>> g1.apply(lambda x: x * 2 if x.name == 'a' else x / 2)
    a    0.0
    a    2.0
    b    1.0
    dtype: float64

    In the above, the groups are not part of the index. We can have them included
    by using ``g2`` where ``group_keys=True``:

    >>> g2.apply(lambda x: x * 2 if x.name == 'a' else x / 2)
    a  a    0.0
       a    2.0
    b  b    1.0
    dtype: float64

    Example 2: The function passed to `apply` takes a Series as
    its argument and returns a scalar. `apply` combines the result for
    each group together into a Series, including setting the index as
    appropriate:

    >>> g1.apply(lambda x: x.max() - x.min())
    a    1
    b    0
    dtype: int64

    The ``group_keys`` argument has no effect here because the result is not
    like-indexed (i.e. :ref:`a transform <groupby.transform>`) when compared
    to the input.

    >>> g2.apply(lambda x: x.max() - x.min())
    a    1
    b    0
    dtype: int64)templatedataframe_examplesseries_examplesa   
Compute {fname} of group values.

Parameters
----------
numeric_only : bool, default {no}
    Include only float, int, boolean columns.

    .. versionchanged:: 2.0.0

        numeric_only no longer accepts ``None``.

min_count : int, default {mc}
    The required number of valid values to perform the operation. If fewer
    than ``min_count`` non-NA values are present the result will be NA.

Returns
-------
Series or DataFrame
    Computed {fname} of values within each group.

Examples
--------
{example}
a:  
Compute {fname} of group values.

Parameters
----------
numeric_only : bool, default {no}
    Include only float, int, boolean columns.

    .. versionchanged:: 2.0.0

        numeric_only no longer accepts ``None``.

min_count : int, default {mc}
    The required number of valid values to perform the operation. If fewer
    than ``min_count`` non-NA values are present the result will be NA.

engine : str, default None {e}
    * ``'cython'`` : Runs rolling apply through C-extensions from cython.
    * ``'numba'`` : Runs rolling apply through JIT compiled code from numba.
        Only available when ``raw`` is set to ``True``.
    * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``

engine_kwargs : dict, default None {ek}
    * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
    * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
        and ``parallel`` dictionary keys. The values must either be ``True`` or
        ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
        ``{{'nopython': True, 'nogil': False, 'parallel': False}}`` and will be
        applied to both the ``func`` and the ``apply`` groupby aggregation.

Returns
-------
Series or DataFrame
    Computed {fname} of values within each group.

Examples
--------
{example}
a  
Apply a ``func`` with arguments to this %(klass)s object and return its result.

Use `.pipe` when you want to improve readability by chaining together
functions that expect Series, DataFrames, GroupBy or Resampler objects.
Instead of writing

>>> h = lambda x, arg2, arg3: x + 1 - arg2 * arg3
>>> g = lambda x, arg1: x * 5 / arg1
>>> f = lambda x: x ** 4
>>> df = pd.DataFrame([["a", 4], ["b", 5]], columns=["group", "value"])
>>> h(g(f(df.groupby('group')), arg1=1), arg2=2, arg3=3)  # doctest: +SKIP

You can write

>>> (df.groupby('group')
...    .pipe(f)
...    .pipe(g, arg1=1)
...    .pipe(h, arg2=2, arg3=3))  # doctest: +SKIP

which is much more readable.

Parameters
----------
func : callable or tuple of (callable, str)
    Function to apply to this %(klass)s object or, alternatively,
    a `(callable, data_keyword)` tuple where `data_keyword` is a
    string indicating the keyword of `callable` that expects the
    %(klass)s object.
args : iterable, optional
       Positional arguments passed into `func`.
kwargs : dict, optional
         A dictionary of keyword arguments passed into `func`.

Returns
-------
the return type of `func`.

See Also
--------
Series.pipe : Apply a function with arguments to a series.
DataFrame.pipe: Apply a function with arguments to a dataframe.
apply : Apply function to each group instead of to the
    full %(klass)s object.

Notes
-----
See more `here
<https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_

Examples
--------
%(examples)s
a  
Call function producing a same-indexed %(klass)s on each group.

Returns a %(klass)s having the same indexes as the original object
filled with the transformed values.

Parameters
----------
f : function, str
    Function to apply to each group. See the Notes section below for requirements.

    Accepted inputs are:

    - String
    - Python function
    - Numba JIT function with ``engine='numba'`` specified.

    Only passing a single function is supported with this engine.
    If the ``'numba'`` engine is chosen, the function must be
    a user defined function with ``values`` and ``index`` as the
    first and second arguments respectively in the function signature.
    Each group's index will be passed to the user defined function
    and optionally available for use.

    If a string is chosen, then it needs to be the name
    of the groupby method you want to use.
*args
    Positional arguments to pass to func.
engine : str, default None
    * ``'cython'`` : Runs the function through C-extensions from cython.
    * ``'numba'`` : Runs the function through JIT compiled code from numba.
    * ``None`` : Defaults to ``'cython'`` or the global setting ``compute.use_numba``

engine_kwargs : dict, default None
    * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
    * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
      and ``parallel`` dictionary keys. The values must either be ``True`` or
      ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
      ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be
      applied to the function

**kwargs
    Keyword arguments to be passed into func.

Returns
-------
%(klass)s

See Also
--------
%(klass)s.groupby.apply : Apply function ``func`` group-wise and combine
    the results together.
%(klass)s.groupby.aggregate : Aggregate using one or more
    operations over the specified axis.
%(klass)s.transform : Call ``func`` on self producing a %(klass)s with the
    same axis shape as self.

Notes
-----
Each group is endowed the attribute 'name' in case you need to know
which group you are working on.

The current implementation imposes three requirements on f:

* f must return a value that either has the same shape as the input
  subframe or can be broadcast to the shape of the input subframe.
  For example, if `f` returns a scalar it will be broadcast to have the
  same shape as the input subframe.
* if this is a DataFrame, f must support application column-by-column
  in the subframe. If f also supports application to the entire subframe,
  then a fast path is used starting from the second chunk.
* f must not mutate groups. Mutation is not supported and may
  produce unexpected results. See :ref:`gotchas.udf-mutation` for more details.

When using ``engine='numba'``, there will be no "fall back" behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.

.. versionchanged:: 1.3.0

    The resulting dtype will reflect the return value of the passed ``func``,
    see the examples below.

.. versionchanged:: 2.0.0

    When using ``.transform`` on a grouped DataFrame and the transformation function
    returns a DataFrame, pandas now aligns the result's index
    with the input's index. You can call ``.to_numpy()`` on the
    result of the transformation function to avoid alignment.

Examples
--------
%(example)saP  
Aggregate using one or more operations over the specified axis.

Parameters
----------
func : function, str, list, dict or None
    Function to use for aggregating the data. If a function, must either
    work when passed a {klass} or when passed to {klass}.apply.

    Accepted combinations are:

    - function
    - string function name
    - list of functions and/or function names, e.g. ``[np.sum, 'mean']``
    - None, in which case ``**kwargs`` are used with Named Aggregation. Here the
      output has one column for each element in ``**kwargs``. The name of the
      column is keyword, whereas the value determines the aggregation used to compute
      the values in the column.

      Can also accept a Numba JIT function with
      ``engine='numba'`` specified. Only passing a single function is supported
      with this engine.

      If the ``'numba'`` engine is chosen, the function must be
      a user defined function with ``values`` and ``index`` as the
      first and second arguments respectively in the function signature.
      Each group's index will be passed to the user defined function
      and optionally available for use.

    .. deprecated:: 2.1.0

        Passing a dictionary is deprecated and will raise in a future version
        of pandas. Pass a list of aggregations instead.
*args
    Positional arguments to pass to func.
engine : str, default None
    * ``'cython'`` : Runs the function through C-extensions from cython.
    * ``'numba'`` : Runs the function through JIT compiled code from numba.
    * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``

engine_kwargs : dict, default None
    * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
    * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
      and ``parallel`` dictionary keys. The values must either be ``True`` or
      ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
      ``{{'nopython': True, 'nogil': False, 'parallel': False}}`` and will be
      applied to the function

**kwargs
    * If ``func`` is None, ``**kwargs`` are used to define the output names and
      aggregations via Named Aggregation. See ``func`` entry.
    * Otherwise, keyword arguments to be passed into func.

Returns
-------
{klass}

See Also
--------
{klass}.groupby.apply : Apply function func group-wise
    and combine the results together.
{klass}.groupby.transform : Transforms the Series on each group
    based on the given function.
{klass}.aggregate : Aggregate using one or more
    operations over the specified axis.

Notes
-----
When using ``engine='numba'``, there will be no "fall back" behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.

Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
for more details.

.. versionchanged:: 1.3.0

    The resulting dtype will reflect the return value of the passed ``func``,
    see the examples below.
{examples}a  
Aggregate using one or more operations over the specified axis.

Parameters
----------
func : function, str, list, dict or None
    Function to use for aggregating the data. If a function, must either
    work when passed a {klass} or when passed to {klass}.apply.

    Accepted combinations are:

    - function
    - string function name
    - list of functions and/or function names, e.g. ``[np.sum, 'mean']``
    - dict of axis labels -> functions, function names or list of such.
    - None, in which case ``**kwargs`` are used with Named Aggregation. Here the
      output has one column for each element in ``**kwargs``. The name of the
      column is keyword, whereas the value determines the aggregation used to compute
      the values in the column.

      Can also accept a Numba JIT function with
      ``engine='numba'`` specified. Only passing a single function is supported
      with this engine.

      If the ``'numba'`` engine is chosen, the function must be
      a user defined function with ``values`` and ``index`` as the
      first and second arguments respectively in the function signature.
      Each group's index will be passed to the user defined function
      and optionally available for use.

*args
    Positional arguments to pass to func.
engine : str, default None
    * ``'cython'`` : Runs the function through C-extensions from cython.
    * ``'numba'`` : Runs the function through JIT compiled code from numba.
    * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``

engine_kwargs : dict, default None
    * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
    * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
      and ``parallel`` dictionary keys. The values must either be ``True`` or
      ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
      ``{{'nopython': True, 'nogil': False, 'parallel': False}}`` and will be
      applied to the function

**kwargs
    * If ``func`` is None, ``**kwargs`` are used to define the output names and
      aggregations via Named Aggregation. See ``func`` entry.
    * Otherwise, keyword arguments to be passed into func.

Returns
-------
{klass}

See Also
--------
{klass}.groupby.apply : Apply function func group-wise
    and combine the results together.
{klass}.groupby.transform : Transforms the Series on each group
    based on the given function.
{klass}.aggregate : Aggregate using one or more
    operations over the specified axis.

Notes
-----
When using ``engine='numba'``, there will be no "fall back" behavior internally.
The group data and group index will be passed as numpy arrays to the JITed
user defined function, and no alternative execution attempts will be tried.

Functions that mutate the passed object can produce unexpected
behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
for more details.

.. versionchanged:: 1.3.0

    The resulting dtype will reflect the return value of the passed ``func``,
    see the examples below.
{examples}c                  &    e Zd ZdZddZd ZddZy)GroupByPlotzE
    Class implementing the .plot attribute for groupby objects.
    c                    || _         y N)_groupby)selfgroupbys     {/Users/abdullahkazmi/Downloads/GenAi-Session-RAG-Pipeline/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py__init__zGroupByPlot.__init__  s	        c                    fd}d|_         | j                  j                  || j                  j                        S )Nc                (     | j                   i S rk   )plot)rm   argskwargss    ro   fzGroupByPlot.__call__.<locals>.f  s    499d-f--rq   rt   )__name__rl   _python_apply_general_selected_obj)rm   ru   rv   rw   s    `` ro   __call__zGroupByPlot.__call__  s2    	. 
}}221dmm6Q6QRRrq   c                      fd}|S )Nc                 v      fd}j                   j                  |j                   j                        S )Nc                <     t        | j                        i S rk   )getattrrt   )rm   ru   rv   names    ro   rw   z0GroupByPlot.__getattr__.<locals>.attr.<locals>.f  s     /wtyy$/@@@rq   )rl   ry   rz   )ru   rv   rw   r   rm   s   `` ro   attrz%GroupByPlot.__getattr__.<locals>.attr  s,    A ==66q$--:U:UVVrq    )rm   r   r   s   `` ro   __getattr__zGroupByPlot.__getattr__  s    	W rq   N)rn   GroupByreturnNoner   str)rx   
__module____qualname____doc__rp   r{   r   r   rq   ro   ri   ri     s     Srq   ri   c                     e Zd ZU ej                  h dz  Zded<   ded<   dZded<   dZd	ed
<   ded<   edd       Z	edd       Z
eedd              Zeed d              Zeedd              Zeed!d              Zed        Zed        Zeed               Zed"d       Z ed ed             ee      	 	 	 	 d#d              Zed$d%d       Zed&d       Zy)'BaseGroupBy>   objaxiskeyssortleveldropnagrouperas_indexobserved
exclusions
group_keysr   r   ops.BaseGrouper_grouperN_KeysArgType | Noner   IndexLabel | Noner   boolr   c                ,    t        | j                        S rk   )lengroupsrm   s    ro   __len__zBaseGroupBy.__len__  s    4;;rq   c                ,    t         j                  |       S rk   )object__repr__r   s    ro   r   zBaseGroupBy.__repr__  s     t$$rq   c                    t        j                  t        |       j                   dt        t                      | j                  S )NzI.grouper is deprecated and will be removed in a future version of pandas.)category
stacklevel)warningswarntyperx   FutureWarningr,   r   r   s    ro   r   zBaseGroupBy.grouper  s?     	Dz""# $( ("')		
 }}rq   c                .    | j                   j                  S )aI  
        Dict {group name -> group labels}.

        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 3], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        dtype: int64
        >>> ser.groupby(level=0).groups
        {'a': ['a', 'a'], 'b': ['b']}

        For DataFrameGroupBy:

        >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"])
        >>> df
           a  b  c
        0  1  2  3
        1  1  5  6
        2  7  8  9
        >>> df.groupby(by=["a"]).groups
        {1: [0, 1], 7: [2]}

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        >>> ser.resample('MS').groups
        {Timestamp('2023-01-01 00:00:00'): 2, Timestamp('2023-02-01 00:00:00'): 4}
        )r   r   r   s    ro   r   zBaseGroupBy.groups'  s    \ }}###rq   c                .    | j                   j                  S rk   )r   ngroupsr   s    ro   r   zBaseGroupBy.ngroupsW  s     }}$$$rq   c                .    | j                   j                  S )a  
        Dict {group name -> group indices}.

        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 3], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        dtype: int64
        >>> ser.groupby(level=0).indices
        {'a': array([0, 1]), 'b': array([2])}

        For DataFrameGroupBy:

        >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["owl", "toucan", "eagle"])
        >>> df
                a  b  c
        owl     1  2  3
        toucan  1  5  6
        eagle   7  8  9
        >>> df.groupby(by=["a"]).indices
        {1: array([0, 1]), 7: array([2])}

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        >>> ser.resample('MS').indices
        defaultdict(<class 'list'>, {Timestamp('2023-01-01 00:00:00'): [0, 1],
        Timestamp('2023-02-01 00:00:00'): [2, 3]})
        )r   indicesr   s    ro   r   zBaseGroupBy.indices\  s    ` }}$$$rq   c                  	
 d }t        |      dk(  rg S t        | j                        dkD  rt        t        | j                              }nd}|d   }t	        |t
              rtt	        |t
              sd}t        |      t        |      t        |      k(  s	 |D cg c]  }| j                  |    c}S |D cg c]
  } ||       c}

fd|D        }n ||      		fd|D        }|D cg c]  }| j                  j                  |g         c}S c c}w # t        $ r}d}t        |      |d}~ww xY wc c}w c c}w )zd
        Safe get multiple indices, translate keys for
        datelike to underlying repr.
        c                |    t        | t        j                        rd S t        | t        j                        rd S d S )Nc                    t        |       S rk   )r   keys    ro   <lambda>zABaseGroupBy._get_indices.<locals>.get_converter.<locals>.<lambda>  s    9S>rq   c                ,    t        |       j                  S rk   )r   asm8r   s    ro   r   zABaseGroupBy._get_indices.<locals>.get_converter.<locals>.<lambda>  s    9S>#6#6rq   c                    | S rk   r   r   s    ro   r   zABaseGroupBy._get_indices.<locals>.get_converter.<locals>.<lambda>  s    3rq   )
isinstancedatetimenp
datetime64)ss    ro   get_converterz/BaseGroupBy._get_indices.<locals>.get_converter  s4     !X../11Ar}}-66&&rq   r   Nz<must supply a tuple to get_group with multiple grouping keyszHmust supply a same-length tuple to get_group with multiple grouping keysc              3  V   K   | ]   }t        d  t        |      D               " yw)c              3  2   K   | ]  \  }} ||        y wrk   r   ).0rw   ns      ro   	<genexpr>z5BaseGroupBy._get_indices.<locals>.<genexpr>.<genexpr>  s     B,ADAq1Q4,As   N)tuplezip)r   r   
converterss     ro   r   z+BaseGroupBy._get_indices.<locals>.<genexpr>  s$     UutUBC
D,ABBus   &)c              3  .   K   | ]  } |        y wrk   r   )r   r   	converters     ro   r   z+BaseGroupBy._get_indices.<locals>.<genexpr>  s     7Yt_s   )	r   r   nextiterr   r   
ValueErrorKeyErrorget)rm   namesr   index_samplename_samplemsgr   errr   r   r   s            @@ro   _get_indiceszBaseGroupBy._get_indices  s>   	' u:?It||q T\\ 23LLAhlE*k51T o%{#s<'88	3;@A54DLL.5AA 5AALq-*LAJUuUE &l3I77E7<=ut  r*u==! B 36  %S/s23 B >s6   D D3D :D9/#D>D 	D6#D11D6c                ,    | j                  |g      d   S )zQ
        Safe get index, translate keys for datelike to underlying repr.
        r   )r   )rm   r   s     ro   
_get_indexzBaseGroupBy._get_index  s    
   $(++rq   c                    t        | j                  t              r| j                  S | j                  :t	        | j                        r| j                  | j                     S | j
                  S | j                  S rk   )r   r   r\   
_selectionr1   _obj_with_exclusionsr   s    ro   rz   zBaseGroupBy._selected_obj  s]     dhh'88O??&4??+ xx00
 ,,,xxrq   c                6    | j                   j                         S rk   )r   _dir_additionsr   s    ro   r   zBaseGroupBy._dir_additions  s    xx&&((rq   r   a          >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})
        >>> df
           A  B
        0  a  1
        1  b  2
        2  a  3
        3  b  4

        To get the difference between each groups maximum and minimum value in one
        pass, you can do

        >>> df.groupby('A').pipe(lambda x: x.max() - x.min())
           B
        A
        a  2
        b  2)klassexamplesc                6    t        j                  | |g|i |S rk   )compipe)rm   funcru   rv   s       ro   r   zBaseGroupBy.pipe  s    : xxd4T4V44rq   c                   | j                   }| j                  }t        |      rt        |      dk(  st        |      rft        |      dk(  rXt	        |t
              rt        |      dk(  r|d   }n4t	        |t
              s$t        j                  dt        t                      | j                  |      }t        |      st        |      |7| j                  dk(  r|nt        d      |f}| j                  j                  |   S t        j                  dt        t                      |j!                  || j                        S )aA  
        Construct DataFrame from group with provided name.

        Parameters
        ----------
        name : object
            The name of the group to get as a DataFrame.
        obj : DataFrame, default None
            The DataFrame to take the DataFrame out of.  If
            it is None, the object groupby was called on will
            be used.

            .. deprecated:: 2.1.0
                The obj is deprecated and will be removed in a future version.
                Do ``df.iloc[gb.indices.get(name)]``
                instead of ``gb.get_group(name, obj=df)``.

        Returns
        -------
        same type as obj

        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 3], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        dtype: int64
        >>> ser.groupby(level=0).get_group("a")
        a    1
        a    2
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["owl", "toucan", "eagle"])
        >>> df
                a  b  c
        owl     1  2  3
        toucan  1  5  6
        eagle   7  8  9
        >>> df.groupby(by=["a"]).get_group((1,))
                a  b  c
        owl     1  2  3
        toucan  1  5  6

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        >>> ser.resample('MS').get_group('2023-01-01')
        2023-01-01    1
        2023-01-15    2
        dtype: int64
           r   zWhen grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.r   Nzobj is deprecated and will be removed in a future version. Do ``df.iloc[gb.indices.get(name)]`` instead of ``gb.get_group(name, obj=df)``.r   )r   r   r4   r   r   r   r   r   r   r,   r   r   r   slicerz   iloc_take_with_is_copy)rm   r   r   r   r   indsindexers          ro   	get_groupzBaseGroupBy.get_group   s   L yy

CJ!O3t9> $&3t9>Awe,$ "/1 t$4y4. ;"ii1nd5;2EG%%**733MM= +- ))$TYY)??rq   c                `   | j                   }| j                  }| j                  j                  | j                  | j
                        }t        |      r2t        |      dk(  r$t        j                  dt        t                      t        |t              rt        |      dk(  r	d |D        }|S )aB  
        Groupby iterator.

        Returns
        -------
        Generator yielding sequence of (name, subsetted object)
        for each group

        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 3], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        dtype: int64
        >>> for x, y in ser.groupby(level=0):
        ...     print(f'{x}\n{y}\n')
        a
        a    1
        a    2
        dtype: int64
        b
        b    3
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"])
        >>> df
           a  b  c
        0  1  2  3
        1  1  5  6
        2  7  8  9
        >>> for x, y in df.groupby(by=["a"]):
        ...     print(f'{x}\n{y}\n')
        (1,)
           a  b  c
        0  1  2  3
        1  1  5  6
        (7,)
           a  b  c
        2  7  8  9

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        >>> for x, y in ser.resample('MS'):
        ...     print(f'{x}\n{y}\n')
        2023-01-01 00:00:00
        2023-01-01    1
        2023-01-15    2
        dtype: int64
        2023-02-01 00:00:00
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        r   r   zCreating a Groupby object with a length-1 list-like level parameter will yield indexes as tuples in a future version. To keep indexes as scalars, create Groupby objects with a scalar level parameter instead.r   c              3  ,   K   | ]  \  }}|f|f  y wrk   r   )r   r   groups      ro   r   z'BaseGroupBy.__iter__.<locals>.<genexpr>  s     ?*#uvuos   )r   r   r   get_iteratorrz   r   r4   r   r   r   r   r,   r   list)rm   r   r   results       ro   __iter__zBaseGroupBy.__iter__k  s    P yy

++D,>,>TYY+O3u:?MM4 +- dD!c$i1n??Frq   )r   int)r   r   )r   r   )r   zdict[Hashable, np.ndarray])r   z$dict[Hashable, npt.NDArray[np.intp]])r   zset[str])r   z/Callable[..., T] | tuple[Callable[..., T], str]r   r#   rk   r   DataFrame | Series)r   z#Iterator[tuple[Hashable, NDFrameT]])rx   r   r   rL   _hidden_attrs__annotations__r   r   r   r   r   propertyr   r   r   r   r   r   r*   rz   r   r)   r
   r(   _pipe_templater   r   r   r   rq   ro   r   r     s    .. 2 M M $D
$#E#
    % %    ,$  ,$\ %  % .%  .%` 0> 0>d , ,   & ) ) 
, n5=5
 
5 -.5 h@ h@T X Xrq   r   OutputFrameOrSeries)boundc                     e Zd ZU dZded<   ded<   edddddddddej                  df	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 did	       Zdjd
Z	edkd       Z
edld       Ze	 	 dm	 	 	 dnd       Ze	 	 	 	 dod       Zedpd       Zedqd       Ze	 dr	 	 	 dsd       Z	 	 dm	 	 	 	 	 dtdZedud       Z	 	 	 	 	 	 dvdZeddd       Zeddd       Z eed   j1                  ded               dddwd       Ze	 	 	 dx	 	 	 	 	 	 	 	 	 	 	 dyd       Ze	 	 dzdd!	 	 	 	 	 	 	 d{d"       Z	 	 	 	 	 	 	 	 	 	 d|d#Ze	 	 	 d}	 	 	 	 	 	 	 d~d$       Z	 d	 	 	 	 	 dd%Zeddd&d'       Zedqd(       Z ed)        Z!eddd*       Z"ee#dd+              Z$e e%d,-       e%e&.      ddd/                     Z'e e%d,-       e%e&.      ddd0                     Z(e e%d,-       e%e&.      dd1                     Z)e e%d,-       e%e&.      	 	 	 d	 	 	 	 	 dd2                     Z*eddd3       Z+e e%d,-       e%e&.      	 	 	 	 d	 	 	 	 	 	 	 dd5                     Z,e e%d,-       e%e&.      	 	 	 	 d	 	 	 	 	 	 	 dd6                     Z-e	 	 	 	 	 d	 	 	 	 	 	 	 	 	 	 	 dd7       Z.eddd8       Z/e e%d,-       e%e&.      dd9                     Z0e e1e2d:dddd e3d;      <      	 	 	 	 d	 	 	 	 	 	 	 dd=              Z4e e1e5d>dd e3d?      @      dddA              Z6e e1e2dBdd dd e3dC      <      	 	 	 	 d	 	 	 	 	 	 	 ddD              Z7e e1e2dEdd dd e3dF      <      	 	 	 	 d	 	 	 	 	 	 	 ddG              Z8e	 d	 	 	 	 	 	 	 ddH       Z9e	 d	 	 	 	 	 	 	 ddI       Z:eddJ       Z; e1e<jz                        	 	 	 d	 ddK       Z=eddddL       Z>eddM       Z?e e%d,-       ee&      ddN                     Z@e e%d,-       ee&      ddO                     ZAedrddP       ZBe e%d,-      drddQ              ZCe e%d,-      drddR              ZDee# e%d,-       e%e&.      ddS                            ZE	 dr	 	 	 	 	 ddTZFe	 	 	 d	 	 	 	 	 ddU       ZGe e%d,-      dddV              ZHe e%d,-      dddW              ZIe e%d,-       e%e&.      dXddYdej                  f	 	 	 	 	 	 	 	 	 	 	 ddZ                     ZJe e%d,-       e%e&.      ej                  f	 	 	 dd[                     ZKe e%d,-       e%e&.      ej                  f	 	 	 dd\                     ZLe e%d,-       e%e&.      ej                  df	 	 	 	 	 dd]                     ZMe e%d,-       e%e&.      ej                  df	 	 	 	 	 dd^                     ZNe e%d,-      d4dej                  ej                  df	 	 	 	 	 dd_              ZOe e%d,-       e%e&.      d4ej                  f	 	 	 	 	 dd`                     ZPe e%d,-       e%e&.      d4ej                  ej                  dej                  f	 	 	 	 	 	 	 dda                     ZQe e%d,-       e%e&.      dddb                     ZRe e%d,-       e%e&.      dddc                     ZSeddd       ZTeeUj                  ddf	 	 	 	 	 	 	 	 	 dde       ZWe	 	 	 	 	 d	 	 	 	 	 	 	 	 	 ddf       ZXdej                  ddf	 	 	 	 	 	 	 	 	 	 	 ddgZYddhZZy)r   a  
    Class for grouping and aggregating relational data.

    See aggregate, transform, and apply functions on this object.

    It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:

    ::

        grouped = groupby(obj, ...)

    Parameters
    ----------
    obj : pandas object
    axis : int, default 0
    level : int, default None
        Level of MultiIndex
    groupings : list of Grouping objects
        Most users should ignore this
    exclusions : array-like, optional
        List of columns to exclude
    name : str
        Most users should ignore this

    Returns
    -------
    **Attributes**
    groups : dict
        {group name -> group labels}
    len(grouped) : int
        Number of groups

    Notes
    -----
    After grouping, see aggregate, apply, and transform functions. Here are
    some other brief notes about usage. When grouping by multiple groups, the
    result index will be a MultiIndex (hierarchical) by default.

    Iteration produces (key, group) tuples, i.e. chunking the data by group. So
    you can write code like:

    ::

        grouped = obj.groupby(keys, axis=axis)
        for key, group in grouped:
            # do something with the data

    Function calls on GroupBy, if not specially implemented, "dispatch" to the
    grouped data. So if you group a DataFrame and wish to invoke the std()
    method on each group, you can simply do:

    ::

        df.groupby(mapper).std()

    rather than

    ::

        df.groupby(mapper).aggregate(np.std)

    You can pass arguments to these "wrapped" functions, too.

    See the online documentation for full exposition on these topics and much
    more
    r   r   r   r   Nr   Tc           	     x   || _         t        |t              sJ t        |             || _        |s|dk7  rt        d      || _        || _        |	| _        |
| _	        || _
        |4t        |||||	|t        j                  u rdn|| j                        \  }}}|t        j                  u rBt        d |j                  D              r$t!        j"                  dt$        t'                      d}|| _        || _        |j-                  |      | _        || _        |rt3        |      | _        y t3               | _        y )Nr   z$as_index=False only valid for axis=0F)r   r   r   r   r   c              3  4   K   | ]  }|j                     y wrk   _passed_categoricalr   pings     ro   r   z#GroupBy.__init__.<locals>.<genexpr>>  s     J8I4++8I   zThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.r   )r   r   rO   r   r   r   r   r   r   r   r   rS   r   
no_defaultany	groupingsr   r   r   r,   r   r   _get_axis_numberr   r   	frozensetr   )rm   r   r   r   r   r   r   	selectionr   r   r   r   r   s                ro   rp   zGroupBy.__init__  s"     $#w'2c2'
qy !GHH 		$?'2"*cnn"<({{($GZ s~~%J8I8IJJ8 "/1 H ((.	3=)J/9;rq   c                    || j                   v rt        j                  | |      S || j                  v r| |   S t	        dt        |       j                   d| d      )N'z' object has no attribute ')_internal_names_setr   __getattribute__r   AttributeErrorr   rx   )rm   r   s     ro   r   zGroupBy.__getattr__O  sd    4+++**466488:T
##$$?vQG
 	
rq   c                   |dk(  r>t        j                  t        |       j                   d| dt        t                      y t        j                  dt        |       j                   d| dt        t                      y )Nr   .zo with axis=1 is deprecated and will be removed in a future version. Operate on the un-grouped DataFrame insteadr   zThe 'axis' keyword in z\ is deprecated and will be removed in a future version. Call without passing 'axis' instead.)r   r   r   rx   r   r,   )rm   r   r   s      ro   _deprecate_axiszGroupBy._deprecate_axisY  s|    19MM:&&'q /$ $ +- MM(d)<)<(=Qtf E7 7 +-rq   c                
  	 t        t        | j                        |      	t        j                  	      }dv rFd   t
        j                  ur1| j                  j                  d         }| j                  ||       ndv r|dk(  rn|dk(  rdd<   ndd<   d|j                  v rBj                  dd      !j                  d      t
        j                  u r| j                  d<   	fd}||_        |t        j                  v r| j!                  || j"                        S |t        j$                  v }| j!                  || j                  ||       }| j&                  j(                  r|r| j+                  |      }|S )z<Compute the result of an operation by using GroupBy's apply.r   skewfillnaNr   c                     | gi S rk   r   )xru   rw   rv   s    ro   curriedz&GroupBy._op_via_apply.<locals>.curried  s    Q((((rq   )is_transformnot_indexed_same)r   r   r   inspect	signaturer   r  r   r  r  
parametersr   r   rx   rP   plotting_methodsry   rz   transformation_kernelsr   has_dropped_na_set_result_index_ordered)
rm   r   ru   rv   sigr   r  r  r   rw   s
     ``     @ro   _op_via_applyzGroupBy._op_via_applyl  ss    D223T:"Vvcnn D88,,VF^<D  t,v v~!!%v!"v S^^#zz&$'/6::f3E3W!%v	)
   4(((--gt7I7IJJt:::++%%%!--	 , 
 ==''L 33F;Frq   Fc                   ddl m} | j                  r|s| j                  r\| j                  j
                  }| j                  j                  }| j                  j                  } ||| j                  |||d      }nat        t        t        |                  }	 ||| j                  |	      }n-|s ||| j                        }| j                  j                  | j                        }
| j                  r#| j                  j                  d   }|dk7  }|
|   }
|
j                   r|j"                  | j                     j%                  |
      s[t'        j(                  |
j*                        }|j,                  j/                  |      \  }}|j1                  || j                        }n3|j3                  |
| j                  d      }n ||| j                        }| j4                  j6                  d	k(  r| j4                  j8                  }n$t;        | j<                        r| j<                  }nd }t?        |t@              r	|||_        |S )
Nr   concatF)r   r   levelsr   r   )r   r   r   r   copyr   )!pandas.core.reshape.concatr&  r   r   r   result_indexr'  r   r   r   ranger   rz   	_get_axisr   
group_infohas_duplicatesaxesequalsr>   unique1d_valuesindexget_indexer_non_uniquetakereindexr   ndimr   r1   r   r   r\   )rm   valuesr  r  r&  r   group_levelsgroup_namesr   r   axlabelsmasktargetr   _r   s                    ro   _concat_objectszGroupBy._concat_objects  s    	6??<}}!]]77
#}}33"mm11#'% E#f+./TYYTB!F3F##--dii8B{{11!4|X   TYY)?)F)Fr)J#,,RZZ8#\\@@H
W499=G F3F88==A88==D)??DDff%$*:FKrq   c                h   | j                   j                  | j                        }| j                  j                  r6| j                  j
                  s |j                  || j                  d      }|S t        | j                  j                               }|j                  || j                  d      }|j                  | j                        }| j                  j
                  r/|j                  t        t        |            | j                        }|j                  || j                  d      }|S )NFr)  r   )r   r.  r   r   is_monotonicr   set_axisrW   result_ilocs
sort_indexr8  rY   r   )rm   r   obj_axisoriginal_positionss       ro   r!  z!GroupBy._set_result_index_ordered  s     88%%dii0==%%dmm.J.J__XDIIE_JFM #4==#=#=#?@!3$))%P""		"2=='' ^^Js8}$=DII^NF		Frq   c           
        t        |t              r|j                         }|j                  }t	        t        | j                  j                        t        | j                  j                               t        | j                  j                  D cg c]  }|j                   c}            D ]G  \  }}}||vs|r|j                  d||       "d}t        j                  |t        t                      I |S c c}w )Nr   zA grouping was used that is not in the columns of the DataFrame and so was excluded from the result. This grouping will be included in a future version of pandas. Add the grouping as a column of the DataFrame to silence this warning.messager   r   )r   r\   to_framecolumnsr   reversedr   r   get_group_levelsr  in_axisinsertr   r   r   r,   )rm   r   rN  grpr   levrQ  r   s           ro   _insert_inaxis_grouperzGroupBy._insert_inaxis_grouper  s    ff%__&F .."%T]](()T]]3356T]]-D-DE-Dcckk-DEF#
D#w 7"MM!T3/Y  MM #!.#3#5##
. ) Fs   C9c                    | j                   dk(  rd|j                  }|j                  j                  | j                  j                        r)| j                  j                  j                         |_        |S )Nr   )r   r#   r5  r2  r   r*  )rm   r   s     ro   _maybe_transpose_resultzGroupBy._maybe_transpose_result!  sO    99>XXF||""488>>2  $xx~~224rq   c                L   | j                   sJ| j                  |      }|j                         }t        t	        | j
                  j                              }n| j
                  j                  }|t        ||      }||_	        | j                  |      }| j                  ||      S )z
        Wraps the output of GroupBy aggregations into the expected result.

        Parameters
        ----------
        result : Series, DataFrame

        Returns
        -------
        Series or DataFrame
        qs)r   rU  _consolidaterW   r-  r   r   r,  _insert_quantile_levelr5  rW  _reindex_output)rm   r   rZ  r5  ress        ro   _wrap_aggregated_outputzGroupBy._wrap_aggregated_output,  s    ( }} 008F((*F% 5 567E MM..E> +5"5E **62##CB#//rq   c                    t        |       rk   r&   )rm   datar:  r  r  s        ro   _wrap_applied_outputzGroupBy._wrap_applied_outputV  s     "$''rq   c                Z   | j                   j                  \  }}}| j                   j                  }| j                   j                  }|j	                  || j
                        j                         }|j                  }t        |t              rat        | j                   j                        dkD  rt        d      | j                   j                  d   j                  }	|j                  |	      }|j	                  |      j                         }
t        j                   ||      \  }}|||
|fS )Nr   r   z_Grouping with more than 1 grouping labels and a MultiIndex is not supported with engine='numba'r   )r   r/  	_sort_idx_sorted_idsr7  r   to_numpyr5  r   rX   r   r  NotImplementedErrorr   get_level_valuesr   generate_slices)rm   rb  idsrA  r   sorted_index
sorted_idssorted_data
index_data	group_keysorted_index_datastartsendss                ro   _numba_prepzGroupBy._numba_prepb  s   --22Q}}..]]..
ii499i=FFHZZ
j*-4==**+a/)H  //277I#44Y?J&OOL9BBD**:w?	
 	
rq   c                   | j                   st        d      | j                  dk(  rt        d      | j                  }|j                  dk(  r|n|j                         }t        j                  ||dfi t        |      }| j                  j                  \  }}	}	| j                  j                  }
 |j                  j                  |f||
d|}| j                  j                  |j                  d<   |j!                  ||j                        }|j                  dk(  r$|j#                  d      }|j$                  |_        |S |j&                  |_        |S )	zp
        Perform groupby with a standard numerical aggregation function (e.g. mean)
        with Numba.
        z<as_index=False is not supported. Use .reset_index() instead.r   zaxis=1 is not supported.   T)r>  r   )r1  rN  )r   rh  r   r   r9  rM  r@   generate_shared_aggregatorr^   r   r/  r   _mgrapplyr,  r1  _constructor_from_mgrsqueezer   rN  )rm   r   dtype_mappingengine_kwargsaggregator_kwargsrb  df
aggregatorrk  rA  r   res_mgrr   s                ro   _numba_agg_generalzGroupBy._numba_agg_general}  s<    }}%N  99>%&@AA((YY!^T88
  .	

 MM,,	Q--''"''--
"G
7H
 --44Q))')E99>^^I.F))FK  "\\FNrq   )r}  c          	     8   | j                   }|j                  dk(  r|n|j                         }| j                  |      \  }}}	}
t	        j
                  |       t	        j                  |fi t        ||      } ||
|	||t        |j                        g| }|j                  t        j                  |	      d      }|j                  }|j                  dk(  rd|j                  i}|j                         }nd|j                  i} |j                   |fd|i|S )a(  
        Perform groupby transform routine with the numba engine.

        This routine mimics the data splitting routine of the DataSplitter class
        to generate the indices of each group in the sorted data and then passes the
        data and indices into a Numba jitted function.
        rv  r   r   r   r   rN  r5  )r   r9  rM  rt  rQ   validate_udfgenerate_numba_transform_funcr^   r   rN  r7  r   argsortr5  r   ravel_constructor)rm   r   r}  ru   rv   rb  r  rr  rs  rl  rn  numba_transform_funcr   r5  result_kwargss                  ro   _transform_with_numbazGroupBy._transform_with_numba  s    ((YY!^T262B2B22F/lKD!%CC 
%mV< 
 &

O
 
 RZZ5A>

99>#TYY/M\\^F&5M t  FuFFFrq   c          	     p   | j                   }|j                  dk(  r|n|j                         }| j                  |      \  }}}	}
t	        j
                  |       t	        j                  |fi t        ||      } ||
|	||t        |j                        g| }| j                  j                  }|j                  dk(  rd|j                  i}|j                         }nd|j                  i} |j                  |fd|i|}| j                  s*| j!                  |      }t#        t        |            |_        |S )a*  
        Perform groupby aggregation routine with the numba engine.

        This routine mimics the data splitting routine of the DataSplitter class
        to generate the indices of each group in the sorted data and then passes the
        data and indices into a Numba jitted function.
        rv  r   r   rN  r5  )r   r9  rM  rt  rQ   r  generate_numba_agg_funcr^   r   rN  r   r,  r   r  r  r   rU  rZ   r5  )rm   r   r}  ru   rv   rb  r  rr  rs  rl  rn  numba_agg_funcr   r5  r  r^  s                   ro   _aggregate_with_numbazGroupBy._aggregate_with_numba  s'    ((YY!^T262B2B22F/lKD!77
%mV<
  

O
 
 **99>#TYY/M\\^F&5MdEeE}E}}--c2C%c#h/CI
rq   re   	dataframerf   )inputr   )include_groupsc                  }t        j                        |k7  r t         j                  |   }t        | ||       t	        t
              rNt        |       r3t        |       }t        |      r |i S srt        d       |S t        d d      sr,t              rt              fd       }nt        d      }|s| j                  || j                        S t        dd       5  	 | j                  || j                        }	t	        | j                   t"              s| j$                  x| j                  j&                  | j                  j&                  k7  rKt)        j*                  t,        j/                  t1        |       j2                  d      t4        t7                      d d d        |	S # t        $ r( | j                  || j                        cY cd d d        S w xY w# 1 sw Y   	S xY w)	Nz"Cannot pass arguments to property z$apply func should be callable, not 'r  c                     | gi S rk   r   )gru   r   rv   s    ro   rw   zGroupBy.apply.<locals>.f  s    3D3F33rq   z6func must be a callable if args or kwargs are suppliedzmode.chained_assignmentry  rK  )r   is_builtin_func_builtin_table_aliasrA   r   r   hasattrr   callabler   	TypeErrorr	   ry   r   r   rz   r   r\   r   shaper   r   _apply_groupings_deprformatr   rx   r   r,   )
rm   r   r  ru   rv   	orig_funcaliasr^  rw   r   s
    ` ``     ro   ry  zGroupBy.apply  s    	""4(,,Y7E"4E:dC tT"dD)C=///V$'I$%PQQ
  "FtfA NOOV~t4 4 !L  A--a1J1JKK 5t<P33At7I7IJ"488V4/**00D4M4M4S4SSMM 5 < < J//! "/#3#5 =4   	P 11!T5N5NOO1 =<	P =4 s+   :G4<B:G  %G1%G40G11G44G>c                    | j                   j                  ||| j                        \  }}||}| j                  ||||      S )a  
        Apply function f in python space

        Parameters
        ----------
        f : callable
            Function to apply
        data : Series or DataFrame
            Data to apply f to
        not_indexed_same: bool, optional
            When specified, overrides the value of not_indexed_same. Apply behaves
            differently when the result index is equal to the input index, but
            this can be coincidental leading to value-dependent behavior.
        is_transform : bool, default False
            Indicator for whether the function is actually a transform
            and should not have group keys prepended.
        is_agg : bool, default False
            Indicator for whether the function is an aggregation. When the
            result is empty, we don't want to warn for this case.
            See _GroupBy._python_agg_general.

        Returns
        -------
        Series or DataFrame
            data after applying f
        )r   apply_groupwiser   rc  )rm   rw   rb  r  r  is_aggr:  mutateds           ro   ry   zGroupBy._python_apply_general<  sP    F --774K#&((	
 	
rq   r(  )npfuncc               j     | j                   d||||d|}|j                  | j                  d      S )N)howaltnumeric_only	min_countrn   methodr   _cython_agg_general__finalize__r   )rm   r  r  r  r  rv   r   s          ro   _agg_generalzGroupBy._agg_generalj  sM     *)) 
%	

 
 ""488I">>rq   c                N   |J |j                   dk(  rt        |d      }nHt        |j                  |j                        }|j
                  d   dk(  sJ |j                  dddf   }	 | j                  j                  ||d      }|j                  }
|
t        k(  r|j                  t        d      }n.t        |
      r#|
j                         }|j                  ||
      }t!        ||      S # t        $ r*}d	| d
|j                   d}	 t        |      |	      |d}~ww xY w)zn
        Fallback to pure-python aggregation if _cython_operation raises
        NotImplementedError.
        Nr   Fr*  dtyper   T)preserve_dtypezagg function failed [how->z,dtype->])r9  )r9  r\   rN   r#   r  r  r   r   
agg_series	Exceptionr   r   astyper8   construct_array_type_from_sequencer[   )rm   r  r:  r9  r  serr  
res_valuesr   r   r  string_array_clss               ro   _agg_py_fallbackzGroupBy._agg_py_fallback}  s%    ;;!e,C 6886<<8B 88A;!### ''!Q$-C
	*11#s41PJ 		F?#**6*>JU#$99;)8858QJ "*488#  	*.se8CII;aHC$s)C.c)	*s   +C1 1	D$:%DD$c                    
  j                  |      
d
 fd}
j                  |      } j                  |      }dv r j                  |      } j	                  |      }	 j
                  dk(  r|	j                  d      }	|	S )Nr  r   c                   	  j                   j                  d| fj                  dz
  d}|S # t        $ r dv rt	        | t
              rndv r Y nw xY wJ j                  | j                        }|S )N	aggregater   r   r  r  all)r  r  stdsem)r9  r  )r   _cython_operationr9  rh  r   rH   r  )r:  r   r  rb  r  rv   r  rm   s     ro   
array_funcz/GroupBy._cython_agg_general.<locals>.array_func  s    888 Q' &  ' 	 .(Z-L[C+G$G	 ?"?**3TYYC*PFMs   /4 %AAidxminidxmaxr   Fr  r:  r   r   r   )_get_data_to_aggregategrouped_reduce_wrap_agged_manager_wrap_idxmax_idxminr_  r   infer_objects)rm   r  r  r  r  rv   r  new_mgrr^  outrb  s   ``` ``    @ro   r  zGroupBy._cython_agg_general  s     **3*O	 	6 %%j1&&w/&&**3/C**3/99>###/C
rq   c                    t        |       rk   ra  )rm   r  r  r   rv   s        ro   _cython_transformzGroupBy._cython_transform  s     "$''rq   )enginer}  c                  |}t        j                  |      xs |}||k7  rt        | ||       t        |t              s | j
                  |||g|i |S |t        j                  vrd| d}t        |      |t        j                  v s|t        j                  v r|
||d<   ||d<    t        | |      |i |S t        j                  | dd      5  |dv r+t        t        d   |      } | j                  |dg|i |}n|
||d<   ||d<    t        | |      |i |}d d d        | j!                        S # 1 sw Y   xY w)Nr  z2' is not a valid function name for transform(name)r  r}  r   Tr  )r   get_cython_funcrA   r   r   _transform_generalrP   transform_kernel_allowlistr   cythonized_kernelsr  r   temp_setattrr   r   _idxmax_idxmin_wrap_transform_fast_result)	rm   r   r  r}  ru   rv   r  r   r   s	            ro   
_transformzGroupBy._transform  su    	""4(0D"4D9$$*4**4XXQWXX888dVMNCS/!T,,,8S8S0S!#)x *7'&74&777 !!$
D9 //(: ;TBD0T00tMdMfMF)+1x(2?/0WT40$A&AF : 33F;; :9s   AD99Ec                z   | j                   }| j                  j                  \  }}}|j                  | j                  j                  | j
                  d      }| j                  j                  dk(  rJt        j                  |j                  |      }|j                  ||j                  |j                        }|S |j                  dk(  rdn| j
                  }|j                  |   j                  |      }|j!                  |||fidd      }|j#                  |j%                  | j
                        |      }|S )	z7
        Fast transform path for aggregations.
        Fr)  r   r5  r   r   T)
allow_dupsr*  r   )r   r   r/  r8  r,  r   r   r9  r>   take_ndr4  r  r5  r   r1  r7  _reindex_with_indexersrE  r.  )	rm   r   r   rk  rA  r  outputr   new_axs	            ro   r  z#GroupBy._wrap_transform_fast_result  s   
 '' MM,,	Q : :QVW88==A$$V^^S9C%%c%JF  q(1diiD [[&++C0F22}%$U 3 F __S]]499%=D_IFrq   c                x   t        |      dk(  rt        j                  g d      }n(t        j                  t        j                  |            }|r)| j
                  j                  || j                        }|S t        j                  t        | j
                  j                        t              }|j                  d       d||j                  t              <   t        j                  |t        | j
                  j                   dd        dgz         j"                  }| j
                  j%                  |      }|S )Nr   int64r  r   FTr   )r   r   arrayr   concatenaterz   r7  r   emptyr5  r   fillr  r   tiler   r  r#   where)rm   r   r   filteredr?  s        ro   _apply_filterzGroupBy._apply_filter,  s    w<1hhr1GggbnnW56G))..wTYY.GH  88C 2 2 8 89FDIIe(,D$%774d&8&8&>&>qr&B!Cqc!IJLLD))//5Hrq   c                   | j                   j                  \  }}}t        ||      }||   t        |      }}|dk(  r%t	        j
                  dt        j                        S t        j                  d|dd |dd k7  f   }t	        j                  t        j                  t	        j                  |      d   |f         }| j                         }	|r|	t	        j                  |	|   |      z  }	n2t	        j                  |	t        j                  |dd df      |      |	z
  }	| j                   j                  rHt	        j                  |dk(  t        j                  |	j                  t        j                   d            }	n!|	j                  t        j                  d      }	t	        j
                  |t        j"                        }
t	        j$                  |t        j"                        |
|<   |	|
   S )	a.  
        Parameters
        ----------
        ascending : bool, default True
            If False, number in reverse, from length of group - 1 to 0.

        Notes
        -----
        this is currently implementing sort=False
        (though the default is sort=True) for groupby in general
        r   r  TNr(  r   Fr  )r   r/  r]   r   r   r  r  r_diffnonzerocumsumrepeatr   r  nanr  float64intparange)rm   	ascendingrk  rA  r   sortercountrunrepr  revs              ro   _cumcount_arrayzGroupBy._cumcount_array=  sx    --22Q'W5[#c(UA:88ARXX..eeD#cr(c!"g--.ggbeeBJJsOA.567tmmo299SXs++C))Cc!"gtm 45s;cAC==''((3"9bffcjj%j.PQC**RXXE*2ChhuBGG,iiRWW5F3xrq   c                    t        | j                  t              r| j                  j                  S t        | j                  t              sJ | j                  j
                  S rk   )r   r   rN   _constructor_slicedr\   r  r   s    ro   _obj_1d_constructorzGroupBy._obj_1d_constructore  sF     dhh	*88///$((F+++xx$$$rq   rn   r   )see_alsoc                2    | j                  dfd      S )a  
        Return True if any value in the group is truthful, else False.

        Parameters
        ----------
        skipna : bool, default True
            Flag to ignore nan values during truth testing.

        Returns
        -------
        Series or DataFrame
            DataFrame or Series of boolean values, where a value is True if any element
            is True within its respective group, False otherwise.
        %(see_also)s
        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 0], index=lst)
        >>> ser
        a    1
        a    2
        b    0
        dtype: int64
        >>> ser.groupby(level=0).any()
        a     True
        b    False
        dtype: bool

        For DataFrameGroupBy:

        >>> data = [[1, 0, 3], [1, 0, 6], [7, 1, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["ostrich", "penguin", "parrot"])
        >>> df
                 a  b  c
        ostrich  1  0  3
        penguin  1  0  6
        parrot   7  1  9
        >>> df.groupby(by=["a"]).any()
               b      c
        a
        1  False   True
        7   True   True
        r  c                >    t        | d      j                        S NFr  )skipna)r\   r  r  r  s    ro   r   zGroupBy.any.<locals>.<lambda>      &/3363Brq   r  r  r  rm   r  s    `ro   r  zGroupBy.anyn  s'    d ''B ( 
 	
rq   c                2    | j                  dfd      S )a  
        Return True if all values in the group are truthful, else False.

        Parameters
        ----------
        skipna : bool, default True
            Flag to ignore nan values during truth testing.

        Returns
        -------
        Series or DataFrame
            DataFrame or Series of boolean values, where a value is True if all elements
            are True within its respective group, False otherwise.
        %(see_also)s
        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 0], index=lst)
        >>> ser
        a    1
        a    2
        b    0
        dtype: int64
        >>> ser.groupby(level=0).all()
        a     True
        b    False
        dtype: bool

        For DataFrameGroupBy:

        >>> data = [[1, 0, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["ostrich", "penguin", "parrot"])
        >>> df
                 a  b  c
        ostrich  1  0  3
        penguin  1  5  6
        parrot   7  8  9
        >>> df.groupby(by=["a"]).all()
               b      c
        a
        1  False   True
        7   True   True
        r  c                >    t        | d      j                        S r
  )r\   r  r  s    ro   r   zGroupBy.all.<locals>.<lambda>  r  rq   r  r  r  s    `ro   r  zGroupBy.all  s'    f ''B ( 
 	
rq   c                |  	
 | j                         }| j                  j                  \  }
dk7  	|j                  dk(  d		
fd}|j	                  |      }| j                  |      }t        j                  | dd      5  | j                  |      }ddd       | j                  d      S # 1 sw Y   xY w)
af  
        Compute count of group, excluding missing values.

        Returns
        -------
        Series or DataFrame
            Count of values within each group.
        %(see_also)s
        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, np.nan], index=lst)
        >>> ser
        a    1.0
        a    2.0
        b    NaN
        dtype: float64
        >>> ser.groupby(level=0).count()
        a    2
        b    0
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, np.nan, 3], [1, np.nan, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["cow", "horse", "bull"])
        >>> df
                a	  b	c
        cow     1	NaN	3
        horse	1	NaN	6
        bull	7	8.0	9
        >>> df.groupby("a").count()
            b   c
        a
        1   0   2
        7   1   1

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 4], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        2023-02-15    4
        dtype: int64
        >>> ser.resample('MS').count()
        2023-01-01    2
        2023-02-01    2
        Freq: MS, dtype: int64
        r(  r   c                T   | j                   dk(  r t        |       j                  dd       z  }nt        |        z  }t        j                  |      }t        | t              r@t        |d   t        j                  |j                  d   t        j                              S t        | t              rDt        | j                  t              s*t        d      }t!        |       j#                  |d   |      S r*|j                   dk(  sJ |j                  d   dk(  sJ |d   S |S )	Nr   r(  )r>  max_binr   r  )r?  zint64[pyarrow]rv  )r9  r;   reshaper   count_level_2dr   rC   rG   r   zerosr  bool_rB   r  rI   r:   r   r  )bvaluesmaskedcountedr  rk  	is_seriesr?  r   s       ro   hfunczGroupBy.count.<locals>.hfunc 	  s   ||q g!6!6q"!= ==g.((WMG'?3#AJRXXgmmA.>bhh%O  G%89*{C %%56G}33GAJe3LL||q(((}}Q'1,,,qz!Nrq   r   TNr   
fill_value)r  r   r   r   )
r  r   r/  r9  r  r  r   r  r_  r]  )rm   rb  rA  r  r  new_objr   rk  r  r?  r   s          @@@@ro   r  zGroupBy.count  s    v **,--22QbyIIN		 	0 %%e,**73 dJ511':F 6 ##Fq#99 65s   B22B;c                    t        |      r)ddlm} | j                  |t        j
                  |d      S | j                  dfd      }|j                  | j                  d      S )	aW  
        Compute mean of groups, excluding missing values.

        Parameters
        ----------
        numeric_only : bool, default False
            Include only float, int, boolean columns.

            .. versionchanged:: 2.0.0

                numeric_only no longer accepts ``None`` and defaults to ``False``.

        engine : str, default None
            * ``'cython'`` : Runs the operation through C-extensions from cython.
            * ``'numba'`` : Runs the operation through JIT compiled code from numba.
            * ``None`` : Defaults to ``'cython'`` or globally setting
              ``compute.use_numba``

            .. versionadded:: 1.4.0

        engine_kwargs : dict, default None
            * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
            * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
              and ``parallel`` dictionary keys. The values must either be ``True`` or
              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
              ``{{'nopython': True, 'nogil': False, 'parallel': False}}``

            .. versionadded:: 1.4.0

        Returns
        -------
        pandas.Series or pandas.DataFrame
        %(see_also)s
        Examples
        --------
        >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
        ...                    'B': [np.nan, 2, 3, 4, 5],
        ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])

        Groupby one column and return the mean of the remaining columns in
        each group.

        >>> df.groupby('A').mean()
             B         C
        A
        1  3.0  1.333333
        2  4.0  1.500000

        Groupby two columns and return the mean of the remaining column.

        >>> df.groupby(['A', 'B']).mean()
                 C
        A B
        1 2.0  2.0
          4.0  1.0
        2 3.0  1.0
          5.0  2.0

        Groupby one column and return the mean of only particular column in
        the group.

        >>> df.groupby('A')['B'].mean()
        A
        1    3.0
        2    4.0
        Name: B, dtype: float64
        r   )grouped_meanmin_periodsmeanc                >    t        | d      j                        S NFr  )r  )r\   r&  r  r  s    ro   r   zGroupBy.mean.<locals>.<lambda>	  s    fQU388l8Srq   r  r  rn   r  )	r_   pandas.core._numba.kernelsr#  r  r@   float_dtype_mappingr  r  r   )rm   r  r  r}  r#  r   s    `    ro   r&  zGroupBy.meanD	  sw    Z 6"?**,,	 +   --S) . F
 &&txx	&BBrq   c                l    | j                  dfd      }|j                  | j                  d      S )a  
        Compute median of groups, excluding missing values.

        For multiple groupings, the result index will be a MultiIndex

        Parameters
        ----------
        numeric_only : bool, default False
            Include only float, int, boolean columns.

            .. versionchanged:: 2.0.0

                numeric_only no longer accepts ``None`` and defaults to False.

        Returns
        -------
        Series or DataFrame
            Median of values within each group.

        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
        >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
        >>> ser
        a     7
        a     2
        a     8
        b     4
        b     3
        b     3
        dtype: int64
        >>> ser.groupby(level=0).median()
        a    7.0
        b    3.0
        dtype: float64

        For DataFrameGroupBy:

        >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
        >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
        ...                   'mouse', 'mouse', 'mouse', 'mouse'])
        >>> df
                 a  b
          dog    1  1
          dog    3  4
          dog    5  8
        mouse    7  4
        mouse    7  4
        mouse    8  2
        mouse    3  1
        >>> df.groupby(level=0).median()
                 a    b
        dog    3.0  4.0
        mouse  7.0  3.0

        For Resampler:

        >>> ser = pd.Series([1, 2, 3, 3, 4, 5],
        ...                 index=pd.DatetimeIndex(['2023-01-01',
        ...                                         '2023-01-10',
        ...                                         '2023-01-15',
        ...                                         '2023-02-01',
        ...                                         '2023-02-10',
        ...                                         '2023-02-15']))
        >>> ser.resample('MS').median()
        2023-01-01    2.0
        2023-02-01    4.0
        Freq: MS, dtype: float64
        medianc                >    t        | d      j                        S r(  )r\   r.  r)  s    ro   r   z GroupBy.median.<locals>.<lambda>	  s    &/66L6Qrq   r*  rn   r  r  )rm   r  r   s    ` ro   r.  zGroupBy.median	  s@    R ))Q% * 

 ""488I">>rq   r   c           	         t        |      r=ddlm} t        j                  | j                  |t        j                  |d            S | j                  dfd|      S )a	  
        Compute standard deviation of groups, excluding missing values.

        For multiple groupings, the result index will be a MultiIndex.

        Parameters
        ----------
        ddof : int, default 1
            Degrees of freedom.

        engine : str, default None
            * ``'cython'`` : Runs the operation through C-extensions from cython.
            * ``'numba'`` : Runs the operation through JIT compiled code from numba.
            * ``None`` : Defaults to ``'cython'`` or globally setting
              ``compute.use_numba``

            .. versionadded:: 1.4.0

        engine_kwargs : dict, default None
            * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
            * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
              and ``parallel`` dictionary keys. The values must either be ``True`` or
              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
              ``{{'nopython': True, 'nogil': False, 'parallel': False}}``

            .. versionadded:: 1.4.0

        numeric_only : bool, default False
            Include only `float`, `int` or `boolean` data.

            .. versionadded:: 1.5.0

            .. versionchanged:: 2.0.0

                numeric_only now defaults to ``False``.

        Returns
        -------
        Series or DataFrame
            Standard deviation of values within each group.
        %(see_also)s
        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
        >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
        >>> ser
        a     7
        a     2
        a     8
        b     4
        b     3
        b     3
        dtype: int64
        >>> ser.groupby(level=0).std()
        a    3.21455
        b    0.57735
        dtype: float64

        For DataFrameGroupBy:

        >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
        >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
        ...                   'mouse', 'mouse', 'mouse', 'mouse'])
        >>> df
                 a  b
          dog    1  1
          dog    3  4
          dog    5  8
        mouse    7  4
        mouse    7  4
        mouse    8  2
        mouse    3  1
        >>> df.groupby(level=0).std()
                      a         b
        dog    2.000000  3.511885
        mouse  2.217356  1.500000
        r   grouped_varr%  ddofr  c                >    t        | d      j                        S NFr  )r4  )r\   r  r  r4  s    ro   r   zGroupBy.std.<locals>.<lambda>Z
      fQU377T7Brq   r  r  r4  )	r_   r+  r2  r   sqrtr  r@   r,  r  rm   r4  r  r}  r  r2  s    `    ro   r  zGroupBy.std	  sp    r 6">77''00! ! (   ++B)	 ,  rq   c                    t        |      r*ddlm} | j                  |t        j
                  |d      S | j                  dfd|      S )a	  
        Compute variance of groups, excluding missing values.

        For multiple groupings, the result index will be a MultiIndex.

        Parameters
        ----------
        ddof : int, default 1
            Degrees of freedom.

        engine : str, default None
            * ``'cython'`` : Runs the operation through C-extensions from cython.
            * ``'numba'`` : Runs the operation through JIT compiled code from numba.
            * ``None`` : Defaults to ``'cython'`` or globally setting
              ``compute.use_numba``

            .. versionadded:: 1.4.0

        engine_kwargs : dict, default None
            * For ``'cython'`` engine, there are no accepted ``engine_kwargs``
            * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``
              and ``parallel`` dictionary keys. The values must either be ``True`` or
              ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is
              ``{{'nopython': True, 'nogil': False, 'parallel': False}}``

            .. versionadded:: 1.4.0

        numeric_only : bool, default False
            Include only `float`, `int` or `boolean` data.

            .. versionadded:: 1.5.0

            .. versionchanged:: 2.0.0

                numeric_only now defaults to ``False``.

        Returns
        -------
        Series or DataFrame
            Variance of values within each group.
        %(see_also)s
        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'a', 'b', 'b', 'b']
        >>> ser = pd.Series([7, 2, 8, 4, 3, 3], index=lst)
        >>> ser
        a     7
        a     2
        a     8
        b     4
        b     3
        b     3
        dtype: int64
        >>> ser.groupby(level=0).var()
        a    10.333333
        b     0.333333
        dtype: float64

        For DataFrameGroupBy:

        >>> data = {'a': [1, 3, 5, 7, 7, 8, 3], 'b': [1, 4, 8, 4, 4, 2, 1]}
        >>> df = pd.DataFrame(data, index=['dog', 'dog', 'dog',
        ...                   'mouse', 'mouse', 'mouse', 'mouse'])
        >>> df
                 a  b
          dog    1  1
          dog    3  4
          dog    5  8
        mouse    7  4
        mouse    7  4
        mouse    8  2
        mouse    3  1
        >>> df.groupby(level=0).var()
                      a          b
        dog    4.000000  12.333333
        mouse  4.916667   2.250000
        r   r1  r3  varc                >    t        | d      j                        S r6  )r\   r=  r7  s    ro   r   zGroupBy.var.<locals>.<lambda>
  r8  rq   r9  )r_   r+  r2  r  r@   r,  r  r;  s    `    ro   r=  zGroupBy.var_
  sd    r 6">**,, +   ++B)	 ,  rq   c           	     	   | j                   dk(  rt        d      |rdnd}| j                  }| j                  }| j                  j
                  D 	ch c]  }	|	j                  s|	j                   }
}	t        |t              r|j                  }||
v rg n|g}nt        |j                        }|@t        |      }|t        |
      z  }|rt        d| d      ||z
  }|rt        d| d      |}t        |j                        D cg c]   \  }}||
vr||v r|j                  dd|f   " }}}t        | j                  j
                        }|D ]C  }t!        ||| j                   | j"                  d	|
      \  }}}|t        |j
                        z  }E |j%                  || j"                  | j&                  | j(                        }t+        t        |j-                               }||_        t/        d |D              r[|D cg c]  }|j0                   }}t3        j4                  ||D cg c]  }|j                   c}      }|j7                  |d      }|r|j9                  |d      }| j"                  r|j:                  j<                  }t?        tA        |            |j:                  _        t        t?        tA        | j                  j
                                    }|jC                  |d	      }||j:                  _        |rt        t?        tA        | j                  j
                        |j:                  jD                              }|j%                  |j:                  jG                  |      | j"                  | j(                  d	      jI                  d      }||z  }|jK                  d      }| jL                  r|}n|j:                  } tO        jP                  | j<                        }!||!v rt        d| d      ||_        | jS                  t?        tA        |!                  |_        |jU                         }"| j                  j
                  d   j                  j                  jV                  }#tY        |!|#      j[                  tA        |!      |      }$|$|"_        |"}|j]                  | j                  d      S c c}	w c c}}w c c}w c c}w )z
        Shared implementation of value_counts for SeriesGroupBy and DataFrameGroupBy.

        SeriesGroupBy additionally supports a bins argument. See the docstring of
        DataFrameGroupBy.value_counts for a description of arguments.
        r   z1DataFrameGroupBy.value_counts only handles axis=0
proportionr  NzKeys z0 in subset cannot be in the groupby column keys.z) in subset do not exist in the DataFrame.F)r   r   r   r   r   )r   r   r   c              3  z   K   | ]3  }t        |j                  t        t        f      xr |j                    5 y wrk   )r   grouping_vectorrD   rV   	_observed)r   groupings     ro   r   z(GroupBy._value_counts.<locals>.<genexpr>  sC      
 & x//+?O1PQ '&&&'%s   9;r   r   r  stable)r  kind)r   sort_remaining)r   r   r   sumg        zColumn label 'z' is duplicate of result columnr  value_countsr  )/r   rh  r   r   r   r  rQ  r   r   r\   setrN  r   	enumerater   r   rS   r   rn   r   r   r   sizer  _result_indexrX   from_productr8  sort_valuesr5  r   r-  r   rG  nlevels	droplevel	transformr  r   r   fill_missing_names	set_namesreset_indexr  rW   rR  r  )%rm   subset	normalizer   r  r   r   r  r   rD  in_axis_names_namer   unique_cols	subsettedclashingdoesnt_existidxr  r   r   rA  gbresult_seriesr  levels_listmulti_indexr   index_levelr'  indexed_group_sizer   r5  rN  result_frame
orig_dtypecolss%                                        ro   _value_countszGroupBy._value_counts
  s    99>%C   )|gXX'' +/--*A*A
*AhXEUEUHMM*A 	 
 c6"HHE-/2cUDckk*K!K	$s='99$z *3 3   );6$~ .2 3 
 (	
 #,CKK"8 #9JC-%92D C "8   001	C'YYYYMGQ g//00I  ZZ]];;	  
 VRWWY/!  
 &
 

 ;DD)$4--)KD$11)#D)$DII)#DK *11+!1LM)55#( 6 M 99!''--E(-c%j(9M%uS)@)@%ABCK)44!% 5 M ).M% c$--112M4G4G4O4OPF "/!6!6##--f5YY{{ "7 " i  //M *005M =="F "''E,,U[[9Gw >$7V!WXX!%M"'//%G2E"FM(446L00377??EEJ
3::3w<ND#'L !F""488N"CCm
2H E#Ds   S#S
%SS0S
c                   |rr| j                   j                  dk(  rYt        | j                   j                        s:t	        t        |       j                   d| d| j                   j                         | j                  dfd|      S )a+  
        Compute standard error of the mean of groups, excluding missing values.

        For multiple groupings, the result index will be a MultiIndex.

        Parameters
        ----------
        ddof : int, default 1
            Degrees of freedom.

        numeric_only : bool, default False
            Include only `float`, `int` or `boolean` data.

            .. versionadded:: 1.5.0

            .. versionchanged:: 2.0.0

                numeric_only now defaults to ``False``.

        Returns
        -------
        Series or DataFrame
            Standard error of the mean of values within each group.

        Examples
        --------
        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b', 'b']
        >>> ser = pd.Series([5, 10, 8, 14], index=lst)
        >>> ser
        a     5
        a    10
        b     8
        b    14
        dtype: int64
        >>> ser.groupby(level=0).sem()
        a    2.5
        b    3.0
        dtype: float64

        For DataFrameGroupBy:

        >>> data = [[1, 12, 11], [1, 15, 2], [2, 5, 8], [2, 6, 12]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["tuna", "salmon", "catfish", "goldfish"])
        >>> df
                   a   b   c
            tuna   1  12  11
          salmon   1  15   2
         catfish   2   5   8
        goldfish   2   6  12
        >>> df.groupby("a").sem()
              b  c
        a
        1    1.5  4.5
        2    0.5  2.0

        For Resampler:

        >>> ser = pd.Series([1, 3, 2, 4, 3, 8],
        ...                 index=pd.DatetimeIndex(['2023-01-01',
        ...                                         '2023-01-10',
        ...                                         '2023-01-15',
        ...                                         '2023-02-01',
        ...                                         '2023-02-10',
        ...                                         '2023-02-15']))
        >>> ser.resample('MS').sem()
        2023-01-01    0.577350
        2023-02-01    1.527525
        Freq: MS, dtype: float64
        r   z.sem called with numeric_only=z and dtype r  c                >    t        | d      j                        S r6  )r\   r  r7  s    ro   r   zGroupBy.sem.<locals>.<lambda>  s    &/333>rq   r9  )r   r9  r5   r  r  r   rx   r  )rm   r4  r  s    ` ro   r  zGroupBy.semZ  s    T DHHMMQ.7G7W:&&' (  ,~[8HJ  ''>%	 ( 
 	
rq   c                R   | j                   j                         }d}t        | j                  t              rt        | j                  j
                  t              rQt        | j                  j
                  t              rd}nPt        | j                  j
                  t              rd}n)d}n&t        | j                  j
                  t              rd}t        | j                  t              r(| j                  || j                  j                        }n| j                  |      }||j                  dddd|      }t        j                  | dd      5  | j                  |d	
      }ddd       | j                   s|j#                  d      j%                         }|S # 1 sw Y   6xY w)a:  
        Compute group sizes.

        Returns
        -------
        DataFrame or Series
            Number of rows in each group as a Series if as_index is True
            or a DataFrame if as_index is False.
        %(see_also)s
        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b']
        >>> ser = pd.Series([1, 2, 3], index=lst)
        >>> ser
        a     1
        a     2
        b     3
        dtype: int64
        >>> ser.groupby(level=0).size()
        a    2
        b    1
        dtype: int64

        >>> data = [[1, 2, 3], [1, 5, 6], [7, 8, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["owl", "toucan", "eagle"])
        >>> df
                a  b  c
        owl     1  2  3
        toucan  1  5  6
        eagle   7  8  9
        >>> df.groupby("a").size()
        a
        1    2
        7    1
        dtype: int64

        For Resampler:

        >>> ser = pd.Series([1, 2, 3], index=pd.DatetimeIndex(
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01']))
        >>> ser
        2023-01-01    1
        2023-01-15    2
        2023-02-01    3
        dtype: int64
        >>> ser.resample('MS').size()
        2023-01-01    2
        2023-02-01    1
        Freq: MS, dtype: int64
        Nnumpy_nullablepyarrowr  F)r  convert_stringconvert_booleanconvert_floatingdtype_backendr   Tr   r  rM  )r   rM  r   r   r\   r  rB   rK   rJ   rC   r  r   convert_dtypesr   r  r]  r   renamerV  )rm   r   rr  s      ro   rM  zGroupBy.size  sP   t ##%EIdhh'$((..*=>dhhnn.LM$(M0@A$4M$-MDHHNNO< 0 dhh'--f488==-IF--f5F$**#$ %!&+ + F dJ5 ))&Q)?F 6 }} ]]6*668F 65s   FF&rI  a          For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b', 'b']
        >>> ser = pd.Series([1, 2, 3, 4], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        b    4
        dtype: int64
        >>> ser.groupby(level=0).sum()
        a    3
        b    7
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["tiger", "leopard", "cheetah", "lion"])
        >>> df
                  a  b  c
          tiger   1  8  2
        leopard   1  2  5
        cheetah   2  5  8
           lion   2  6  9
        >>> df.groupby("a").sum()
             b   c
        a
        1   10   7
        2   11  17)fnamenomceekexamplec                0   t        |      r)ddlm} | j                  |t        j
                  ||      S t        j                  | dd      5  | j                  ||dt        j                        }d d d        | j                  dd      S # 1 sw Y   xY w)	Nr   )grouped_sumr$  r   TrI  r  r  r  r  )r   r  )r_   r+  r|  r  r@   default_dtype_mappingr   r  r  r   rI  r]  )rm   r  r  r  r}  r|  r   s          ro   rI  zGroupBy.sum  s    d 6">**..%	 +   !!$
D9**!-'66	 +  : ''1U'KK :9s   $BBproda          For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b', 'b']
        >>> ser = pd.Series([1, 2, 3, 4], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        b    4
        dtype: int64
        >>> ser.groupby(level=0).prod()
        a    2
        b   12
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["tiger", "leopard", "cheetah", "lion"])
        >>> df
                  a  b  c
          tiger   1  8  2
        leopard   1  2  5
        cheetah   2  5  8
           lion   2  6  9
        >>> df.groupby("a").prod()
             b    c
        a
        1   16   10
        2   30   72)ru  rv  rw  rz  c                H    | j                  ||dt        j                        S )Nr  r}  )r  r   r  )rm   r  r  s      ro   r  zGroupBy.prodZ  s-    T   %&QSQXQX ! 
 	
rq   mina          For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b', 'b']
        >>> ser = pd.Series([1, 2, 3, 4], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        b    4
        dtype: int64
        >>> ser.groupby(level=0).min()
        a    1
        b    3
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["tiger", "leopard", "cheetah", "lion"])
        >>> df
                  a  b  c
          tiger   1  8  2
        leopard   1  2  5
        cheetah   2  5  8
           lion   2  6  9
        >>> df.groupby("a").min()
            b  c
        a
        1   2  2
        2   5  8c                    t        |      r*ddlm} | j                  |t        j
                  ||d      S | j                  ||dt        j                        S )Nr   grouped_min_maxFr%  is_maxr  r}  )	r_   r+  r  r  r@   identity_dtype_mappingr  r   r  rm   r  r  r  r}  r  s         ro   r  zGroupBy.min  sg    d 6"B**//% +   $$)#vv	 %  rq   maxa          For SeriesGroupBy:

        >>> lst = ['a', 'a', 'b', 'b']
        >>> ser = pd.Series([1, 2, 3, 4], index=lst)
        >>> ser
        a    1
        a    2
        b    3
        b    4
        dtype: int64
        >>> ser.groupby(level=0).max()
        a    2
        b    4
        dtype: int64

        For DataFrameGroupBy:

        >>> data = [[1, 8, 2], [1, 2, 5], [2, 5, 8], [2, 6, 9]]
        >>> df = pd.DataFrame(data, columns=["a", "b", "c"],
        ...                   index=["tiger", "leopard", "cheetah", "lion"])
        >>> df
                  a  b  c
          tiger   1  8  2
        leopard   1  2  5
        cheetah   2  5  8
           lion   2  6  9
        >>> df.groupby("a").max()
            b  c
        a
        1   8  5
        2   6  9c                    t        |      r*ddlm} | j                  |t        j
                  ||d      S | j                  ||dt        j                        S )Nr   r  Tr  r  r}  )	r_   r+  r  r  r@   r  r  r   r  r  s         ro   r  zGroupBy.max  sg    d 6"B**//% +   $$)#vv	 %  rq   c                8    ddd}| j                  ||d||      S )a  
        Compute the first entry of each column within each group.

        Defaults to skipping NA elements.

        Parameters
        ----------
        numeric_only : bool, default False
            Include only float, int, boolean columns.
        min_count : int, default -1
            The required number of valid values to perform the operation. If fewer
            than ``min_count`` valid values are present the result will be NA.
        skipna : bool, default True
            Exclude NA/null values. If an entire row/column is NA, the result
            will be NA.

            .. versionadded:: 2.2.1

        Returns
        -------
        Series or DataFrame
            First values within each group.

        See Also
        --------
        DataFrame.groupby : Apply a function groupby to each row or column of a
            DataFrame.
        pandas.core.groupby.DataFrameGroupBy.last : Compute the last non-null entry
            of each column.
        pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.

        Examples
        --------
        >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[None, 5, 6], C=[1, 2, 3],
        ...                        D=['3/11/2000', '3/12/2000', '3/13/2000']))
        >>> df['D'] = pd.to_datetime(df['D'])
        >>> df.groupby("A").first()
             B  C          D
        A
        1  5.0  1 2000-03-11
        3  6.0  3 2000-03-13
        >>> df.groupby("A").first(min_count=2)
            B    C          D
        A
        1 NaN  1.0 2000-03-11
        3 NaN  NaN        NaT
        >>> df.groupby("A").first(numeric_only=True)
             B  C
        A
        1  5.0  1
        3  6.0  3
        c                    dd}t        | t              r| j                  ||      S t        | t              r ||       S t	        t        |             )Nc                    | j                   t        | j                            }t        |      s | j                   j                  j                  S |d   S )z-Helper function for first item that isn't NA.r   r  r=   r   r  na_valuer  arrs     ro   firstz2GroupBy.first.<locals>.first_compat.<locals>.firstJ  s<    ggeAGGn-3x77==1111vrq   r   r  r\   r   rN   ry  r\   r  r   )r   r   r  s      ro   first_compatz#GroupBy.first.<locals>.first_compatI  sI     #y)yyTy22C(Sz!S	**rq   r  r  r  r  r  r  r   r   r   r   r   r  )rm   r  r  r  r  s        ro   r  zGroupBy.first  s1    r	+   % ! 
 	
rq   c                8    ddd}| j                  ||d||      S )aS  
        Compute the last entry of each column within each group.

        Defaults to skipping NA elements.

        Parameters
        ----------
        numeric_only : bool, default False
            Include only float, int, boolean columns. If None, will attempt to use
            everything, then use only numeric data.
        min_count : int, default -1
            The required number of valid values to perform the operation. If fewer
            than ``min_count`` valid values are present the result will be NA.
        skipna : bool, default True
            Exclude NA/null values. If an entire row/column is NA, the result
            will be NA.

            .. versionadded:: 2.2.1

        Returns
        -------
        Series or DataFrame
            Last of values within each group.

        See Also
        --------
        DataFrame.groupby : Apply a function groupby to each row or column of a
            DataFrame.
        pandas.core.groupby.DataFrameGroupBy.first : Compute the first non-null entry
            of each column.
        pandas.core.groupby.DataFrameGroupBy.nth : Take the nth row from each group.

        Examples
        --------
        >>> df = pd.DataFrame(dict(A=[1, 1, 3], B=[5, None, 6], C=[1, 2, 3]))
        >>> df.groupby("A").last()
             B  C
        A
        1  5.0  2
        3  6.0  3
        c                    dd}t        | t              r| j                  ||      S t        | t              r ||       S t	        t        |             )Nc                    | j                   t        | j                            }t        |      s | j                   j                  j                  S |d   S )z,Helper function for last item that isn't NA.r(  r  r  s     ro   lastz/GroupBy.last.<locals>.last_compat.<locals>.last  s<    ggeAGGn-3x77==1112wrq   r   r  r  )r   r   r  s      ro   last_compatz!GroupBy.last.<locals>.last_compat  sI     #y)yyDy11C(Cy S	**rq   r  r  r  r  r  )rm   r  r  r  r  s        ro   r  zGroupBy.last`  s1    \	+   % ! 
 	
rq   c                   | j                   j                  dk(  r| j                  }t        |j                        }|st        d      | j                  j                  d|j                  ddd      }g d}| j                   j                  || j                  j                  |	      }| j                  |      S | j                  d
       }|S )a  
        Compute open, high, low and close values of a group, excluding missing values.

        For multiple groupings, the result index will be a MultiIndex

        Returns
        -------
        DataFrame
            Open, high, low and close values within each group.

        Examples
        --------

        For SeriesGroupBy:

        >>> lst = ['SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC', 'SPX', 'CAC',]
        >>> ser = pd.Series([3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 0.1, 0.5], index=lst)
        >>> ser
        SPX     3.4
        CAC     9.0
        SPX     7.2
        CAC     5.2
        SPX     8.8
        CAC     9.4
        SPX     0.1
        CAC     0.5
        dtype: float64
        >>> ser.groupby(level=0).ohlc()
             open  high  low  close
        CAC   9.0   9.4  0.5    0.5
        SPX   3.4   8.8  0.1    0.1

        For DataFrameGroupBy:

        >>> data = {2022: [1.2, 2.3, 8.9, 4.5, 4.4, 3, 2 , 1],
        ...         2023: [3.4, 9.0, 7.2, 5.2, 8.8, 9.4, 8.2, 1.0]}
        >>> df = pd.DataFrame(data, index=['SPX', 'CAC', 'SPX', 'CAC',
        ...                   'SPX', 'CAC', 'SPX', 'CAC'])
        >>> df
             2022  2023
        SPX   1.2   3.4
        CAC   2.3   9.0
        SPX   8.9   7.2
        CAC   4.5   5.2
        SPX   4.4   8.8
        CAC   3.0   9.4
        SPX   2.0   8.2
        CAC   1.0   1.0
        >>> df.groupby(level=0).ohlc()
            2022                 2023
            open high  low close open high  low close
        CAC  2.3  4.5  1.0   1.0  9.0  9.4  1.0   1.0
        SPX  1.2  8.9  1.2   2.0  3.4  8.8  3.4   8.2

        For Resampler:

        >>> ser = pd.Series([1, 3, 2, 4, 3, 5],
        ...                 index=pd.DatetimeIndex(['2023-01-01',
        ...                                         '2023-01-10',
        ...                                         '2023-01-15',
        ...                                         '2023-02-01',
        ...                                         '2023-02-10',
        ...                                         '2023-02-15']))
        >>> ser.resample('MS').ohlc()
                    open  high  low  close
        2023-01-01     1     3    1      2
        2023-02-01     4     5    3      5
        r   zNo numeric types to aggregater  ohlcr   r(  r  )openhighlowclose)r5  rN  c                "    | j                         S rk   )r  )sgbs    ro   r   zGroupBy.ohlc.<locals>.<lambda>  s
    CHHJrq   )r   r9  rz   r5   r  r'   r   r  r4  _constructor_expanddimr,  r]  _apply_to_column_groupbys)rm   r   
is_numericr  	agg_namesr   s         ro   r  zGroupBy.ohlc  s    L 88==A$$C)#))4J ?@@88S[[&qB 9 J 9IXX44$--"<"<i 5 F ''////0FGrq   c                F   | j                   }t        |      dk(  r]|j                        }|j                  dk(  r|}n|j	                         }|j                         j                  j                  d d S t        j                  | dd      5  | j                  fd|d      }d d d        | j                  dk(  rj                  S j	                         }| j                  s*| j                  |      }t        t        |            |_        |S # 1 sw Y   lxY w)Nr   percentilesincludeexcluder   r   Tc                ,    | j                        S )Nr  )describe)r  r  r  r  s    ro   r   z"GroupBy.describe.<locals>.<lambda>  s    !** +Wg % rq   r  )r   r   r  r9  unstackrM  r#   r   r   r  ry   r   r   rU  rZ   r5  )rm   r  r  r  r   	describedr   s    ```   ro   r  zGroupBy.describe  s    ''s8q='' % I xx1}""**,??$&&++BQ//dJ5// !% 0 F 6 99>88O !}}008F(V5FL# 65s   DD c               ,    ddl m}  || |g|d|i|S )a  
        Provide resampling when using a TimeGrouper.

        Given a grouper, the function resamples it according to a string
        "string" -> "frequency".

        See the :ref:`frequency aliases <timeseries.offset_aliases>`
        documentation for more details.

        Parameters
        ----------
        rule : str or DateOffset
            The offset string or object representing target grouper conversion.
        *args
            Possible arguments are `how`, `fill_method`, `limit`, `kind` and
            `on`, and other arguments of `TimeGrouper`.
        include_groups : bool, default True
            When True, will attempt to include the groupings in the operation in
            the case that they are columns of the DataFrame. If this raises a
            TypeError, the result will be computed with the groupings excluded.
            When False, the groupings will be excluded when applying ``func``.

            .. versionadded:: 2.2.0

            .. deprecated:: 2.2.0

               Setting include_groups to True is deprecated. Only the value
               False will be allowed in a future version of pandas.

        **kwargs
            Possible arguments are `how`, `fill_method`, `limit`, `kind` and
            `on`, and other arguments of `TimeGrouper`.

        Returns
        -------
        pandas.api.typing.DatetimeIndexResamplerGroupby,
        pandas.api.typing.PeriodIndexResamplerGroupby, or
        pandas.api.typing.TimedeltaIndexResamplerGroupby
            Return a new groupby object, with type depending on the data
            being resampled.

        See Also
        --------
        Grouper : Specify a frequency to resample with when
            grouping by a key.
        DatetimeIndex.resample : Frequency conversion and resampling of
            time series.

        Examples
        --------
        >>> idx = pd.date_range('1/1/2000', periods=4, freq='min')
        >>> df = pd.DataFrame(data=4 * [range(2)],
        ...                   index=idx,
        ...                   columns=['a', 'b'])
        >>> df.iloc[2, 0] = 5
        >>> df
                            a  b
        2000-01-01 00:00:00  0  1
        2000-01-01 00:01:00  0  1
        2000-01-01 00:02:00  5  1
        2000-01-01 00:03:00  0  1

        Downsample the DataFrame into 3 minute bins and sum the values of
        the timestamps falling into a bin.

        >>> df.groupby('a').resample('3min', include_groups=False).sum()
                                 b
        a
        0   2000-01-01 00:00:00  2
            2000-01-01 00:03:00  1
        5   2000-01-01 00:00:00  1

        Upsample the series into 30 second bins.

        >>> df.groupby('a').resample('30s', include_groups=False).sum()
                            b
        a
        0   2000-01-01 00:00:00  1
            2000-01-01 00:00:30  0
            2000-01-01 00:01:00  1
            2000-01-01 00:01:30  0
            2000-01-01 00:02:00  0
            2000-01-01 00:02:30  0
            2000-01-01 00:03:00  1
        5   2000-01-01 00:02:00  1

        Resample by month. Values are assigned to the month of the period.

        >>> df.groupby('a').resample('ME', include_groups=False).sum()
                    b
        a
        0   2000-01-31  3
        5   2000-01-31  1

        Downsample the series into 3 minute bins as above, but close the right
        side of the bin interval.

        >>> (
        ...     df.groupby('a')
        ...     .resample('3min', closed='right', include_groups=False)
        ...     .sum()
        ... )
                                 b
        a
        0   1999-12-31 23:57:00  1
            2000-01-01 00:00:00  2
        5   2000-01-01 00:00:00  1

        Downsample the series into 3 minute bins and close the right side of
        the bin interval, but label each bin using the right edge instead of
        the left.

        >>> (
        ...     df.groupby('a')
        ...     .resample('3min', closed='right', label='right', include_groups=False)
        ...     .sum()
        ... )
                                 b
        a
        0   2000-01-01 00:00:00  1
            2000-01-01 00:03:00  2
        5   2000-01-01 00:03:00  1
        r   )get_resampler_for_groupingr  )pandas.core.resampler  )rm   ruler  ru   rv   r  s         ro   resamplezGroupBy.resample%  s5    z 	D *$

.<
@F
 	
rq   c                h    ddl m}  || j                  g|| j                  | j                  d|S )a  
        Return a rolling grouper, providing rolling functionality per group.

        Parameters
        ----------
        window : int, timedelta, str, offset, or BaseIndexer subclass
            Size of the moving window.

            If an integer, the fixed number of observations used for
            each window.

            If a timedelta, str, or offset, the time period of each window. Each
            window will be a variable sized based on the observations included in
            the time-period. This is only valid for datetimelike indexes.
            To learn more about the offsets & frequency strings, please see `this link
            <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.

            If a BaseIndexer subclass, the window boundaries
            based on the defined ``get_window_bounds`` method. Additional rolling
            keyword arguments, namely ``min_periods``, ``center``, ``closed`` and
            ``step`` will be passed to ``get_window_bounds``.

        min_periods : int, default None
            Minimum number of observations in window required to have a value;
            otherwise, result is ``np.nan``.

            For a window that is specified by an offset,
            ``min_periods`` will default to 1.

            For a window that is specified by an integer, ``min_periods`` will default
            to the size of the window.

        center : bool, default False
            If False, set the window labels as the right edge of the window index.

            If True, set the window labels as the center of the window index.

        win_type : str, default None
            If ``None``, all points are evenly weighted.

            If a string, it must be a valid `scipy.signal window function
            <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.

            Certain Scipy window types require additional parameters to be passed
            in the aggregation function. The additional parameters must match
            the keywords specified in the Scipy window type method signature.

        on : str, optional
            For a DataFrame, a column label or Index level on which
            to calculate the rolling window, rather than the DataFrame's index.

            Provided integer column is ignored and excluded from result since
            an integer index is not used to calculate the rolling window.

        axis : int or str, default 0
            If ``0`` or ``'index'``, roll across the rows.

            If ``1`` or ``'columns'``, roll across the columns.

            For `Series` this parameter is unused and defaults to 0.

        closed : str, default None
            If ``'right'``, the first point in the window is excluded from calculations.

            If ``'left'``, the last point in the window is excluded from calculations.

            If ``'both'``, no points in the window are excluded from calculations.

            If ``'neither'``, the first and last points in the window are excluded
            from calculations.

            Default ``None`` (``'right'``).

        method : str {'single', 'table'}, default 'single'
            Execute the rolling operation per single column or row (``'single'``)
            or over the entire object (``'table'``).

            This argument is only implemented when specifying ``engine='numba'``
            in the method call.

        Returns
        -------
        pandas.api.typing.RollingGroupby
            Return a new grouper with our rolling appended.

        See Also
        --------
        Series.rolling : Calling object with Series data.
        DataFrame.rolling : Calling object with DataFrames.
        Series.groupby : Apply a function groupby to a Series.
        DataFrame.groupby : Apply a function groupby.

        Examples
        --------
        >>> df = pd.DataFrame({'A': [1, 1, 2, 2],
        ...                    'B': [1, 2, 3, 4],
        ...                    'C': [0.362, 0.227, 1.267, -0.562]})
        >>> df
              A  B      C
        0     1  1  0.362
        1     1  2  0.227
        2     2  3  1.267
        3     2  4 -0.562

        >>> df.groupby('A').rolling(2).sum()
            B      C
        A
        1 0  NaN    NaN
          1  3.0  0.589
        2 2  NaN    NaN
          3  7.0  0.705

        >>> df.groupby('A').rolling(2, min_periods=1).sum()
            B      C
        A
        1 0  1.0  0.362
          1  3.0  0.589
        2 2  3.0  1.267
          3  7.0  0.705

        >>> df.groupby('A').rolling(2, on='B').sum()
            B      C
        A
        1 0  1    NaN
          1  2  0.589
        2 2  3    NaN
          3  4  0.705
        r   )rd   )r   	_as_index)pandas.core.windowrd   rz   r   r   )rm   ru   rv   rd   s       ro   rollingzGroupBy.rolling  sE    D 	6

 ]]mm	

 
 	
rq   c                R    ddl m}  || j                  g|d| j                  i|S )z
        Return an expanding grouper, providing expanding
        functionality per group.

        Returns
        -------
        pandas.api.typing.ExpandingGroupby
        r   )rb   r   )r  rb   rz   r   )rm   ru   rv   rb   s       ro   	expandingzGroupBy.expanding6  s=     	8

 ]]
 	
 	
rq   c                R    ddl m}  || j                  g|d| j                  i|S )z
        Return an ewm grouper, providing ewm functionality per group.

        Returns
        -------
        pandas.api.typing.ExponentialMovingWindowGroupby
        r   )rc   r   )r  rc   rz   r   )rm   ru   rv   rc   s       ro   ewmzGroupBy.ewmK  s>     	F-

 ]]
 	
 	
rq   c                0   
 |d} j                   j                  \  }}}t        j                  |d      j	                  t        j
                  d      }|dk(  r|ddd   }t        t        j                  ||| j                        
d
 fd	} j                         }|j                  |      } j                  |      }	 j                  d
k(  r'|	j                  }	 j                  j                   |	_         j                  j"                  |	_        |	S )a  
        Shared function for `pad` and `backfill` to call Cython method.

        Parameters
        ----------
        direction : {'ffill', 'bfill'}
            Direction passed to underlying Cython function. `bfill` will cause
            values to be filled backwards. `ffill` and any other values will
            default to a forward fill
        limit : int, default None
            Maximum number of consecutive values to fill. If `None`, this
            method will convert to -1 prior to passing to Cython

        Returns
        -------
        `Series` or `DataFrame` with filled values

        See Also
        --------
        pad : Returns Series with minimum number of char in object.
        backfill : Backward fill the missing values in the dataset.
        Nr(  	mergesort)rG  Fr  bfill)r>  sorted_labelslimitr   c                   t        |       }| j                  dk(  rOt        j                  | j                  t        j
                        } ||       t        j                  | |      S t        | t        j                        rY| j                  }j                  j                  rt        | j                        }t        j                  | j                  |      }n0t        |       j                  | j                  | j                        }t!        |       D ]a  \  }}t        j                  | j                  d   t        j
                        } |||          t        j                  ||      ||d d f<   c |S )Nr   r  )r  r?  )r;   r9  r   r  r  r  r>   r  r   ndarrayr  r   r   r.   r   _emptyrL  )	r:  r?  r   r  r  ivalue_elementcol_funcrm   s	          ro   blk_funczGroupBy._fill.<locals>.blk_func  s   <D{{a((6<<rww?W40!))&'::
 fbjj1"LLE}}33 8 F((6<<u=C v,--fll&,,-OC(1&(9$A} hhv||AbggFGtAw7 * 2 2=' JC1I	 ):
 
rq   r   r  )r   r/  r   r  r  r  r   
libgroupbygroup_fillna_indexerr   r  ry  r  r   r#   r   rN  r5  )rm   	directionr  rk  rA  r  r  mgrr  r!  r  s   `         @ro   _fillzGroupBy._fill_  s    2 =EMM,,	Q

3[9@@u@U)$B$/M++';;
	< ))+))H%**7399>iiG"hh..GOrq   c                (    | j                  d|      S )a0	  
        Forward fill the values.

        Parameters
        ----------
        limit : int, optional
            Limit of how many values to fill.

        Returns
        -------
        Series or DataFrame
            Object with missing values filled.

        See Also
        --------
        Series.ffill: Returns Series with minimum number of char in object.
        DataFrame.ffill: Object with missing values filled or None if inplace=True.
        Series.fillna: Fill NaN values of a Series.
        DataFrame.fillna: Fill NaN values of a DataFrame.

        Examples
        --------

        For SeriesGroupBy:

        >>> key = [0, 0, 1, 1]
        >>> ser = pd.Series([np.nan, 2, 3, np.nan], index=key)
        >>> ser
        0    NaN
        0    2.0
        1    3.0
        1    NaN
        dtype: float64
        >>> ser.groupby(level=0).ffill()
        0    NaN
        0    2.0
        1    3.0
        1    3.0
        dtype: float64

        For DataFrameGroupBy:

        >>> df = pd.DataFrame(
        ...     {
        ...         "key": [0, 0, 1, 1, 1],
        ...         "A": [np.nan, 2, np.nan, 3, np.nan],
        ...         "B": [2, 3, np.nan, np.nan, np.nan],
        ...         "C": [np.nan, np.nan, 2, np.nan, np.nan],
        ...     }
        ... )
        >>> df
           key    A    B   C
        0    0  NaN  2.0 NaN
        1    0  2.0  3.0 NaN
        2    1  NaN  NaN 2.0
        3    1  3.0  NaN NaN
        4    1  NaN  NaN NaN

        Propagate non-null values forward or backward within each group along columns.

        >>> df.groupby("key").ffill()
             A    B   C
        0  NaN  2.0 NaN
        1  2.0  3.0 NaN
        2  NaN  NaN 2.0
        3  3.0  NaN 2.0
        4  3.0  NaN 2.0

        Propagate non-null values forward or backward within each group along rows.

        >>> df.T.groupby(np.array([0, 0, 1, 1])).ffill().T
           key    A    B    C
        0  0.0  0.0  2.0  2.0
        1  0.0  2.0  3.0  3.0
        2  1.0  1.0  NaN  2.0
        3  1.0  3.0  NaN  NaN
        4  1.0  1.0  NaN  NaN

        Only replace the first NaN element within a group along rows.

        >>> df.groupby("key").ffill(limit=1)
             A    B    C
        0  NaN  2.0  NaN
        1  2.0  3.0  NaN
        2  NaN  NaN  2.0
        3  3.0  NaN  2.0
        4  3.0  NaN  NaN
        ffillr  r  rm   r  s     ro   r  zGroupBy.ffill  s    v zz'z//rq   c                (    | j                  d|      S )a  
        Backward fill the values.

        Parameters
        ----------
        limit : int, optional
            Limit of how many values to fill.

        Returns
        -------
        Series or DataFrame
            Object with missing values filled.

        See Also
        --------
        Series.bfill :  Backward fill the missing values in the dataset.
        DataFrame.bfill:  Backward fill the missing values in the dataset.
        Series.fillna: Fill NaN values of a Series.
        DataFrame.fillna: Fill NaN values of a DataFrame.

        Examples
        --------

        With Series:

        >>> index = ['Falcon', 'Falcon', 'Parrot', 'Parrot', 'Parrot']
        >>> s = pd.Series([None, 1, None, None, 3], index=index)
        >>> s
        Falcon    NaN
        Falcon    1.0
        Parrot    NaN
        Parrot    NaN
        Parrot    3.0
        dtype: float64
        >>> s.groupby(level=0).bfill()
        Falcon    1.0
        Falcon    1.0
        Parrot    3.0
        Parrot    3.0
        Parrot    3.0
        dtype: float64
        >>> s.groupby(level=0).bfill(limit=1)
        Falcon    1.0
        Falcon    1.0
        Parrot    NaN
        Parrot    3.0
        Parrot    3.0
        dtype: float64

        With DataFrame:

        >>> df = pd.DataFrame({'A': [1, None, None, None, 4],
        ...                    'B': [None, None, 5, None, 7]}, index=index)
        >>> df
                  A	    B
        Falcon	1.0	  NaN
        Falcon	NaN	  NaN
        Parrot	NaN	  5.0
        Parrot	NaN	  NaN
        Parrot	4.0	  7.0
        >>> df.groupby(level=0).bfill()
                  A	    B
        Falcon	1.0	  NaN
        Falcon	NaN	  NaN
        Parrot	4.0	  5.0
        Parrot	4.0	  7.0
        Parrot	4.0	  7.0
        >>> df.groupby(level=0).bfill(limit=1)
                  A	    B
        Falcon	1.0	  NaN
        Falcon	NaN	  NaN
        Parrot	NaN	  5.0
        Parrot	4.0	  7.0
        Parrot	4.0	  7.0
        r  r  r  r  s     ro   r  zGroupBy.bfill  s    \ zz'z//rq   c                    t        |       S )a  
        Take the nth row from each group if n is an int, otherwise a subset of rows.

        Can be either a call or an index. dropna is not available with index notation.
        Index notation accepts a comma separated list of integers and slices.

        If dropna, will take the nth non-null row, dropna is either
        'all' or 'any'; this is equivalent to calling dropna(how=dropna)
        before the groupby.

        Parameters
        ----------
        n : int, slice or list of ints and slices
            A single nth value for the row or a list of nth values or slices.

            .. versionchanged:: 1.4.0
                Added slice and lists containing slices.
                Added index notation.

        dropna : {'any', 'all', None}, default None
            Apply the specified dropna operation before counting which row is
            the nth row. Only supported if n is an int.

        Returns
        -------
        Series or DataFrame
            N-th value within each group.
        %(see_also)s
        Examples
        --------

        >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],
        ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])
        >>> g = df.groupby('A')
        >>> g.nth(0)
           A   B
        0  1 NaN
        2  2 3.0
        >>> g.nth(1)
           A   B
        1  1 2.0
        4  2 5.0
        >>> g.nth(-1)
           A   B
        3  1 4.0
        4  2 5.0
        >>> g.nth([0, 1])
           A   B
        0  1 NaN
        1  1 2.0
        2  2 3.0
        4  2 5.0
        >>> g.nth(slice(None, -1))
           A   B
        0  1 NaN
        1  1 2.0
        2  2 3.0

        Index notation may also be used

        >>> g.nth[0, 1]
           A   B
        0  1 NaN
        1  1 2.0
        2  2 3.0
        4  2 5.0
        >>> g.nth[:-1]
           A   B
        0  1 NaN
        1  1 2.0
        2  2 3.0

        Specifying `dropna` allows ignoring ``NaN`` values

        >>> g.nth(0, dropna='any')
           A   B
        1  1 2.0
        2  2 3.0

        When the specified ``n`` is larger than any of the groups, an
        empty DataFrame is returned

        >>> g.nth(3, dropna='any')
        Empty DataFrame
        Columns: [A, B]
        Index: []
        )rU   r   s    ro   nthzGroupBy.nth`  s    x "$''rq   c                   |sF| j                  |      }| j                  j                  \  }}}||dk7  z  }| j                  |      }|S t	        |      st        d      |dvrt        d| d      t        t        |      }| j                  j                  || j                        }t        |      t        | j                        k(  r| j                  }n| j                  j                  }	| j                  j                  |	j                  |j                           }| j                  j                  r-|dk(  }
t!        j"                  |
t$        |      }t'        |d      }| j                  d	k(  r3|j(                  j+                  || j,                  | j.                  
      }n(|j+                  || j,                  | j.                  
      }|j1                  |      S )Nr(  z4dropna option only supported for an integer argumentr  z_For a DataFrame or Series groupby.nth, dropna must be either None, 'any' or 'all', (was passed z).)r  r   Int64r  r   )r   r   )"_make_mask_from_positional_indexerr   r/  _mask_selected_objr2   r   r   r   rz   r   r   r   
codes_infoisinr5  r   r   r  r   rW   r#   rn   r   r   r  )rm   r   r   r?  rk  rA  r  droppedr   r   nullsr:  grbs                ro   _nthzGroupBy._nth  s   
 ::1=D00ICA 3"9%D))$/CJ !}STT'%hb*  aL$$++TYY+G w<3t1122mmG
 ==%%Dmm..tyy/GHG}}++2 %W5g699>))##Gdmm$))#TC//'DMM		/RCwwqzrq   c                     j                  |d      } j                  |      } j                  dk(  rH j                  j	                  |j
                   j                        }|j                  j
                  }n3 j                  j	                  | j                        }|j                  }t        j                  |j                  |j                        \  }}	d fd	 	 	 	 	 	 	 	 	 	 dfdt        j                  |t        j                        }
|
}t        |      r(t        j                  |gt        j                        }
d} j                  j                  \  }}t!        |
      t#        t$        j&                  ||
||		      dfd
}|j(                  j+                  |      } j                  |      } j-                  ||      S )a  
        Return group values at the given quantile, a la numpy.percentile.

        Parameters
        ----------
        q : float or array-like, default 0.5 (50% quantile)
            Value(s) between 0 and 1 providing the quantile(s) to compute.
        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}
            Method to use when the desired quantile falls between two points.
        numeric_only : bool, default False
            Include only `float`, `int` or `boolean` data.

            .. versionadded:: 1.5.0

            .. versionchanged:: 2.0.0

                numeric_only now defaults to ``False``.

        Returns
        -------
        Series or DataFrame
            Return type determined by caller of GroupBy object.

        See Also
        --------
        Series.quantile : Similar method for Series.
        DataFrame.quantile : Similar method for DataFrame.
        numpy.percentile : NumPy method to compute qth percentile.

        Examples
        --------
        >>> df = pd.DataFrame([
        ...     ['a', 1], ['a', 2], ['a', 3],
        ...     ['b', 1], ['b', 3], ['b', 5]
        ... ], columns=['key', 'val'])
        >>> df.groupby('key').quantile()
            val
        key
        a    2.0
        b    3.0
        quantiler  r   r   c                    t        | j                  t              st        | j                        rt	        d| j                   d      d }t        | t
              rJt        | j                        r5| j                  t        t        j                        }| j                  }||fS t        | j                        r_t        | t              r&| j                  t        t        j                        }n| }t        j                  t        j                        }||fS t        | j                        r9t        | t              r)| j                  t        t        j                        }||fS t        | j                        rTt        j                   dt#              j$                   dt&        t)                      t        j*                  |       }||fS t-        | j                        r| j                  }| |fS t        | t              rat/        | j                        rLt        j                  t        j0                        }| j                  t        t        j                        }||fS t        j*                  |       }||fS )Nzdtype 'z'' does not support operation 'quantile')r  r  zAllowing bool dtype in z.quantile is deprecated and will raise in a future version, matching the Series/DataFrame behavior. Cast to uint8 dtype before calling quantile instead.r   )r   r  rI   r6   r  rC   r5   rg  floatr   r  r3   rE   r  r/   r   r   r   rx   r   r,   asarrayr9   r0   r  )vals	inferencer  rm   s      ro   pre_processorz'GroupBy.quantile.<locals>.pre_processor3  s   $**k2odjj6Qdjj\)PQ  *.I$05Edjj5Qmm%"&&mA JJ	F 	>!E "$**-dN3--ebff-ECCHHRXX.	: 	>!9 tzz*z$/Omm%"&&mA6 	>!5 tzz*-d4j.A.A-B C0 0 "/1 jj&  	>! %TZZ0 JJ	 Y&D.1nTZZ6PHHRZZ0	mm%"&&mA 	>! jj&	>!rq   c                f   |rt        |t              r|J dv rt        |      st        | |      S t	        j
                         5  t	        j                  dt                t        |      | j                  |j                        |      cd d d        S t        |      rdv s}t        |      rE| j                  d      j                  |j                  j                        } |j!                  |       S t        |t"        j                        sJ | j                  |      S | S # 1 sw Y   | S xY w)N>   linearmidpointignore)r   i8)r   rC   r0   rF   r   catch_warningsfilterwarningsRuntimeWarningr   r  numpy_dtyper3   r9   view_ndarrayr  _from_backing_datar   )r  r  result_mask	orig_valsinterpolations       ro   post_processorz(GroupBy.quantile.<locals>.post_processora  s#    i9&222$(>>~!H  -T;??
 &446$33H~V#24	? $$-$9$9!" !,	$ 76 %Y/%)??*95  ${{4055%..44 
  );;    &i:::;;y11K; 7: Ks   AD&&D0r  N)r>  rZ  r  rr  rs  c                   | }t        | t              r4| j                  }t        j                  ft        j
                        }nt        |       }d }t        | j                        } |       \  }}d}|j                  dk(  r|j                  d   }t        j                  |ft        j                        }|r|j                  d      }|j                  dk(  r 
|d   ||||       n&t        |      D ]  }	 
||	   ||	   ||	   d |        |j                  dk(  r%|j                  d      }|'|j                  d      }n|j!                  |z        } ||||      S )Nr  r   rv  r   r  )r:  r?  r  is_datetimelikeK)r   rC   _maskr   r  r  r;   r9   r  r9  r  r  r  r  r-  r  r  )r:  r  r?  r  r  r  r  ncolsr  r  r   r   nqsr  r  s             ro   r  z"GroupBy.quantile.<locals>.blk_func  sS   I&/2|| hh~RXXFF|"1&,,?O+F3OD)EyyA~

1((E7C0

CCyyyyA~F +$3 uAA#Aw!!W$((7 & yyA~iin*"-"3"3C"8Kkk%37!#y+yIIrq   rY  )r  r   r   z"tuple[np.ndarray, DtypeObj | None])
r  
np.ndarrayr  zDtypeObj | Noner  znp.ndarray | Noner  r   r   r   r  )r  r  r   r   _get_splitterr#   _sorted_datar   rj  _slabelsr   r   r  r  r7   r/  r   r   r  group_quantilerx  r  r_  )rm   qr  r  r  r   splittersdatarr  rs  rZ  pass_qsrk  rA  r  r  r^  r   r   r  r  r  s   ` `              @@@@@ro   r  zGroupBy.quantile  s   ` ))|*)U&&s+99>}}22355tyy2IH))++E}}223TYY2GH))E**8+<+<h>N>NO,	"\0	0	&0	 +0	 !	0	
 0	d XXarzz*%'Q<1#RZZ0BG--22Q"g%%'
0	J 0	Jd **++H5&&w/++CG+<<rq   c                    | j                   }|j                  | j                        }| j                  j                  d   }| j                  j
                  r9t        j                  |dk(  t        j                  |      }t        j                  }nt        j                  }t        d | j                  j                  D              rt        |d      dz
  }| j                  |||      }|s| j                  dz
  |z
  }|S )a  
        Number each group from 0 to the number of groups - 1.

        This is the enumerative complement of cumcount.  Note that the
        numbers given to the groups match the order in which the groups
        would be seen when iterating over the groupby object, not the
        order they are first observed.

        Groups with missing keys (where `pd.isna()` is True) will be labeled with `NaN`
        and will be skipped from the count.

        Parameters
        ----------
        ascending : bool, default True
            If False, number in reverse, from number of group - 1 to 0.

        Returns
        -------
        Series
            Unique numbers for each group.

        See Also
        --------
        .cumcount : Number the rows in each group.

        Examples
        --------
        >>> df = pd.DataFrame({"color": ["red", None, "red", "blue", "blue", "red"]})
        >>> df
           color
        0    red
        1   None
        2    red
        3   blue
        4   blue
        5    red
        >>> df.groupby("color").ngroup()
        0    1.0
        1    NaN
        2    1.0
        3    0.0
        4    0.0
        5    1.0
        dtype: float64
        >>> df.groupby("color", dropna=False).ngroup()
        0    1
        1    2
        2    1
        3    0
        4    0
        5    1
        dtype: int64
        >>> df.groupby("color", dropna=False).ngroup(ascending=False)
        0    1
        1    0
        2    1
        3    2
        4    2
        5    1
        dtype: int64
        r   r(  c              3  4   K   | ]  }|j                     y wrk   r   r  s     ro   r   z!GroupBy.ngroup.<locals>.<genexpr>'  s     L4KDt''4Kr  dense)ties_methodr   r  )r   r.  r   r   r/  r   r   r  r  r  r  r  r  r   r  r   )rm   r  r   r5  comp_idsr  r   s          ro   ngroupzGroupBy.ngroup  s    @ ''dii(==++A. ==''xxBAHJJEHHELDMM4K4KLLxW=AH))(E)G\\A%.Frq   c                    | j                   j                  | j                        }| j                  |      }| j	                  ||      S )a  
        Number each item in each group from 0 to the length of that group - 1.

        Essentially this is equivalent to

        .. code-block:: python

            self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))

        Parameters
        ----------
        ascending : bool, default True
            If False, number in reverse, from length of group - 1 to 0.

        Returns
        -------
        Series
            Sequence number of each element within each group.

        See Also
        --------
        .ngroup : Number the groups themselves.

        Examples
        --------
        >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
        ...                   columns=['A'])
        >>> df
           A
        0  a
        1  a
        2  a
        3  b
        4  b
        5  a
        >>> df.groupby('A').cumcount()
        0    0
        1    1
        2    2
        3    0
        4    1
        5    3
        dtype: int64
        >>> df.groupby('A').cumcount(ascending=False)
        0    3
        1    2
        2    1
        3    1
        4    0
        5    0
        dtype: int64
        )r  )r   r.  r   r  r  )rm   r  r5  	cumcountss       ro   cumcountzGroupBy.cumcount0  sE    n ))33DII>((9(=	''	599rq   averagekeepc                d  	 |dvrd}t        |      t        j                  ur.| j                  j	                        | j                  d       nd||||d	dk7  r:	j                  d      	d<   	fd}| j                  || j                  d	
      }|S  | j                  	 ddd	S )a  
        Provide the rank of values within each group.

        Parameters
        ----------
        method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'
            * average: average rank of group.
            * min: lowest rank in group.
            * max: highest rank in group.
            * first: ranks assigned in order they appear in the array.
            * dense: like 'min', but rank always increases by 1 between groups.
        ascending : bool, default True
            False for ranks by high (1) to low (N).
        na_option : {'keep', 'top', 'bottom'}, default 'keep'
            * keep: leave NA values where they are.
            * top: smallest rank if ascending.
            * bottom: smallest rank if descending.
        pct : bool, default False
            Compute percentage rank of data within